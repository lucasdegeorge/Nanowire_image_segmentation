{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f999263-24d3-4ccf-8c32-ed5998ac4d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboard --quiet\n",
    "!pip install matplotlib --quiet\n",
    "!pip install scikit-learn --quiet\n",
    "!pip install torchsummary --quiet\n",
    "!pip install opencv-python --quiet\n",
    "!pip install monai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "606a4cdf-c314-4e9c-b2ac-28d587cbea32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/onyxia/work/Nanowire_image_segmentation\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import date\n",
    "import json\n",
    "\n",
    "import io\n",
    "import s3fs\n",
    "\n",
    "from dataloader_sep import *\n",
    "from model.model import * \n",
    "from trainer import * \n",
    "\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ab57a82-5ab7-4c15-9781-82d5d10984a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") \n",
    "\n",
    "# Create filesystem object\n",
    "S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n",
    "\n",
    "# BUCKET = \"ldegeorge/images\"\n",
    "# fs.ls(BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c5441-d31f-4804-b1c6-b6b1f09924fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "        with fs.open(path, 'rb') as file:\n",
    "            image_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "792ab50e-96f9-44fa-9058-b5826d373e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataloader ok\n"
     ]
    }
   ],
   "source": [
    "image_paths = []\n",
    "mask_paths = []\n",
    "\n",
    "bucket = \"ldegeorge/labeled_data_pt\"\n",
    "for path in fs.ls(bucket):\n",
    "    if path == 'ldegeorge/images/.keep':\n",
    "        pass\n",
    "    else:\n",
    "        image_paths.append(path)\n",
    "\n",
    "bucket = \"ldegeorge/binary_masks_pt\"\n",
    "for path in fs.ls(bucket):\n",
    "    if path == 'ldegeorge/binary_masks/.keep':\n",
    "        pass\n",
    "    else:\n",
    "        mask_paths.append(path)\n",
    "\n",
    "class train_LabeledDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_list, mask_list, transform=None):\n",
    "        self.image_list = image_list\n",
    "        self.mask_list = mask_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.image_list[index]\n",
    "        mask = self.mask_list[index]\n",
    "        with fs.open(image, 'rb') as file:\n",
    "            image_data = file.read()\n",
    "        with fs.open(mask, 'rb') as file:\n",
    "            mask_data = file.read()\n",
    "        mask = torch.load(mask_data)\n",
    "        return image, mask\n",
    "\n",
    "class eval_LabeledDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_list, mask_list, transform=None):\n",
    "        self.image_list = image_list\n",
    "        self.mask_list = mask_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.image_list[index]\n",
    "        mask = self.mask_list[index]\n",
    "        with fs.open(image, 'rb') as file:\n",
    "            image_data = file.read()\n",
    "        with fs.open(mask, 'rb') as file:\n",
    "            mask_data = file.read()\n",
    "        mask = torch.load(mask_data)\n",
    "        return image, mask\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "train_images, eval_images, train_masks, eval_masks = train_test_split(image_list, mask_list, test_size=0.2)\n",
    "train_dataset = train_LabeledDataset(train_images, train_masks)\n",
    "eval_dataset = eval_LabeledDataset(eval_images, eval_masks)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "eval_dataloader = torch.utils.data.DataLoader(eval_dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f789c677-0cc4-46f6-b988-2f47a4bc513a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mdataloader\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51a552fc-9709-488a-bc54-c5982e2a1808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    print(\"start training\")\n",
    "    start_time = time.time()\n",
    "    lr = 0.0002\n",
    "\n",
    "    generator = UnetGenerator().to(device)\n",
    "    discriminator = ConditionalDiscriminator().to(device)\n",
    "    criterions = [ GeneratorLoss(alpha=100), DiscriminatorLoss() ]\n",
    "\n",
    "    trainer = pix2pix_trainer(generator, discriminator, criterions, lr, batch_size, timestamp=timestamp, dataloader=dataloader)\n",
    "    trainer.train()\n",
    "\n",
    "    print(\"end of training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d8d38-a771-4027-a3d6-a4a3405c6fe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "56\n",
      "EPOCH 0:\n",
      "  batch 0 loss: [62.662261962890625, 0.7088532447814941]\n",
      "  batch 2 loss: [53.87037467956543, 0.8901240825653076]\n",
      "  batch 4 loss: [46.6334342956543, 0.7785354256629944]\n",
      "  batch 6 loss: [46.6695499420166, 0.6993644535541534]\n",
      "  batch 8 loss: [45.96317481994629, 0.6947112381458282]\n",
      "  batch 10 loss: [36.016408920288086, 0.6940074563026428]\n",
      "  batch 12 loss: [27.848180770874023, 0.6937751770019531]\n",
      "  batch 14 loss: [36.485618591308594, 0.6936433613300323]\n",
      "  batch 16 loss: [43.35696029663086, 0.6934984028339386]\n",
      "  batch 18 loss: [45.3878231048584, 0.6935330629348755]\n",
      "  batch 20 loss: [33.673513412475586, 0.6933387517929077]\n",
      "  batch 22 loss: [33.71762561798096, 0.6933234632015228]\n",
      "  batch 24 loss: [40.779977798461914, 0.6933051645755768]\n",
      "  batch 26 loss: [34.26003837585449, 0.6932120323181152]\n",
      "  batch 28 loss: [37.25369644165039, 0.693175733089447]\n",
      "  batch 30 loss: [35.46072006225586, 0.6932038068771362]\n",
      "  batch 32 loss: [43.36826515197754, 0.693413257598877]\n",
      "  batch 34 loss: [47.77342987060547, 0.694085955619812]\n",
      "  batch 36 loss: [33.37541961669922, 0.6941308379173279]\n",
      "  batch 38 loss: [32.7241907119751, 0.693519800901413]\n",
      "  batch 40 loss: [47.13571357727051, 0.6943284869194031]\n",
      "  batch 42 loss: [32.526366233825684, 0.6957035958766937]\n",
      "  batch 44 loss: [33.78853988647461, 0.6937233805656433]\n",
      "  batch 46 loss: [39.87899398803711, 0.6935484409332275]\n",
      "  batch 48 loss: [37.56564998626709, 0.6943758130073547]\n",
      "  batch 50 loss: [32.167643547058105, 0.6961381435394287]\n",
      "  batch 52 loss: [34.8987979888916, 0.6996045112609863]\n",
      "  batch 54 loss: [32.95464324951172, 0.6977191269397736]\n",
      "LOSS generator 32.95464324951172 discriminator 0.6977191269397736\n",
      "EPOCH 1:\n",
      "  batch 0 loss: [42.00521469116211, 0.6936959028244019]\n",
      "  batch 2 loss: [33.34355545043945, 0.6927770376205444]\n",
      "  batch 4 loss: [42.20985221862793, 0.692783921957016]\n",
      "  batch 6 loss: [30.97691059112549, 0.695612221956253]\n",
      "  batch 8 loss: [43.92031478881836, 0.6993738114833832]\n",
      "  batch 10 loss: [36.35202503204346, 0.7040544152259827]\n",
      "  batch 12 loss: [33.534175872802734, 0.6964204907417297]\n",
      "  batch 14 loss: [27.82194995880127, 0.6930118203163147]\n",
      "  batch 16 loss: [36.08096504211426, 0.6940180063247681]\n",
      "  batch 18 loss: [39.89202308654785, 0.692470371723175]\n",
      "  batch 20 loss: [39.0393762588501, 0.6929000616073608]\n",
      "  batch 22 loss: [29.60822582244873, 0.6927707195281982]\n",
      "  batch 24 loss: [36.66591835021973, 0.6952428817749023]\n",
      "  batch 26 loss: [38.795406341552734, 0.6995036005973816]\n",
      "  batch 28 loss: [36.544342041015625, 0.7079082429409027]\n",
      "  batch 30 loss: [41.99704170227051, 0.705015242099762]\n",
      "  batch 32 loss: [32.56505584716797, 0.6878231465816498]\n",
      "  batch 34 loss: [35.84331798553467, 0.6957152187824249]\n",
      "  batch 36 loss: [34.856719970703125, 0.6963150501251221]\n",
      "  batch 38 loss: [38.36500263214111, 0.6933207511901855]\n",
      "  batch 40 loss: [37.80908966064453, 0.6930689215660095]\n",
      "  batch 42 loss: [35.52895641326904, 0.6921453475952148]\n",
      "  batch 44 loss: [46.546979904174805, 0.6923976540565491]\n",
      "  batch 46 loss: [32.702799797058105, 0.693129152059555]\n",
      "  batch 48 loss: [39.30722236633301, 0.6980412602424622]\n",
      "  batch 50 loss: [36.02865219116211, 0.7058331668376923]\n",
      "  batch 52 loss: [34.30855464935303, 0.6961273849010468]\n",
      "  batch 54 loss: [34.311184883117676, 0.6922773122787476]\n",
      "LOSS generator 34.311184883117676 discriminator 0.6922773122787476\n",
      "EPOCH 2:\n",
      "  batch 0 loss: [33.926334381103516, 0.6911300420761108]\n",
      "  batch 2 loss: [29.23391342163086, 0.6913885176181793]\n",
      "  batch 4 loss: [31.616619110107422, 0.6921930313110352]\n",
      "  batch 6 loss: [39.829750061035156, 0.7165396809577942]\n",
      "  batch 8 loss: [33.71672439575195, 0.7192662954330444]\n",
      "  batch 10 loss: [38.434701919555664, 0.6932448744773865]\n",
      "  batch 12 loss: [38.41449737548828, 0.6933932602405548]\n",
      "  batch 14 loss: [29.739005088806152, 0.6929979622364044]\n",
      "  batch 16 loss: [41.98925971984863, 0.6914159059524536]\n",
      "  batch 18 loss: [41.45913505554199, 0.6937639117240906]\n",
      "  batch 20 loss: [50.84443664550781, 0.696195662021637]\n",
      "  batch 22 loss: [39.0974178314209, 0.6939924955368042]\n",
      "  batch 24 loss: [32.64252948760986, 0.6913196742534637]\n",
      "  batch 26 loss: [40.12800216674805, 0.6909005641937256]\n",
      "  batch 28 loss: [34.673312187194824, 0.6931292414665222]\n",
      "  batch 30 loss: [27.276399612426758, 0.6933392286300659]\n",
      "  batch 32 loss: [37.11761665344238, 0.6981534659862518]\n",
      "  batch 34 loss: [30.01152229309082, 0.692255288362503]\n",
      "  batch 36 loss: [33.94433403015137, 0.6915197372436523]\n",
      "  batch 38 loss: [35.20860481262207, 0.6905142664909363]\n",
      "  batch 40 loss: [35.73130226135254, 0.688400149345398]\n",
      "  batch 42 loss: [33.41060829162598, 0.7012274861335754]\n",
      "  batch 44 loss: [28.716774940490723, 0.7145460247993469]\n",
      "  batch 46 loss: [35.72154140472412, 0.6933635473251343]\n",
      "  batch 48 loss: [37.70598602294922, 0.68594890832901]\n",
      "  batch 50 loss: [37.59260940551758, 0.7186873555183411]\n",
      "  batch 52 loss: [41.32382678985596, 0.7170103788375854]\n",
      "  batch 54 loss: [38.02710151672363, 0.7080807387828827]\n",
      "LOSS generator 38.02710151672363 discriminator 0.7080807387828827\n",
      "EPOCH 3:\n",
      "  batch 0 loss: [37.666717529296875, 0.693526029586792]\n",
      "  batch 2 loss: [39.711517333984375, 0.6940053105354309]\n",
      "  batch 4 loss: [31.7808780670166, 0.6959809064865112]\n",
      "  batch 6 loss: [40.85048866271973, 0.6920371353626251]\n",
      "  batch 8 loss: [39.2979736328125, 0.6904028356075287]\n",
      "  batch 10 loss: [37.22027778625488, 0.6893139481544495]\n",
      "  batch 12 loss: [31.5562162399292, 0.6932771503925323]\n",
      "  batch 14 loss: [27.397197723388672, 0.6901418268680573]\n",
      "  batch 16 loss: [36.390323638916016, 0.687526524066925]\n",
      "  batch 18 loss: [35.77968978881836, 0.6859226226806641]\n",
      "  batch 20 loss: [36.957125663757324, 0.6887915730476379]\n",
      "  batch 22 loss: [38.643367767333984, 0.6965986788272858]\n",
      "  batch 24 loss: [36.47851276397705, 0.72157883644104]\n",
      "  batch 26 loss: [46.40435600280762, 0.6961535513401031]\n",
      "  batch 28 loss: [33.37443923950195, 0.6879826188087463]\n",
      "  batch 30 loss: [32.99234580993652, 0.6882718801498413]\n",
      "  batch 32 loss: [34.90426063537598, 0.6850776672363281]\n",
      "  batch 34 loss: [37.711931228637695, 0.6920074224472046]\n",
      "  batch 36 loss: [34.19761085510254, 0.7014060020446777]\n",
      "  batch 38 loss: [37.5162410736084, 0.6987088918685913]\n",
      "  batch 40 loss: [28.177964210510254, 0.6987577080726624]\n",
      "  batch 42 loss: [34.53554153442383, 0.7285420596599579]\n",
      "  batch 44 loss: [32.49545383453369, 0.6994591653347015]\n",
      "  batch 46 loss: [35.192158699035645, 0.6927260160446167]\n",
      "  batch 48 loss: [39.82976531982422, 0.6906712055206299]\n",
      "  batch 50 loss: [40.21051597595215, 0.6854749321937561]\n",
      "  batch 52 loss: [32.70515537261963, 0.691094309091568]\n",
      "  batch 54 loss: [35.3494291305542, 0.7151130139827728]\n",
      "LOSS generator 35.3494291305542 discriminator 0.7151130139827728\n",
      "EPOCH 4:\n",
      "  batch 0 loss: [36.598812103271484, 0.6997005343437195]\n",
      "  batch 2 loss: [46.93931770324707, 0.6900787353515625]\n",
      "  batch 4 loss: [36.737436294555664, 0.6924903392791748]\n",
      "  batch 6 loss: [27.310976028442383, 0.688433051109314]\n",
      "  batch 8 loss: [45.81546211242676, 0.6862624883651733]\n",
      "  batch 10 loss: [32.71449661254883, 0.6888744533061981]\n",
      "  batch 12 loss: [33.36894607543945, 0.6954463422298431]\n",
      "  batch 14 loss: [31.00035858154297, 0.6976776421070099]\n",
      "  batch 16 loss: [33.52232074737549, 0.6907039880752563]\n",
      "  batch 18 loss: [38.99155616760254, 0.6859252452850342]\n",
      "  batch 20 loss: [30.28627872467041, 0.694698691368103]\n",
      "  batch 22 loss: [34.579731941223145, 0.6984782218933105]\n",
      "  batch 24 loss: [36.533535957336426, 0.6872763633728027]\n",
      "  batch 26 loss: [38.116926193237305, 0.6907787322998047]\n",
      "  batch 28 loss: [41.70753479003906, 0.6837697625160217]\n",
      "  batch 30 loss: [35.20059776306152, 0.6826987564563751]\n",
      "  batch 32 loss: [37.50587844848633, 0.7218013405799866]\n",
      "  batch 34 loss: [36.254438400268555, 0.7389888763427734]\n",
      "  batch 36 loss: [25.80004119873047, 0.6944626867771149]\n",
      "  batch 38 loss: [36.93172836303711, 0.7048427760601044]\n",
      "  batch 40 loss: [38.374820709228516, 0.6873723566532135]\n",
      "  batch 42 loss: [38.40269660949707, 0.6848219633102417]\n",
      "  batch 44 loss: [30.29919147491455, 0.6882640719413757]\n",
      "  batch 46 loss: [34.859703063964844, 0.6886686682701111]\n",
      "  batch 48 loss: [38.1714973449707, 0.6883839666843414]\n",
      "  batch 50 loss: [33.095285415649414, 0.690913200378418]\n",
      "  batch 52 loss: [37.406747817993164, 0.6848864853382111]\n",
      "  batch 54 loss: [33.959662437438965, 0.6719396114349365]\n",
      "LOSS generator 33.959662437438965 discriminator 0.6719396114349365\n",
      "EPOCH 5:\n",
      "  batch 0 loss: [46.8276481628418, 0.6833204030990601]\n",
      "  batch 2 loss: [34.51528739929199, 0.6824639141559601]\n",
      "  batch 4 loss: [38.812652587890625, 0.7009047865867615]\n",
      "  batch 6 loss: [35.04743957519531, 0.7132665514945984]\n",
      "  batch 8 loss: [37.02814292907715, 0.6914344429969788]\n",
      "  batch 10 loss: [41.296987533569336, 0.6902806460857391]\n",
      "  batch 12 loss: [37.025699615478516, 0.6870104670524597]\n",
      "  batch 14 loss: [30.422483444213867, 0.6774120926856995]\n",
      "  batch 16 loss: [30.88021755218506, 0.6881470382213593]\n",
      "  batch 18 loss: [40.307273864746094, 0.6910102069377899]\n",
      "  batch 20 loss: [37.139190673828125, 0.6978548467159271]\n",
      "  batch 22 loss: [34.30836486816406, 0.710667759180069]\n",
      "  batch 24 loss: [35.576863288879395, 0.6988518238067627]\n",
      "  batch 26 loss: [36.10379981994629, 0.6830849647521973]\n",
      "  batch 28 loss: [32.42949104309082, 0.6829439997673035]\n",
      "  batch 30 loss: [39.325788497924805, 0.6936043202877045]\n",
      "  batch 32 loss: [30.733180046081543, 0.6894814670085907]\n",
      "  batch 34 loss: [27.8385591506958, 0.6963599622249603]\n",
      "  batch 36 loss: [39.65255832672119, 0.6789437830448151]\n",
      "  batch 38 loss: [26.3397274017334, 0.6998847126960754]\n",
      "  batch 40 loss: [43.68462944030762, 0.6861128807067871]\n",
      "  batch 42 loss: [37.49648475646973, 0.6804456412792206]\n",
      "  batch 44 loss: [39.71196937561035, 0.6740281581878662]\n",
      "  batch 46 loss: [34.06948947906494, 0.6676401495933533]\n",
      "  batch 48 loss: [42.040910720825195, 0.7077112793922424]\n",
      "  batch 50 loss: [32.42325973510742, 0.7195703089237213]\n",
      "  batch 52 loss: [32.325467109680176, 0.6645034551620483]\n",
      "  batch 54 loss: [30.756142616271973, 0.6831478476524353]\n",
      "LOSS generator 30.756142616271973 discriminator 0.6831478476524353\n",
      "EPOCH 6:\n",
      "  batch 0 loss: [31.988998413085938, 0.7644372582435608]\n",
      "  batch 2 loss: [35.09104919433594, 0.6968116164207458]\n",
      "  batch 4 loss: [37.1483039855957, 0.6831567287445068]\n",
      "  batch 6 loss: [30.33858585357666, 0.6688205003738403]\n",
      "  batch 8 loss: [30.314733505249023, 0.6710363030433655]\n",
      "  batch 10 loss: [40.455121994018555, 0.6763845384120941]\n",
      "  batch 12 loss: [38.44584846496582, 0.6697795987129211]\n",
      "  batch 14 loss: [39.032508850097656, 0.6699053645133972]\n",
      "  batch 16 loss: [35.75024127960205, 0.6600358188152313]\n",
      "  batch 18 loss: [36.25222206115723, 0.6845210194587708]\n",
      "  batch 20 loss: [28.190239906311035, 0.6812984943389893]\n",
      "  batch 22 loss: [36.77536869049072, 0.685249924659729]\n",
      "  batch 24 loss: [35.7540340423584, 0.6940860152244568]\n",
      "  batch 26 loss: [37.19761657714844, 0.6861465573310852]\n",
      "  batch 28 loss: [35.74998188018799, 0.6805411577224731]\n",
      "  batch 30 loss: [29.059731483459473, 0.6705101728439331]\n",
      "  batch 32 loss: [33.96746063232422, 0.6764806509017944]\n",
      "  batch 34 loss: [39.01704978942871, 0.6879169642925262]\n",
      "  batch 36 loss: [34.30185317993164, 0.6808145642280579]\n",
      "  batch 38 loss: [33.613037109375, 0.6721950173377991]\n",
      "  batch 40 loss: [33.949612617492676, 0.6698813438415527]\n",
      "  batch 42 loss: [37.97958946228027, 0.6959428489208221]\n",
      "  batch 44 loss: [30.046213150024414, 0.7702060639858246]\n",
      "  batch 46 loss: [37.578529357910156, 0.7061704993247986]\n",
      "  batch 48 loss: [41.28917694091797, 0.6837280988693237]\n",
      "  batch 50 loss: [41.74761199951172, 0.684219241142273]\n",
      "  batch 52 loss: [43.215999603271484, 0.6763660907745361]\n",
      "  batch 54 loss: [34.32957649230957, 0.6765570640563965]\n",
      "LOSS generator 34.32957649230957 discriminator 0.6765570640563965\n",
      "EPOCH 7:\n",
      "  batch 0 loss: [29.75121307373047, 0.6669908761978149]\n",
      "  batch 2 loss: [37.7357702255249, 0.681182324886322]\n",
      "  batch 4 loss: [32.37657642364502, 0.7103978991508484]\n",
      "  batch 6 loss: [43.17970848083496, 0.6899902820587158]\n",
      "  batch 8 loss: [43.47088813781738, 0.6766848862171173]\n",
      "  batch 10 loss: [27.817614555358887, 0.6694081723690033]\n",
      "  batch 12 loss: [37.113603591918945, 0.6744938492774963]\n",
      "  batch 14 loss: [36.519962310791016, 0.6679307520389557]\n",
      "  batch 16 loss: [37.11963653564453, 0.6840468347072601]\n",
      "  batch 18 loss: [35.02299976348877, 0.715047299861908]\n",
      "  batch 20 loss: [41.7415828704834, 0.6863597929477692]\n",
      "  batch 22 loss: [27.000980377197266, 0.6852293014526367]\n",
      "  batch 24 loss: [36.07408332824707, 0.6820699572563171]\n",
      "  batch 26 loss: [32.01113510131836, 0.6814370155334473]\n",
      "  batch 28 loss: [42.45223808288574, 0.6870119571685791]\n",
      "  batch 30 loss: [28.227962493896484, 0.6771045625209808]\n",
      "  batch 32 loss: [41.34242916107178, 0.6910495460033417]\n",
      "  batch 34 loss: [39.64038848876953, 0.6885998845100403]\n",
      "  batch 36 loss: [38.97268486022949, 0.6790403723716736]\n",
      "  batch 38 loss: [36.104857444763184, 0.6910172700881958]\n",
      "  batch 40 loss: [30.09943675994873, 0.6868869662284851]\n",
      "  batch 42 loss: [33.04687786102295, 0.6838195025920868]\n",
      "  batch 44 loss: [29.528850555419922, 0.6760574877262115]\n",
      "  batch 46 loss: [31.66855525970459, 0.6781215667724609]\n",
      "  batch 48 loss: [45.67527770996094, 0.704186201095581]\n",
      "  batch 50 loss: [31.221394538879395, 0.6842492818832397]\n",
      "  batch 52 loss: [34.94464683532715, 0.6789544820785522]\n",
      "  batch 54 loss: [35.70677375793457, 0.6797860264778137]\n",
      "LOSS generator 35.70677375793457 discriminator 0.6797860264778137\n",
      "EPOCH 8:\n",
      "  batch 0 loss: [37.73833465576172, 0.6587634086608887]\n",
      "  batch 2 loss: [27.881282806396484, 0.6649503111839294]\n",
      "  batch 4 loss: [37.171613693237305, 0.6886795461177826]\n",
      "  batch 6 loss: [47.208834648132324, 0.7207976877689362]\n",
      "  batch 8 loss: [37.81195259094238, 0.6875752806663513]\n",
      "  batch 10 loss: [45.225515365600586, 0.6766589283943176]\n",
      "  batch 12 loss: [32.02980327606201, 0.6635328233242035]\n",
      "  batch 14 loss: [27.87712574005127, 0.7136400938034058]\n",
      "  batch 16 loss: [36.00079536437988, 0.6891745924949646]\n",
      "  batch 18 loss: [30.043545722961426, 0.6663523018360138]\n",
      "  batch 20 loss: [31.897067070007324, 0.6585196256637573]\n",
      "  batch 22 loss: [36.61385154724121, 0.692553699016571]\n",
      "  batch 24 loss: [32.31595039367676, 0.778499037027359]\n",
      "  batch 26 loss: [37.53947448730469, 0.677483469247818]\n",
      "  batch 28 loss: [33.740044593811035, 0.6591764986515045]\n",
      "  batch 30 loss: [45.53494071960449, 0.6559309661388397]\n",
      "  batch 32 loss: [37.471967697143555, 0.6463792026042938]\n",
      "  batch 34 loss: [43.0509033203125, 0.6388552188873291]\n",
      "  batch 36 loss: [28.79824161529541, 0.623910665512085]\n",
      "  batch 38 loss: [32.86863708496094, 0.6318983733654022]\n",
      "  batch 40 loss: [39.33225917816162, 0.6680903434753418]\n",
      "  batch 42 loss: [27.295333862304688, 0.6518400609493256]\n",
      "  batch 44 loss: [40.86013889312744, 0.6504063308238983]\n",
      "  batch 46 loss: [26.600879669189453, 0.6092453002929688]\n",
      "  batch 48 loss: [34.25130271911621, 0.6226658523082733]\n",
      "  batch 50 loss: [40.1742057800293, 0.7359451353549957]\n",
      "  batch 52 loss: [35.89684867858887, 0.6842765510082245]\n",
      "  batch 54 loss: [36.71998691558838, 0.6681099832057953]\n",
      "LOSS generator 36.71998691558838 discriminator 0.6681099832057953\n",
      "EPOCH 9:\n",
      "  batch 0 loss: [27.313684463500977, 0.6613596677780151]\n",
      "  batch 2 loss: [36.94583702087402, 0.6377964913845062]\n",
      "  batch 4 loss: [51.99357986450195, 0.6625077128410339]\n",
      "  batch 6 loss: [39.356061935424805, 0.6272315680980682]\n",
      "  batch 8 loss: [39.17953395843506, 0.6271841824054718]\n",
      "  batch 10 loss: [42.15820503234863, 0.6238217055797577]\n",
      "  batch 12 loss: [29.491239547729492, 0.6005875766277313]\n",
      "  batch 14 loss: [38.32210159301758, 0.6025751531124115]\n",
      "  batch 16 loss: [38.1657657623291, 0.6092555522918701]\n",
      "  batch 18 loss: [32.74802494049072, 0.5982907116413116]\n",
      "  batch 20 loss: [28.176644325256348, 0.6373984813690186]\n",
      "  batch 22 loss: [35.29101371765137, 0.6479359269142151]\n",
      "  batch 24 loss: [27.99784755706787, 0.6528699398040771]\n",
      "  batch 26 loss: [41.96858310699463, 0.6989913582801819]\n",
      "  batch 28 loss: [40.90152359008789, 0.6628459692001343]\n",
      "  batch 30 loss: [38.29213523864746, 0.593109667301178]\n",
      "  batch 32 loss: [30.883028030395508, 0.5735484957695007]\n",
      "  batch 34 loss: [30.364805221557617, 0.6340510249137878]\n",
      "  batch 36 loss: [35.606698989868164, 0.6183918416500092]\n",
      "  batch 38 loss: [33.741031646728516, 0.6079621613025665]\n",
      "  batch 40 loss: [35.7085485458374, 0.5503482222557068]\n",
      "  batch 42 loss: [41.26592445373535, 0.5748946070671082]\n",
      "  batch 44 loss: [33.42597484588623, 0.5546957552433014]\n",
      "  batch 46 loss: [35.983638763427734, 0.5298256576061249]\n",
      "  batch 48 loss: [28.804616928100586, 0.5382660627365112]\n",
      "  batch 50 loss: [30.654099464416504, 0.6631198525428772]\n",
      "  batch 52 loss: [30.672667503356934, 0.6141760349273682]\n",
      "  batch 54 loss: [39.34548377990723, 0.6270671486854553]\n",
      "LOSS generator 39.34548377990723 discriminator 0.6270671486854553\n",
      "EPOCH 10:\n",
      "  batch 0 loss: [31.06258773803711, 0.68887859582901]\n",
      "  batch 2 loss: [32.54545211791992, 0.6785106956958771]\n",
      "  batch 4 loss: [32.04653549194336, 0.6065431237220764]\n",
      "  batch 6 loss: [29.925538063049316, 0.6439895033836365]\n",
      "  batch 8 loss: [42.623491287231445, 0.7559743821620941]\n",
      "  batch 10 loss: [34.81316661834717, 0.6543430685997009]\n",
      "  batch 12 loss: [30.62503433227539, 0.6572692692279816]\n",
      "  batch 14 loss: [28.435364723205566, 0.6253150701522827]\n",
      "  batch 16 loss: [41.69355010986328, 0.667966216802597]\n",
      "  batch 18 loss: [40.71454429626465, 0.5994271039962769]\n",
      "  batch 20 loss: [38.555999755859375, 0.5179612338542938]\n",
      "  batch 22 loss: [40.53237342834473, 0.5263398289680481]\n",
      "  batch 24 loss: [32.996686935424805, 0.5738330483436584]\n",
      "  batch 26 loss: [43.51653480529785, 0.6443756222724915]\n",
      "  batch 28 loss: [34.53738498687744, 0.586791455745697]\n",
      "  batch 30 loss: [39.53803062438965, 0.5862429738044739]\n",
      "  batch 32 loss: [32.12632751464844, 0.630274087190628]\n",
      "  batch 34 loss: [34.361894607543945, 0.6973879039287567]\n",
      "  batch 36 loss: [32.912940979003906, 0.6486096978187561]\n",
      "  batch 38 loss: [31.834242820739746, 0.6014194488525391]\n",
      "  batch 40 loss: [27.862845420837402, 0.5871858894824982]\n",
      "  batch 42 loss: [37.0118465423584, 0.6456164121627808]\n",
      "  batch 44 loss: [29.72810459136963, 0.5792902112007141]\n",
      "  batch 46 loss: [47.869537353515625, 0.7374119460582733]\n",
      "  batch 48 loss: [30.67375087738037, 0.7187983989715576]\n",
      "  batch 50 loss: [39.61792755126953, 0.6382249891757965]\n",
      "  batch 52 loss: [40.23542022705078, 0.5925692021846771]\n",
      "  batch 54 loss: [37.86201000213623, 0.5838560163974762]\n",
      "LOSS generator 37.86201000213623 discriminator 0.5838560163974762\n",
      "EPOCH 11:\n",
      "  batch 0 loss: [30.824575424194336, 0.5284928679466248]\n",
      "  batch 2 loss: [36.64103889465332, 0.6383035480976105]\n",
      "  batch 4 loss: [41.42951202392578, 0.6600721478462219]\n",
      "  batch 6 loss: [30.62851905822754, 0.6103363633155823]\n",
      "  batch 8 loss: [42.51762008666992, 0.5776108503341675]\n",
      "  batch 10 loss: [31.42741870880127, 0.5559044778347015]\n",
      "  batch 12 loss: [27.70753002166748, 0.5226281881332397]\n",
      "  batch 14 loss: [33.80134963989258, 0.519428014755249]\n",
      "  batch 16 loss: [31.46977710723877, 0.4409708082675934]\n",
      "  batch 18 loss: [40.42240333557129, 0.4845825284719467]\n",
      "  batch 20 loss: [26.896467208862305, 0.4731559604406357]\n",
      "  batch 22 loss: [35.68574047088623, 0.6458550095558167]\n",
      "  batch 24 loss: [41.15210723876953, 0.5225425362586975]\n",
      "  batch 26 loss: [36.064727783203125, 0.5070499032735825]\n",
      "  batch 28 loss: [36.693867683410645, 0.5922475159168243]\n",
      "  batch 30 loss: [33.32152843475342, 0.5451443493366241]\n",
      "  batch 32 loss: [36.99455738067627, 0.6202565729618073]\n",
      "  batch 34 loss: [35.72175979614258, 0.508405864238739]\n",
      "  batch 36 loss: [35.89513397216797, 0.49412593245506287]\n",
      "  batch 38 loss: [36.15433883666992, 0.5510943531990051]\n",
      "  batch 40 loss: [36.86343193054199, 0.4869636297225952]\n",
      "  batch 42 loss: [35.3862361907959, 0.4254126697778702]\n",
      "  batch 44 loss: [33.24843120574951, 0.4922718405723572]\n",
      "  batch 46 loss: [39.55277061462402, 0.6272551417350769]\n",
      "  batch 48 loss: [45.825767517089844, 0.6050251722335815]\n",
      "  batch 50 loss: [34.81870079040527, 0.4358222335577011]\n",
      "  batch 52 loss: [32.849992752075195, 0.38795478641986847]\n",
      "  batch 54 loss: [40.2750186920166, 0.5905748605728149]\n",
      "LOSS generator 40.2750186920166 discriminator 0.5905748605728149\n",
      "EPOCH 12:\n",
      "  batch 0 loss: [43.67548751831055, 0.6889342069625854]\n",
      "  batch 2 loss: [38.42406463623047, 0.6038578748703003]\n",
      "  batch 4 loss: [33.06681823730469, 0.4410296827554703]\n",
      "  batch 6 loss: [36.45357131958008, 0.5705232918262482]\n",
      "  batch 8 loss: [41.878828048706055, 0.48390059173107147]\n",
      "  batch 10 loss: [41.97924995422363, 0.5062553137540817]\n",
      "  batch 12 loss: [34.39970302581787, 0.3992564380168915]\n",
      "  batch 14 loss: [33.284799575805664, 0.38148388266563416]\n",
      "  batch 16 loss: [28.688364028930664, 0.3494876027107239]\n",
      "  batch 18 loss: [28.901845932006836, 0.4307185709476471]\n",
      "  batch 20 loss: [31.689078330993652, 0.327901229262352]\n",
      "  batch 22 loss: [35.892921447753906, 0.6855794489383698]\n",
      "  batch 24 loss: [30.79241180419922, 0.5090955197811127]\n",
      "  batch 26 loss: [42.19477844238281, 0.5333805680274963]\n",
      "  batch 28 loss: [31.471882820129395, 0.3782976120710373]\n",
      "  batch 30 loss: [39.30561828613281, 0.3693801015615463]\n",
      "  batch 32 loss: [34.97325801849365, 0.3681342601776123]\n",
      "  batch 34 loss: [36.351263999938965, 0.3372231721878052]\n",
      "  batch 36 loss: [40.58923530578613, 0.39170190691947937]\n",
      "  batch 38 loss: [33.58390808105469, 0.41792958974838257]\n",
      "  batch 40 loss: [34.218326568603516, 0.37826991081237793]\n",
      "  batch 42 loss: [32.1804723739624, 0.2757411301136017]\n",
      "  batch 44 loss: [34.265878677368164, 0.36158332228660583]\n",
      "  batch 46 loss: [44.06382751464844, 0.38663890957832336]\n",
      "  batch 48 loss: [37.15875244140625, 0.3787571042776108]\n",
      "  batch 50 loss: [31.204113960266113, 0.36804555356502533]\n",
      "  batch 52 loss: [36.17976665496826, 0.5801799595355988]\n",
      "  batch 54 loss: [38.1832332611084, 0.4134182184934616]\n",
      "LOSS generator 38.1832332611084 discriminator 0.4134182184934616\n",
      "EPOCH 13:\n",
      "  batch 0 loss: [33.81410598754883, 0.3318992853164673]\n",
      "  batch 2 loss: [41.16487503051758, 0.3959469497203827]\n",
      "  batch 4 loss: [38.29116249084473, 0.3888266086578369]\n",
      "  batch 6 loss: [36.83774185180664, 0.4121840000152588]\n",
      "  batch 8 loss: [32.446664810180664, 0.38651424646377563]\n",
      "  batch 10 loss: [33.227439880371094, 0.3742845952510834]\n",
      "  batch 12 loss: [41.26101207733154, 0.46892616152763367]\n",
      "  batch 14 loss: [30.125240325927734, 0.35890232026576996]\n",
      "  batch 16 loss: [34.55586051940918, 0.46901996433734894]\n",
      "  batch 18 loss: [40.540767669677734, 0.4114619493484497]\n",
      "  batch 20 loss: [31.65084934234619, 0.2997125834226608]\n",
      "  batch 22 loss: [35.61437702178955, 0.4536151885986328]\n",
      "  batch 24 loss: [44.5696964263916, 0.44383344054222107]\n",
      "  batch 26 loss: [33.92835807800293, 0.49176327884197235]\n",
      "  batch 28 loss: [35.23959541320801, 0.34861335158348083]\n",
      "  batch 30 loss: [35.172000885009766, 0.29479508101940155]\n",
      "  batch 32 loss: [41.86048126220703, 0.4232805669307709]\n",
      "  batch 34 loss: [33.216673851013184, 0.3601149320602417]\n",
      "  batch 36 loss: [36.494741439819336, 0.3667648285627365]\n",
      "  batch 38 loss: [35.271982192993164, 0.3141332045197487]\n",
      "  batch 40 loss: [45.2878532409668, 0.42121705412864685]\n",
      "  batch 42 loss: [28.71202278137207, 0.26277631521224976]\n",
      "  batch 44 loss: [32.813530921936035, 0.2645014226436615]\n",
      "  batch 46 loss: [41.060909271240234, 0.4373202323913574]\n",
      "  batch 48 loss: [37.651227951049805, 0.38309071958065033]\n",
      "  batch 50 loss: [40.39339637756348, 0.44242921471595764]\n",
      "  batch 52 loss: [30.105277061462402, 0.3503188192844391]\n",
      "  batch 54 loss: [33.753376960754395, 0.6873357594013214]\n",
      "LOSS generator 33.753376960754395 discriminator 0.6873357594013214\n",
      "EPOCH 14:\n",
      "  batch 0 loss: [41.189056396484375, 0.7802261114120483]\n",
      "  batch 2 loss: [36.21271324157715, 0.7299702763557434]\n",
      "  batch 4 loss: [33.420806884765625, 0.6235197484493256]\n",
      "  batch 6 loss: [30.617172241210938, 0.5198032259941101]\n",
      "  batch 8 loss: [35.270073890686035, 0.4955754280090332]\n",
      "  batch 10 loss: [37.9461669921875, 0.6134664565324783]\n",
      "  batch 12 loss: [32.38715648651123, 0.5625625550746918]\n",
      "  batch 14 loss: [47.6390266418457, 0.5121926069259644]\n",
      "  batch 16 loss: [35.628108978271484, 0.28237518668174744]\n",
      "  batch 18 loss: [35.84650421142578, 0.24277852475643158]\n",
      "  batch 20 loss: [38.63991165161133, 0.380203016102314]\n",
      "  batch 22 loss: [39.50634002685547, 0.28178858757019043]\n",
      "  batch 24 loss: [36.55244827270508, 0.24413330107927322]\n",
      "  batch 26 loss: [39.10238265991211, 0.41757984459400177]\n",
      "  batch 28 loss: [35.7364559173584, 0.3976443260908127]\n",
      "  batch 30 loss: [43.09399223327637, 0.5120910406112671]\n",
      "  batch 32 loss: [44.97678565979004, 0.3167993128299713]\n",
      "  batch 34 loss: [34.554715156555176, 0.3335086703300476]\n",
      "  batch 36 loss: [32.28194332122803, 0.26885294914245605]\n",
      "  batch 38 loss: [38.898237228393555, 0.3179090544581413]\n",
      "  batch 40 loss: [29.480250358581543, 0.2883135676383972]\n",
      "  batch 42 loss: [35.99788856506348, 0.18585972487926483]\n",
      "  batch 44 loss: [28.18514919281006, 0.233108788728714]\n",
      "  batch 46 loss: [38.659799575805664, 0.3101465553045273]\n",
      "  batch 48 loss: [35.21534061431885, 0.38808175921440125]\n",
      "  batch 50 loss: [35.21133995056152, 0.3663438856601715]\n",
      "  batch 52 loss: [35.12190818786621, 0.2981617748737335]\n",
      "  batch 54 loss: [34.30062294006348, 0.20048239827156067]\n",
      "LOSS generator 34.30062294006348 discriminator 0.20048239827156067\n",
      "EPOCH 15:\n",
      "  batch 0 loss: [38.50230026245117, 0.3072870075702667]\n",
      "  batch 2 loss: [35.14365577697754, 0.17247268557548523]\n",
      "  batch 4 loss: [41.30999565124512, 0.30620427429676056]\n",
      "  batch 6 loss: [35.450042724609375, 0.2847997397184372]\n",
      "  batch 8 loss: [34.696550369262695, 0.31395169347524643]\n",
      "  batch 10 loss: [34.046085357666016, 0.2565221041440964]\n",
      "  batch 12 loss: [27.895112991333008, 0.22155702114105225]\n",
      "  batch 14 loss: [40.454267501831055, 0.2691050320863724]\n",
      "  batch 16 loss: [33.98543357849121, 0.25217659026384354]\n",
      "  batch 18 loss: [34.60104942321777, 0.2482222616672516]\n",
      "  batch 20 loss: [45.16416931152344, 0.2763700485229492]\n",
      "  batch 22 loss: [42.40267753601074, 0.34793800860643387]\n",
      "  batch 24 loss: [38.70503234863281, 0.2304515317082405]\n",
      "  batch 26 loss: [39.849313735961914, 0.2563416510820389]\n",
      "  batch 28 loss: [32.96329879760742, 0.32895809412002563]\n",
      "  batch 30 loss: [38.67953300476074, 0.24724413454532623]\n",
      "  batch 32 loss: [36.75698661804199, 0.11839508637785912]\n",
      "  batch 34 loss: [39.295352935791016, 0.12661972641944885]\n",
      "  batch 36 loss: [34.57223892211914, 0.27917705476284027]\n",
      "  batch 38 loss: [38.24141502380371, 0.2823067307472229]\n",
      "  batch 40 loss: [38.53652381896973, 0.17522794753313065]\n",
      "  batch 42 loss: [40.33677291870117, 0.23845406621694565]\n",
      "  batch 44 loss: [34.37296676635742, 0.21984711289405823]\n",
      "  batch 46 loss: [35.27387809753418, 0.21761629730463028]\n",
      "  batch 48 loss: [34.41128158569336, 0.15776517987251282]\n",
      "  batch 50 loss: [29.573122024536133, 0.16812814027071]\n",
      "  batch 52 loss: [33.178025245666504, 0.1407727673649788]\n",
      "  batch 54 loss: [37.3830509185791, 0.2805331200361252]\n",
      "LOSS generator 37.3830509185791 discriminator 0.2805331200361252\n",
      "EPOCH 16:\n",
      "  batch 0 loss: [33.42011642456055, 0.16531258821487427]\n",
      "  batch 2 loss: [35.247742652893066, 0.2224552258849144]\n",
      "  batch 4 loss: [35.15236568450928, 0.23654204607009888]\n",
      "  batch 6 loss: [36.03350067138672, 0.13005290925502777]\n",
      "  batch 8 loss: [28.84231948852539, 0.17722586542367935]\n",
      "  batch 10 loss: [38.01287651062012, 0.23274049162864685]\n",
      "  batch 12 loss: [37.75054359436035, 0.3595465123653412]\n",
      "  batch 14 loss: [38.03595733642578, 0.28306353092193604]\n",
      "  batch 16 loss: [38.198296546936035, 0.19885876029729843]\n",
      "  batch 18 loss: [44.74796676635742, 0.26835349202156067]\n",
      "  batch 20 loss: [24.502516746520996, 0.17485786974430084]\n",
      "  batch 22 loss: [48.542585372924805, 0.5417990684509277]\n",
      "  batch 24 loss: [33.33342933654785, 0.12458265200257301]\n",
      "  batch 26 loss: [37.08595657348633, 0.19796062260866165]\n",
      "  batch 28 loss: [39.32615661621094, 0.161297757178545]\n",
      "  batch 30 loss: [30.32682228088379, 0.12836680561304092]\n",
      "  batch 32 loss: [42.841604232788086, 0.24984564632177353]\n",
      "  batch 34 loss: [29.11306095123291, 0.13891984522342682]\n",
      "  batch 36 loss: [41.81030082702637, 0.26500897109508514]\n",
      "  batch 38 loss: [27.856342315673828, 0.3869050145149231]\n",
      "  batch 40 loss: [37.39990711212158, 0.5028964281082153]\n",
      "  batch 42 loss: [41.27345085144043, 0.5794236958026886]\n",
      "  batch 44 loss: [40.07121658325195, 0.39082615077495575]\n",
      "  batch 46 loss: [32.8015079498291, 0.5684838891029358]\n",
      "  batch 48 loss: [45.06821250915527, 0.44668203592300415]\n",
      "  batch 50 loss: [34.562180519104004, 0.34944459795951843]\n",
      "  batch 52 loss: [36.13564491271973, 0.36204124987125397]\n",
      "  batch 54 loss: [32.76445293426514, 0.3764741122722626]\n",
      "LOSS generator 32.76445293426514 discriminator 0.3764741122722626\n",
      "EPOCH 17:\n",
      "  batch 0 loss: [38.179656982421875, 0.4155084788799286]\n",
      "  batch 2 loss: [35.97020149230957, 0.4272359758615494]\n",
      "  batch 4 loss: [37.409278869628906, 0.3643284738063812]\n",
      "  batch 6 loss: [39.53512954711914, 0.46132051944732666]\n",
      "  batch 8 loss: [33.159109115600586, 0.3732335865497589]\n",
      "  batch 10 loss: [39.10026168823242, 0.4284212291240692]\n",
      "  batch 12 loss: [41.26127052307129, 0.4401071071624756]\n",
      "  batch 14 loss: [33.3747444152832, 0.32565639913082123]\n",
      "  batch 16 loss: [28.4332275390625, 0.2742040306329727]\n",
      "  batch 18 loss: [41.394248962402344, 0.4066484868526459]\n",
      "  batch 20 loss: [34.633554458618164, 0.31316307187080383]\n",
      "  batch 22 loss: [36.10822296142578, 0.1564972922205925]\n",
      "  batch 24 loss: [28.73147678375244, 0.208890862762928]\n",
      "  batch 26 loss: [39.19952583312988, 0.31772297620773315]\n",
      "  batch 28 loss: [26.16446590423584, 0.23918887972831726]\n",
      "  batch 30 loss: [44.42337989807129, 0.4103702902793884]\n",
      "  batch 32 loss: [33.62811279296875, 0.36846157908439636]\n",
      "  batch 34 loss: [37.33562660217285, 0.2732592970132828]\n",
      "  batch 36 loss: [33.87343120574951, 0.19873236864805222]\n",
      "  batch 38 loss: [39.86330795288086, 0.34111106395721436]\n",
      "  batch 40 loss: [31.755541801452637, 0.2296721190214157]\n",
      "  batch 42 loss: [37.394161224365234, 0.15532952547073364]\n",
      "  batch 44 loss: [33.02260494232178, 0.46846215426921844]\n",
      "  batch 46 loss: [34.95359420776367, 0.27428194135427475]\n",
      "  batch 48 loss: [39.26838207244873, 0.5335805863142014]\n",
      "  batch 50 loss: [40.74379348754883, 0.4791424870491028]\n",
      "  batch 52 loss: [41.0257568359375, 0.42477354407310486]\n",
      "  batch 54 loss: [40.43598556518555, 0.5501541495323181]\n",
      "LOSS generator 40.43598556518555 discriminator 0.5501541495323181\n",
      "EPOCH 18:\n",
      "  batch 0 loss: [43.254085540771484, 0.5519716739654541]\n",
      "  batch 2 loss: [32.25181007385254, 0.23918962478637695]\n",
      "  batch 4 loss: [34.00985527038574, 0.16477751731872559]\n",
      "  batch 6 loss: [36.111202239990234, 0.3133206441998482]\n",
      "  batch 8 loss: [39.00610542297363, 0.2133987359702587]\n",
      "  batch 10 loss: [32.24410533905029, 0.18751820921897888]\n",
      "  batch 12 loss: [36.19206237792969, 0.11384330689907074]\n",
      "  batch 14 loss: [31.220569610595703, 0.10152505338191986]\n",
      "  batch 16 loss: [38.02381134033203, 0.1619747430086136]\n",
      "  batch 18 loss: [47.8632869720459, 0.40871670842170715]\n",
      "  batch 20 loss: [41.88676834106445, 0.2457180917263031]\n",
      "  batch 22 loss: [38.863463401794434, 0.23302339017391205]\n",
      "  batch 24 loss: [38.77115821838379, 0.1857794001698494]\n",
      "  batch 26 loss: [43.17341232299805, 0.2696335166692734]\n",
      "  batch 28 loss: [35.037588119506836, 0.2180388644337654]\n",
      "  batch 30 loss: [36.18233299255371, 0.21419331058859825]\n",
      "  batch 32 loss: [37.05765151977539, 0.09896589815616608]\n",
      "  batch 34 loss: [31.542613983154297, 0.12033898383378983]\n",
      "  batch 36 loss: [36.53404235839844, 0.22917141020298004]\n",
      "  batch 38 loss: [41.089202880859375, 0.24257276952266693]\n",
      "  batch 40 loss: [30.664206504821777, 0.3118034452199936]\n",
      "  batch 42 loss: [33.04838562011719, 0.17214372009038925]\n",
      "  batch 44 loss: [33.11172294616699, 0.3517044857144356]\n",
      "  batch 46 loss: [48.45619010925293, 0.7018958926200867]\n",
      "  batch 48 loss: [35.6135311126709, 0.27504295855760574]\n",
      "  batch 50 loss: [32.39677619934082, 0.3207063525915146]\n",
      "  batch 52 loss: [35.95841407775879, 0.23098132014274597]\n",
      "  batch 54 loss: [36.32956886291504, 0.12184170633554459]\n",
      "LOSS generator 36.32956886291504 discriminator 0.12184170633554459\n",
      "EPOCH 19:\n",
      "  batch 0 loss: [38.87740707397461, 0.09280237555503845]\n",
      "  batch 2 loss: [31.80015468597412, 0.21158812940120697]\n",
      "  batch 4 loss: [39.47833061218262, 0.19043773040175438]\n",
      "  batch 6 loss: [32.78880023956299, 0.10640506073832512]\n",
      "  batch 8 loss: [30.601426124572754, 0.1429680809378624]\n",
      "  batch 10 loss: [48.062082290649414, 0.4134235084056854]\n",
      "  batch 12 loss: [39.84770965576172, 0.2467554435133934]\n",
      "  batch 14 loss: [46.93729019165039, 0.3133450448513031]\n",
      "  batch 16 loss: [44.01873970031738, 0.1859961673617363]\n",
      "  batch 18 loss: [41.0781192779541, 0.2059735655784607]\n",
      "  batch 20 loss: [30.838767051696777, 0.10711310431361198]\n",
      "  batch 22 loss: [40.59881401062012, 0.29887787252664566]\n",
      "  batch 24 loss: [31.853508949279785, 0.17041772603988647]\n",
      "  batch 26 loss: [32.15627956390381, 0.15451275557279587]\n",
      "  batch 28 loss: [31.142252922058105, 0.21671881526708603]\n",
      "  batch 30 loss: [34.05377006530762, 0.19444448500871658]\n",
      "  batch 32 loss: [37.8582649230957, 0.16756312549114227]\n",
      "  batch 34 loss: [40.10276222229004, 0.25195086747407913]\n",
      "  batch 36 loss: [32.80103588104248, 0.14639372378587723]\n",
      "  batch 38 loss: [42.40398693084717, 0.2446346879005432]\n",
      "  batch 40 loss: [38.77449607849121, 0.12400832027196884]\n",
      "  batch 42 loss: [43.17634391784668, 0.12916512787342072]\n",
      "  batch 44 loss: [39.3682804107666, 0.06370947510004044]\n",
      "  batch 46 loss: [35.03237724304199, 0.21388643234968185]\n",
      "  batch 48 loss: [36.19325256347656, 0.19147533923387527]\n",
      "  batch 50 loss: [36.37797832489014, 0.17013989761471748]\n",
      "  batch 52 loss: [33.57758808135986, 0.08630831725895405]\n",
      "  batch 54 loss: [33.61198139190674, 0.06776387616991997]\n",
      "LOSS generator 33.61198139190674 discriminator 0.06776387616991997\n",
      "EPOCH 20:\n",
      "  batch 0 loss: [38.797035217285156, 0.20234356820583344]\n",
      "  batch 2 loss: [37.87103843688965, 0.17909914255142212]\n",
      "  batch 4 loss: [34.396738052368164, 0.1546628326177597]\n",
      "  batch 6 loss: [35.0992431640625, 0.07057780027389526]\n",
      "  batch 8 loss: [43.08056831359863, 0.16467279195785522]\n",
      "  batch 10 loss: [41.067111015319824, 0.2219240739941597]\n",
      "  batch 12 loss: [32.22597599029541, 0.08654912561178207]\n",
      "  batch 14 loss: [36.63521671295166, 0.21116449683904648]\n",
      "  batch 16 loss: [41.199100494384766, 0.18553703278303146]\n",
      "  batch 18 loss: [32.80414390563965, 0.18455377221107483]\n",
      "  batch 20 loss: [30.47606658935547, 0.13020749390125275]\n",
      "  batch 22 loss: [36.032793045043945, 0.22320128977298737]\n",
      "  batch 24 loss: [40.1893310546875, 0.16213442385196686]\n",
      "  batch 26 loss: [37.8924503326416, 0.2042660340666771]\n",
      "  batch 28 loss: [31.35799217224121, 0.15253259241580963]\n",
      "  batch 30 loss: [33.197421073913574, 0.1368001103401184]\n",
      "  batch 32 loss: [36.152587890625, 0.21630047261714935]\n",
      "  batch 34 loss: [35.17309761047363, 0.21142497658729553]\n",
      "  batch 36 loss: [39.72050857543945, 0.136915385723114]\n",
      "  batch 38 loss: [45.21671676635742, 0.4646473824977875]\n",
      "  batch 40 loss: [44.22282791137695, 0.28307434171438217]\n",
      "  batch 42 loss: [35.67886924743652, 0.10697951540350914]\n",
      "  batch 44 loss: [34.83791542053223, 0.08625937439501286]\n",
      "  batch 46 loss: [32.157814025878906, 0.2965843975543976]\n",
      "  batch 48 loss: [43.62858581542969, 0.2773582488298416]\n",
      "  batch 50 loss: [40.88582992553711, 0.18045096844434738]\n",
      "  batch 52 loss: [40.00846481323242, 0.17538563907146454]\n",
      "  batch 54 loss: [35.68162155151367, 0.12376030161976814]\n",
      "LOSS generator 35.68162155151367 discriminator 0.12376030161976814\n",
      "EPOCH 21:\n",
      "  batch 0 loss: [43.53138732910156, 0.35284581780433655]\n",
      "  batch 2 loss: [39.252450942993164, 0.11638803035020828]\n",
      "  batch 4 loss: [36.50016784667969, 0.05727456137537956]\n",
      "  batch 6 loss: [42.262203216552734, 0.30392786860466003]\n",
      "  batch 8 loss: [38.52529239654541, 0.13331232219934464]\n",
      "  batch 10 loss: [36.44477844238281, 0.06728828325867653]\n",
      "  batch 12 loss: [45.17043876647949, 0.26117371022701263]\n",
      "  batch 14 loss: [32.00666522979736, 0.21797961741685867]\n",
      "  batch 16 loss: [34.42986297607422, 0.11157004907727242]\n",
      "  batch 18 loss: [41.702653884887695, 0.15660476684570312]\n",
      "  batch 20 loss: [32.2106990814209, 0.09444442391395569]\n",
      "  batch 22 loss: [42.5543270111084, 0.31309081614017487]\n",
      "  batch 24 loss: [34.30554676055908, 0.2398761287331581]\n",
      "  batch 26 loss: [45.32243728637695, 0.3943939507007599]\n",
      "  batch 28 loss: [34.50733947753906, 0.4709067642688751]\n",
      "  batch 30 loss: [34.16170120239258, 0.3972318470478058]\n",
      "  batch 32 loss: [40.04416275024414, 0.1791159212589264]\n",
      "  batch 34 loss: [30.368682861328125, 0.17311560362577438]\n",
      "  batch 36 loss: [33.10801124572754, 0.1460552141070366]\n",
      "  batch 38 loss: [35.68228054046631, 0.20451140403747559]\n",
      "  batch 40 loss: [34.629913330078125, 0.10923290997743607]\n",
      "  batch 42 loss: [45.110713958740234, 0.21704261004924774]\n",
      "  batch 44 loss: [39.117156982421875, 0.10922473296523094]\n",
      "  batch 46 loss: [31.798322677612305, 0.0805850401520729]\n",
      "  batch 48 loss: [31.169164657592773, 0.06430112943053246]\n",
      "  batch 50 loss: [40.855770111083984, 0.1847006008028984]\n",
      "  batch 52 loss: [30.843351364135742, 0.14453695714473724]\n",
      "  batch 54 loss: [47.870216369628906, 0.2277003973722458]\n",
      "LOSS generator 47.870216369628906 discriminator 0.2277003973722458\n",
      "EPOCH 22:\n",
      "  batch 0 loss: [31.383060455322266, 0.10174471139907837]\n",
      "  batch 2 loss: [31.613191604614258, 0.1739581637084484]\n",
      "  batch 4 loss: [40.86933898925781, 0.1705034114420414]\n",
      "  batch 6 loss: [38.00195503234863, 0.14166376739740372]\n",
      "  batch 8 loss: [39.994842529296875, 0.18382570147514343]\n",
      "  batch 10 loss: [43.332679748535156, 0.20216787606477737]\n",
      "  batch 12 loss: [40.92780876159668, 0.16008297353982925]\n",
      "  batch 14 loss: [36.57140254974365, 0.23562267422676086]\n",
      "  batch 16 loss: [37.54730033874512, 0.18319377303123474]\n",
      "  batch 18 loss: [36.33590030670166, 0.16039451956748962]\n",
      "  batch 20 loss: [36.27465057373047, 0.14829262346029282]\n",
      "  batch 22 loss: [34.96990203857422, 0.08597977459430695]\n",
      "  batch 24 loss: [37.12078666687012, 0.15089906007051468]\n",
      "  batch 26 loss: [44.217668533325195, 0.21212776005268097]\n",
      "  batch 28 loss: [38.25663375854492, 0.12488988786935806]\n",
      "  batch 30 loss: [36.01623249053955, 0.11969815567135811]\n",
      "  batch 32 loss: [35.871131896972656, 0.22520694136619568]\n",
      "  batch 34 loss: [41.746559143066406, 0.15055249631404877]\n",
      "  batch 36 loss: [35.87322807312012, 0.23344551026821136]\n",
      "  batch 38 loss: [36.09776973724365, 0.14120442420244217]\n",
      "  batch 40 loss: [34.320791244506836, 0.08288339152932167]\n",
      "  batch 42 loss: [37.91714286804199, 0.04690605588257313]\n",
      "  batch 44 loss: [34.45774745941162, 0.13029060140252113]\n",
      "  batch 46 loss: [42.762657165527344, 0.1427268199622631]\n",
      "  batch 48 loss: [35.10818672180176, 0.05423072353005409]\n",
      "  batch 50 loss: [41.16278648376465, 0.35478629171848297]\n",
      "  batch 52 loss: [37.43093490600586, 0.15554814785718918]\n",
      "  batch 54 loss: [32.60170555114746, 0.18400747328996658]\n",
      "LOSS generator 32.60170555114746 discriminator 0.18400747328996658\n",
      "EPOCH 23:\n",
      "  batch 0 loss: [42.94540023803711, 0.20951101183891296]\n",
      "  batch 2 loss: [31.825639724731445, 0.06879689730703831]\n",
      "  batch 4 loss: [41.365394592285156, 0.27376246452331543]\n",
      "  batch 6 loss: [44.736337661743164, 0.4195265471935272]\n",
      "  batch 8 loss: [44.406707763671875, 0.5568861812353134]\n",
      "  batch 10 loss: [37.24774169921875, 0.1130942702293396]\n",
      "  batch 12 loss: [34.628400802612305, 0.2647585868835449]\n",
      "  batch 14 loss: [40.34730529785156, 0.3842484652996063]\n",
      "  batch 16 loss: [48.6007022857666, 0.5834451913833618]\n",
      "  batch 18 loss: [31.508283615112305, 0.2952986806631088]\n",
      "  batch 20 loss: [30.561516761779785, 0.14078307524323463]\n",
      "  batch 22 loss: [33.300859451293945, 0.1066487655043602]\n",
      "  batch 24 loss: [31.130064964294434, 0.1763795167207718]\n",
      "  batch 26 loss: [41.673933029174805, 0.24145635962486267]\n",
      "  batch 28 loss: [35.055978775024414, 0.10063939541578293]\n",
      "  batch 30 loss: [40.6578369140625, 0.2281603291630745]\n",
      "  batch 32 loss: [39.178693771362305, 0.25333426892757416]\n",
      "  batch 34 loss: [36.658267974853516, 0.26189417392015457]\n",
      "  batch 36 loss: [36.53222370147705, 0.2058681771159172]\n",
      "  batch 38 loss: [46.50213623046875, 0.30149947106838226]\n",
      "  batch 40 loss: [30.372066497802734, 0.12728138267993927]\n",
      "  batch 42 loss: [34.47573661804199, 0.09023134782910347]\n",
      "  batch 44 loss: [34.04642391204834, 0.06582604721188545]\n",
      "  batch 46 loss: [34.21352672576904, 0.10530008003115654]\n",
      "  batch 48 loss: [30.378361701965332, 0.13920898735523224]\n",
      "  batch 50 loss: [38.443315505981445, 0.25826965272426605]\n",
      "  batch 52 loss: [46.37888145446777, 0.24864185228943825]\n",
      "  batch 54 loss: [35.64436340332031, 0.07610844075679779]\n",
      "LOSS generator 35.64436340332031 discriminator 0.07610844075679779\n",
      "EPOCH 24:\n",
      "  batch 0 loss: [46.087886810302734, 0.3653290569782257]\n",
      "  batch 2 loss: [34.646413803100586, 0.07610438019037247]\n",
      "  batch 4 loss: [41.884023666381836, 0.2458893060684204]\n",
      "  batch 6 loss: [37.4468879699707, 0.1815900206565857]\n",
      "  batch 8 loss: [34.92692947387695, 0.126755490899086]\n",
      "  batch 10 loss: [31.813551902770996, 0.38222576677799225]\n",
      "  batch 12 loss: [43.032875061035156, 0.14314663410186768]\n",
      "  batch 14 loss: [44.79082679748535, 0.16618192195892334]\n",
      "  batch 16 loss: [35.29667568206787, 0.15609532594680786]\n",
      "  batch 18 loss: [36.71785831451416, 0.12536060065031052]\n",
      "  batch 20 loss: [35.94474411010742, 0.13827772438526154]\n",
      "  batch 22 loss: [29.145204544067383, 0.08438343554735184]\n",
      "  batch 24 loss: [32.50649642944336, 0.28902527689933777]\n",
      "  batch 26 loss: [39.540205001831055, 0.29013127461075783]\n",
      "  batch 28 loss: [37.62431049346924, 0.21646268665790558]\n",
      "  batch 30 loss: [41.36408805847168, 0.28139054775238037]\n",
      "  batch 32 loss: [33.52968978881836, 0.142401322722435]\n",
      "  batch 34 loss: [35.0790901184082, 0.1660526767373085]\n",
      "  batch 36 loss: [45.74876403808594, 0.14462360739707947]\n",
      "  batch 38 loss: [34.129791259765625, 0.06867270916700363]\n",
      "  batch 40 loss: [40.42610740661621, 0.20977649092674255]\n",
      "  batch 42 loss: [39.64240074157715, 0.15423916280269623]\n",
      "  batch 44 loss: [38.72116279602051, 0.2155466377735138]\n",
      "  batch 46 loss: [36.473737716674805, 0.058634303510189056]\n",
      "  batch 48 loss: [40.719099044799805, 0.06854076310992241]\n",
      "  batch 50 loss: [41.645240783691406, 0.1427999511361122]\n",
      "  batch 52 loss: [31.377034187316895, 0.10259062796831131]\n",
      "  batch 54 loss: [38.26863098144531, 0.1129239909350872]\n",
      "LOSS generator 38.26863098144531 discriminator 0.1129239909350872\n",
      "EPOCH 25:\n",
      "  batch 0 loss: [41.66831588745117, 0.1337093859910965]\n",
      "  batch 2 loss: [34.99205017089844, 0.12849853560328484]\n",
      "  batch 4 loss: [35.02252006530762, 0.1951012834906578]\n",
      "  batch 6 loss: [38.07581901550293, 0.22062741965055466]\n",
      "  batch 8 loss: [35.009897232055664, 0.0513366162776947]\n",
      "  batch 10 loss: [32.7917366027832, 0.11761939525604248]\n",
      "  batch 12 loss: [42.96713829040527, 0.1999167650938034]\n",
      "  batch 14 loss: [40.1361198425293, 0.05474848113954067]\n",
      "  batch 16 loss: [44.38689613342285, 0.12488579750061035]\n",
      "  batch 18 loss: [39.132986068725586, 0.1021210141479969]\n",
      "  batch 20 loss: [32.28957176208496, 0.0874408408999443]\n",
      "  batch 22 loss: [37.44907760620117, 0.17870273813605309]\n",
      "  batch 24 loss: [41.49375343322754, 0.09501825086772442]\n",
      "  batch 26 loss: [39.20575714111328, 0.11677635833621025]\n",
      "  batch 28 loss: [36.707679748535156, 0.05354278162121773]\n",
      "  batch 30 loss: [42.77761650085449, 0.19065570086240768]\n",
      "  batch 32 loss: [39.319430351257324, 0.16418930888175964]\n",
      "  batch 34 loss: [31.830838203430176, 0.12712699174880981]\n",
      "  batch 36 loss: [33.59267997741699, 0.12810357846319675]\n",
      "  batch 38 loss: [40.31677436828613, 0.2090107500553131]\n",
      "  batch 40 loss: [38.59045600891113, 0.1538974791765213]\n",
      "  batch 42 loss: [41.96184158325195, 0.15031511336565018]\n",
      "  batch 44 loss: [33.026859283447266, 0.06065635196864605]\n",
      "  batch 46 loss: [34.00667667388916, 0.08071548491716385]\n",
      "  batch 48 loss: [37.086814880371094, 0.0887903980910778]\n",
      "  batch 50 loss: [44.394126892089844, 0.3235618472099304]\n",
      "  batch 52 loss: [34.25770092010498, 0.06775862164795399]\n",
      "  batch 54 loss: [34.59696578979492, 0.05993042699992657]\n",
      "LOSS generator 34.59696578979492 discriminator 0.05993042699992657\n",
      "EPOCH 26:\n",
      "  batch 0 loss: [34.05551528930664, 0.2083120048046112]\n",
      "  batch 2 loss: [41.32271385192871, 0.14075608178973198]\n",
      "  batch 4 loss: [42.04063606262207, 0.15276534855365753]\n",
      "  batch 6 loss: [30.427091598510742, 0.1551084890961647]\n",
      "  batch 8 loss: [44.402048110961914, 0.2783339023590088]\n",
      "  batch 10 loss: [45.02816390991211, 0.10191275924444199]\n",
      "  batch 12 loss: [36.75673294067383, 0.05547971464693546]\n",
      "  batch 14 loss: [40.021799087524414, 0.07307682186365128]\n",
      "  batch 16 loss: [38.63982391357422, 0.07154142111539841]\n",
      "  batch 18 loss: [37.11872863769531, 0.06255597993731499]\n",
      "  batch 20 loss: [41.194786071777344, 0.09079875238239765]\n",
      "  batch 22 loss: [38.37259864807129, 0.2510146200656891]\n",
      "  batch 24 loss: [35.426557540893555, 0.0644863173365593]\n",
      "  batch 26 loss: [41.250823974609375, 0.13338858634233475]\n",
      "  batch 28 loss: [35.80171585083008, 0.21994982659816742]\n",
      "  batch 30 loss: [34.15569305419922, 0.06042017415165901]\n",
      "  batch 32 loss: [42.296695709228516, 0.17087779566645622]\n",
      "  batch 34 loss: [31.853859901428223, 0.0613781176507473]\n",
      "  batch 36 loss: [39.33049201965332, 0.18930447474122047]\n",
      "  batch 38 loss: [27.08866310119629, 0.17517775297164917]\n",
      "  batch 40 loss: [35.950439453125, 0.22328149154782295]\n",
      "  batch 42 loss: [45.18674087524414, 0.15074198693037033]\n",
      "  batch 44 loss: [33.46515464782715, 0.09687397629022598]\n",
      "  batch 46 loss: [44.154436111450195, 0.13852740079164505]\n",
      "  batch 48 loss: [39.054161071777344, 0.1067260280251503]\n",
      "  batch 50 loss: [36.57907962799072, 0.16067200899124146]\n",
      "  batch 52 loss: [34.057865142822266, 0.08413468766957521]\n",
      "  batch 54 loss: [36.11104393005371, 0.05046085920184851]\n",
      "LOSS generator 36.11104393005371 discriminator 0.05046085920184851\n",
      "EPOCH 27:\n",
      "  batch 0 loss: [39.10249710083008, 0.10816153138875961]\n",
      "  batch 2 loss: [38.86810302734375, 0.03990575019270182]\n",
      "  batch 4 loss: [36.375349044799805, 0.05925758555531502]\n",
      "  batch 6 loss: [41.48939037322998, 0.2222531232982874]\n",
      "  batch 8 loss: [34.918296813964844, 0.3210373520851135]\n",
      "  batch 10 loss: [39.605234146118164, 0.17933238297700882]\n",
      "  batch 12 loss: [33.514373779296875, 0.09517199173569679]\n",
      "  batch 14 loss: [34.32452964782715, 0.11166372895240784]\n",
      "  batch 16 loss: [35.82128143310547, 0.10026940330862999]\n",
      "  batch 18 loss: [42.87875938415527, 0.11782035231590271]\n",
      "  batch 20 loss: [40.28890037536621, 0.026629834435880184]\n",
      "  batch 22 loss: [33.15036582946777, 0.05247671343386173]\n",
      "  batch 24 loss: [52.25652885437012, 0.2667757421731949]\n",
      "  batch 26 loss: [38.64345741271973, 0.15448013320565224]\n",
      "  batch 28 loss: [30.877253532409668, 0.13394775986671448]\n",
      "  batch 30 loss: [38.37838554382324, 0.10929094441235065]\n",
      "  batch 32 loss: [41.398128509521484, 0.2148878537118435]\n",
      "  batch 34 loss: [37.381032943725586, 0.14943677559494972]\n",
      "  batch 36 loss: [32.13249206542969, 0.3172720894217491]\n",
      "  batch 38 loss: [37.97187900543213, 0.29121555015444756]\n",
      "  batch 40 loss: [34.69207191467285, 0.23038586974143982]\n",
      "  batch 42 loss: [40.608442306518555, 0.2899024039506912]\n",
      "  batch 44 loss: [40.927690505981445, 0.27087467163801193]\n",
      "  batch 46 loss: [37.7114200592041, 0.1024765819311142]\n",
      "  batch 48 loss: [38.95267105102539, 0.2342168390750885]\n",
      "  batch 50 loss: [34.54546642303467, 0.14539415389299393]\n",
      "  batch 52 loss: [43.50062370300293, 0.1694301813840866]\n",
      "  batch 54 loss: [29.542266845703125, 0.10615380853414536]\n",
      "LOSS generator 29.542266845703125 discriminator 0.10615380853414536\n",
      "EPOCH 28:\n",
      "  batch 0 loss: [39.34065246582031, 0.16041499376296997]\n",
      "  batch 2 loss: [43.30436325073242, 0.22927474975585938]\n",
      "  batch 4 loss: [35.91406059265137, 0.06364282220602036]\n",
      "  batch 6 loss: [38.269901275634766, 0.03652659431099892]\n",
      "  batch 8 loss: [42.86092948913574, 0.17329668998718262]\n",
      "  batch 10 loss: [31.33513641357422, 0.059024229645729065]\n",
      "  batch 12 loss: [39.93512535095215, 0.0943954773247242]\n",
      "  batch 14 loss: [42.28153419494629, 0.22420839965343475]\n",
      "  batch 16 loss: [38.95680618286133, 0.1035427674651146]\n",
      "  batch 18 loss: [34.478882789611816, 0.12397617101669312]\n",
      "  batch 20 loss: [35.77606201171875, 0.1015301663428545]\n",
      "  batch 22 loss: [42.112565994262695, 0.16008006036281586]\n",
      "  batch 24 loss: [35.77753925323486, 0.1892867088317871]\n",
      "  batch 26 loss: [38.75009727478027, 0.1286262348294258]\n",
      "  batch 28 loss: [32.805068016052246, 0.049722541123628616]\n",
      "  batch 30 loss: [36.726003646850586, 0.12778458558022976]\n",
      "  batch 32 loss: [40.68478012084961, 0.08703982457518578]\n",
      "  batch 34 loss: [36.56422233581543, 0.03858737088739872]\n",
      "  batch 36 loss: [33.46359634399414, 0.03792677819728851]\n",
      "  batch 38 loss: [43.76774978637695, 0.05513650272041559]\n",
      "  batch 40 loss: [41.49469184875488, 0.08427735790610313]\n",
      "  batch 42 loss: [40.65325355529785, 0.13169598579406738]\n",
      "  batch 44 loss: [28.182479858398438, 0.08511850982904434]\n",
      "  batch 46 loss: [42.55636024475098, 0.24300338327884674]\n",
      "  batch 48 loss: [39.85926055908203, 0.13279027491807938]\n",
      "  batch 50 loss: [34.04958152770996, 0.1069100871682167]\n",
      "  batch 52 loss: [37.66711235046387, 0.14297354966402054]\n",
      "  batch 54 loss: [34.50458240509033, 0.134997196495533]\n",
      "LOSS generator 34.50458240509033 discriminator 0.134997196495533\n",
      "EPOCH 29:\n",
      "  batch 0 loss: [44.773963928222656, 0.1854325532913208]\n",
      "  batch 2 loss: [38.75685691833496, 0.11861211061477661]\n",
      "  batch 4 loss: [35.950294494628906, 0.2099582627415657]\n",
      "  batch 6 loss: [33.064701080322266, 0.057451047003269196]\n",
      "  batch 8 loss: [39.61313819885254, 0.39689156971871853]\n",
      "  batch 10 loss: [37.1893310546875, 0.2274726815521717]\n",
      "  batch 12 loss: [36.388288497924805, 0.10767172276973724]\n",
      "  batch 14 loss: [43.46928405761719, 0.15016821026802063]\n",
      "  batch 16 loss: [34.07503318786621, 0.039650510996580124]\n",
      "  batch 18 loss: [34.188724517822266, 0.032149627804756165]\n",
      "  batch 20 loss: [38.851139068603516, 0.11467315256595612]\n",
      "  batch 22 loss: [32.99513530731201, 0.11423537135124207]\n",
      "  batch 24 loss: [45.42308235168457, 0.11895532160997391]\n",
      "  batch 26 loss: [45.231611251831055, 0.09406287595629692]\n",
      "  batch 28 loss: [34.04853534698486, 0.03617575019598007]\n",
      "  batch 30 loss: [38.4012336730957, 0.09918590728193521]\n",
      "  batch 32 loss: [27.80419158935547, 0.039077045395970345]\n",
      "  batch 34 loss: [40.543630599975586, 0.07603161036968231]\n",
      "  batch 36 loss: [35.563053131103516, 0.10721607506275177]\n",
      "  batch 38 loss: [37.457425117492676, 0.060501907020807266]\n",
      "  batch 40 loss: [44.632469177246094, 0.09875720739364624]\n",
      "  batch 42 loss: [43.879669189453125, 0.07931462675333023]\n",
      "  batch 44 loss: [39.37328910827637, 0.11987113952636719]\n",
      "  batch 46 loss: [36.486433029174805, 0.05096184089779854]\n",
      "  batch 48 loss: [45.33332443237305, 0.14188802614808083]\n",
      "  batch 50 loss: [37.583003997802734, 0.060900076292455196]\n",
      "  batch 52 loss: [33.772579193115234, 0.04996888153254986]\n",
      "  batch 54 loss: [32.668025970458984, 0.10346890427172184]\n",
      "LOSS generator 32.668025970458984 discriminator 0.10346890427172184\n",
      "EPOCH 30:\n",
      "  batch 0 loss: [28.955547332763672, 0.040629904717206955]\n",
      "  batch 2 loss: [37.3536434173584, 0.09121240489184856]\n",
      "  batch 4 loss: [29.903688430786133, 0.03488881420344114]\n",
      "  batch 6 loss: [40.585716247558594, 0.04200544115155935]\n",
      "  batch 8 loss: [34.587799072265625, 0.02001775847747922]\n",
      "  batch 10 loss: [37.247697830200195, 0.08996375650167465]\n",
      "  batch 12 loss: [37.12419128417969, 0.04147446155548096]\n",
      "  batch 14 loss: [42.32965278625488, 0.02130789216607809]\n",
      "  batch 16 loss: [44.72343826293945, 0.057140037417411804]\n",
      "  batch 18 loss: [37.149423599243164, 0.07726013101637363]\n",
      "  batch 20 loss: [33.562376976013184, 0.02530238963663578]\n",
      "  batch 22 loss: [45.82294464111328, 0.12093537114560604]\n",
      "  batch 24 loss: [32.90333366394043, 0.07837112247943878]\n",
      "  batch 26 loss: [43.57475471496582, 0.11716122180223465]\n",
      "  batch 28 loss: [36.32803726196289, 0.06003163754940033]\n",
      "  batch 30 loss: [38.31376266479492, 0.09228642843663692]\n",
      "  batch 32 loss: [35.69684600830078, 0.036364300176501274]\n",
      "  batch 34 loss: [45.50835418701172, 0.2877824455499649]\n",
      "  batch 36 loss: [41.33646202087402, 0.2650501877069473]\n",
      "  batch 38 loss: [37.165916442871094, 0.031557511538267136]\n",
      "  batch 40 loss: [44.02634620666504, 0.17786337435245514]\n",
      "  batch 42 loss: [42.12639808654785, 0.20475716888904572]\n",
      "  batch 44 loss: [36.45914649963379, 0.10548725910484791]\n",
      "  batch 46 loss: [44.40250205993652, 0.17272890359163284]\n",
      "  batch 48 loss: [35.83250617980957, 0.1353258602321148]\n",
      "  batch 50 loss: [33.61011219024658, 0.10103575512766838]\n",
      "  batch 52 loss: [40.6375732421875, 0.14718925207853317]\n",
      "  batch 54 loss: [32.56573963165283, 0.1920723132789135]\n",
      "LOSS generator 32.56573963165283 discriminator 0.1920723132789135\n",
      "EPOCH 31:\n",
      "  batch 0 loss: [50.01691818237305, 0.20694667100906372]\n",
      "  batch 2 loss: [46.5095329284668, 0.12459756806492805]\n",
      "  batch 4 loss: [36.34168243408203, 0.11152279190719128]\n",
      "  batch 6 loss: [34.20017623901367, 0.09109743684530258]\n",
      "  batch 8 loss: [44.57260513305664, 0.12497266754508018]\n",
      "  batch 10 loss: [36.71315383911133, 0.16619138047099113]\n",
      "  batch 12 loss: [32.43449020385742, 0.05354462005198002]\n",
      "  batch 14 loss: [34.30939769744873, 0.10947715491056442]\n",
      "  batch 16 loss: [30.919052124023438, 0.05157601833343506]\n",
      "  batch 18 loss: [38.50074768066406, 0.07522339932620525]\n",
      "  batch 20 loss: [36.41729927062988, 0.02125963568687439]\n",
      "  batch 22 loss: [39.74100112915039, 0.16613776981830597]\n",
      "  batch 24 loss: [35.83320426940918, 0.08884485065937042]\n",
      "  batch 26 loss: [49.425397872924805, 0.18382279574871063]\n",
      "  batch 28 loss: [40.633052825927734, 0.11721985414624214]\n",
      "  batch 30 loss: [33.67441749572754, 0.066383957862854]\n",
      "  batch 32 loss: [34.44937324523926, 0.07019730284810066]\n",
      "  batch 34 loss: [38.733686447143555, 0.07151444628834724]\n",
      "  batch 36 loss: [39.57232093811035, 0.09132299572229385]\n",
      "  batch 38 loss: [36.74298667907715, 0.1330832801759243]\n",
      "  batch 40 loss: [38.12047004699707, 0.03561422973871231]\n",
      "  batch 42 loss: [34.53948211669922, 0.03320654295384884]\n",
      "  batch 44 loss: [37.50779914855957, 0.1452462263405323]\n",
      "  batch 46 loss: [38.43372917175293, 0.10352515988051891]\n",
      "  batch 48 loss: [43.79788589477539, 0.17324812337756157]\n",
      "  batch 50 loss: [41.4339714050293, 0.2090214490890503]\n",
      "  batch 52 loss: [35.66512107849121, 0.05091653764247894]\n",
      "  batch 54 loss: [35.58439254760742, 0.04928137548267841]\n",
      "LOSS generator 35.58439254760742 discriminator 0.04928137548267841\n",
      "EPOCH 32:\n",
      "  batch 0 loss: [37.929725646972656, 0.033784594386816025]\n",
      "  batch 2 loss: [32.91242218017578, 0.04593692347407341]\n",
      "  batch 4 loss: [41.9697322845459, 0.11325261928141117]\n",
      "  batch 6 loss: [35.26871585845947, 0.11921219155192375]\n",
      "  batch 8 loss: [39.33210372924805, 0.07334407605230808]\n",
      "  batch 10 loss: [35.78118896484375, 0.03760431334376335]\n",
      "  batch 12 loss: [36.99747657775879, 0.02990322094410658]\n",
      "  batch 14 loss: [31.809964179992676, 0.03443348407745361]\n",
      "  batch 16 loss: [44.114091873168945, 0.15606223046779633]\n",
      "  batch 18 loss: [43.81752586364746, 0.11301891133189201]\n",
      "  batch 20 loss: [42.18286323547363, 0.08275877870619297]\n",
      "  batch 22 loss: [47.84063720703125, 0.19025634229183197]\n",
      "  batch 24 loss: [37.02091407775879, 0.0534380991011858]\n",
      "  batch 26 loss: [51.31900978088379, 0.24440380930900574]\n",
      "  batch 28 loss: [37.25185775756836, 0.17481371015310287]\n",
      "  batch 30 loss: [29.95301055908203, 0.049852825701236725]\n",
      "  batch 32 loss: [36.99985218048096, 0.1909433752298355]\n",
      "  batch 34 loss: [35.27294731140137, 0.1008642315864563]\n",
      "  batch 36 loss: [28.847740173339844, 0.05474589020013809]\n",
      "  batch 38 loss: [38.07634353637695, 0.17087136209011078]\n",
      "  batch 40 loss: [40.6645450592041, 0.12243565917015076]\n",
      "  batch 42 loss: [34.56774711608887, 0.10469344072043896]\n",
      "  batch 44 loss: [38.99735450744629, 0.1362151987850666]\n",
      "  batch 46 loss: [34.83601379394531, 0.021071190014481544]\n",
      "  batch 48 loss: [40.1358528137207, 0.08431451860815287]\n",
      "  batch 50 loss: [38.479976654052734, 0.037461042404174805]\n",
      "  batch 52 loss: [43.02391052246094, 0.15418479219079018]\n",
      "  batch 54 loss: [39.2384033203125, 0.10598783195018768]\n",
      "LOSS generator 39.2384033203125 discriminator 0.10598783195018768\n",
      "EPOCH 33:\n",
      "  batch 0 loss: [28.161760330200195, 0.02759762853384018]\n",
      "  batch 2 loss: [36.305532455444336, 0.023824463598430157]\n",
      "  batch 4 loss: [30.430394172668457, 0.04664241895079613]\n",
      "  batch 6 loss: [39.03457260131836, 0.028867973014712334]\n",
      "  batch 8 loss: [40.99901580810547, 0.0873420387506485]\n",
      "  batch 10 loss: [40.6201171875, 0.045695843175053596]\n",
      "  batch 12 loss: [31.8830509185791, 0.024110088124871254]\n",
      "  batch 14 loss: [36.28518104553223, 0.06161081977188587]\n",
      "  batch 16 loss: [38.482337951660156, 0.05402018129825592]\n",
      "  batch 18 loss: [45.85320854187012, 0.1698927842080593]\n",
      "  batch 20 loss: [41.109018325805664, 0.11216599959880114]\n",
      "  batch 22 loss: [37.9772891998291, 0.03909316845238209]\n",
      "  batch 24 loss: [41.17050552368164, 0.08528478071093559]\n",
      "  batch 26 loss: [38.29338264465332, 0.11358432844281197]\n",
      "  batch 28 loss: [31.74686908721924, 0.030517414212226868]\n",
      "  batch 30 loss: [42.380043029785156, 0.08168712630867958]\n",
      "  batch 32 loss: [40.47446632385254, 0.07123975548893213]\n",
      "  batch 34 loss: [34.51081085205078, 0.02576909400522709]\n",
      "  batch 36 loss: [38.87152862548828, 0.1059565618634224]\n",
      "  batch 38 loss: [34.88024616241455, 0.08329411875456572]\n",
      "  batch 40 loss: [50.57975387573242, 0.13815004378557205]\n",
      "  batch 42 loss: [40.14949417114258, 0.08406159281730652]\n",
      "  batch 44 loss: [34.09104537963867, 0.045444220304489136]\n",
      "  batch 46 loss: [45.42995834350586, 0.11249851435422897]\n",
      "  batch 48 loss: [32.45918273925781, 0.028719802387058735]\n",
      "  batch 50 loss: [44.85979652404785, 0.094642692245543]\n",
      "  batch 52 loss: [37.58624267578125, 0.05308487080037594]\n",
      "  batch 54 loss: [33.982051849365234, 0.022790261544287205]\n",
      "LOSS generator 33.982051849365234 discriminator 0.022790261544287205\n",
      "EPOCH 34:\n",
      "  batch 0 loss: [41.47732162475586, 0.05768202990293503]\n",
      "  batch 2 loss: [46.26095008850098, 0.14473718404769897]\n",
      "  batch 4 loss: [37.204824447631836, 0.02441731095314026]\n",
      "  batch 6 loss: [38.75771999359131, 0.0943156760185957]\n",
      "  batch 8 loss: [41.89405822753906, 0.11335380282253027]\n",
      "  batch 10 loss: [35.67337989807129, 0.03101576305925846]\n",
      "  batch 12 loss: [51.80405235290527, 0.3418382406234741]\n",
      "  batch 14 loss: [33.37256336212158, 0.09741872921586037]\n",
      "  batch 16 loss: [43.72081756591797, 0.10217908304184675]\n",
      "  batch 18 loss: [37.8198184967041, 0.057374028488993645]\n",
      "  batch 20 loss: [34.82192039489746, 0.03586964309215546]\n",
      "  batch 22 loss: [47.4294548034668, 0.1500852331519127]\n",
      "  batch 24 loss: [33.09837627410889, 0.026914797723293304]\n",
      "  batch 26 loss: [41.387481689453125, 0.09092921763658524]\n",
      "  batch 28 loss: [39.43388557434082, 0.029220597818493843]\n",
      "  batch 30 loss: [39.79546546936035, 0.08142687380313873]\n",
      "  batch 32 loss: [32.039021492004395, 0.05948206968605518]\n",
      "  batch 34 loss: [29.48597526550293, 0.036135380156338215]\n",
      "  batch 36 loss: [45.58135795593262, 0.07273315638303757]\n",
      "  batch 38 loss: [38.26899719238281, 0.03523895610123873]\n",
      "  batch 40 loss: [41.0903263092041, 0.01130352495238185]\n",
      "  batch 42 loss: [40.50965118408203, 0.04701220244169235]\n",
      "  batch 44 loss: [38.39385414123535, 0.027419631369411945]\n",
      "  batch 46 loss: [29.69746208190918, 0.03774432651698589]\n",
      "  batch 48 loss: [38.09794330596924, 0.06057611480355263]\n",
      "  batch 50 loss: [37.05853843688965, 0.027378953993320465]\n",
      "  batch 52 loss: [34.6613883972168, 0.03642295487225056]\n",
      "  batch 54 loss: [36.51279258728027, 0.048372434452176094]\n",
      "LOSS generator 36.51279258728027 discriminator 0.048372434452176094\n",
      "EPOCH 35:\n",
      "  batch 0 loss: [40.90627670288086, 0.07027889788150787]\n",
      "  batch 2 loss: [49.99641036987305, 0.07950000464916229]\n",
      "  batch 4 loss: [40.70565414428711, 0.03706738352775574]\n",
      "  batch 6 loss: [31.079862594604492, 0.024930871091783047]\n",
      "  batch 8 loss: [42.87550735473633, 0.06840934790670872]\n",
      "  batch 10 loss: [40.94085693359375, 0.0351083017885685]\n",
      "  batch 12 loss: [36.40641975402832, 0.199549013748765]\n",
      "  batch 14 loss: [42.71874809265137, 0.06296717748045921]\n",
      "  batch 16 loss: [39.65774154663086, 0.033643463626503944]\n",
      "  batch 18 loss: [40.670454025268555, 0.08277839422225952]\n",
      "  batch 20 loss: [41.079050064086914, 0.06952593475580215]\n",
      "  batch 22 loss: [31.287464141845703, 0.02600325644016266]\n",
      "  batch 24 loss: [38.181562423706055, 0.08827811479568481]\n",
      "  batch 26 loss: [33.10168266296387, 0.05650302767753601]\n",
      "  batch 28 loss: [40.677297592163086, 0.10477934498339891]\n",
      "  batch 30 loss: [33.559380531311035, 0.07457870244979858]\n",
      "  batch 32 loss: [36.61337089538574, 0.08150175958871841]\n",
      "  batch 34 loss: [34.87312698364258, 0.1414743810892105]\n",
      "  batch 36 loss: [40.66530799865723, 0.040066616609692574]\n",
      "  batch 38 loss: [35.00789451599121, 0.06338969804346561]\n",
      "  batch 40 loss: [37.58515930175781, 0.0909563209861517]\n",
      "  batch 42 loss: [45.58156967163086, 0.11782294884324074]\n",
      "  batch 44 loss: [33.05400848388672, 0.15782323479652405]\n",
      "  batch 46 loss: [47.8688850402832, 0.08735585957765579]\n",
      "  batch 48 loss: [37.27362632751465, 0.05232634022831917]\n",
      "  batch 50 loss: [38.060834884643555, 0.021161921322345734]\n",
      "  batch 52 loss: [36.61767768859863, 0.04320490825921297]\n",
      "  batch 54 loss: [32.55548095703125, 0.03404594957828522]\n",
      "LOSS generator 32.55548095703125 discriminator 0.03404594957828522\n",
      "EPOCH 36:\n",
      "  batch 0 loss: [36.191062927246094, 0.017563212662935257]\n",
      "  batch 2 loss: [48.05200004577637, 0.2657013535499573]\n",
      "  batch 4 loss: [37.516395568847656, 0.2151591256260872]\n",
      "  batch 6 loss: [33.60832214355469, 0.0999501422047615]\n",
      "  batch 8 loss: [40.53466033935547, 0.12963103875517845]\n",
      "  batch 10 loss: [47.59528160095215, 0.16020970419049263]\n",
      "  batch 12 loss: [36.30925941467285, 0.03495685011148453]\n",
      "  batch 14 loss: [44.77279472351074, 0.1858064904808998]\n",
      "  batch 16 loss: [34.444007873535156, 0.0793793648481369]\n",
      "  batch 18 loss: [37.207889556884766, 0.08793176338076591]\n",
      "  batch 20 loss: [39.40406036376953, 0.06439553387463093]\n",
      "  batch 22 loss: [35.87434673309326, 0.02738209441304207]\n",
      "  batch 24 loss: [39.6649112701416, 0.053862178698182106]\n",
      "  batch 26 loss: [36.79695129394531, 0.0989590073004365]\n",
      "  batch 28 loss: [38.83080863952637, 0.05290240701287985]\n",
      "  batch 30 loss: [37.91003227233887, 0.09940818324685097]\n",
      "  batch 32 loss: [44.57563400268555, 0.06294254213571548]\n",
      "  batch 34 loss: [36.72731971740723, 0.042198581621050835]\n",
      "  batch 36 loss: [36.73004913330078, 0.017742690164595842]\n",
      "  batch 38 loss: [30.414868354797363, 0.026111800223588943]\n",
      "  batch 40 loss: [36.87452507019043, 0.05783252790570259]\n",
      "  batch 42 loss: [44.28408622741699, 0.034765453077852726]\n",
      "  batch 44 loss: [39.43457794189453, 0.07820429652929306]\n",
      "  batch 46 loss: [45.9317626953125, 0.13086821883916855]\n",
      "  batch 48 loss: [33.522579193115234, 0.07473139092326164]\n",
      "  batch 50 loss: [29.245749473571777, 0.10156668536365032]\n",
      "  batch 52 loss: [35.45137023925781, 0.055988432839512825]\n",
      "  batch 54 loss: [47.1291446685791, 0.24690140783786774]\n",
      "LOSS generator 47.1291446685791 discriminator 0.24690140783786774\n",
      "EPOCH 37:\n",
      "  batch 0 loss: [39.796878814697266, 0.02766330912709236]\n",
      "  batch 2 loss: [41.89114761352539, 0.14723874256014824]\n",
      "  batch 4 loss: [47.60758399963379, 0.2891666889190674]\n",
      "  batch 6 loss: [42.439979553222656, 0.09017127379775047]\n",
      "  batch 8 loss: [31.615280151367188, 0.03129773773252964]\n",
      "  batch 10 loss: [38.82467460632324, 0.04448886401951313]\n",
      "  batch 12 loss: [32.04025650024414, 0.0271145342849195]\n",
      "  batch 14 loss: [36.08400344848633, 0.017490866594016552]\n",
      "  batch 16 loss: [36.29716110229492, 0.03887304477393627]\n",
      "  batch 18 loss: [39.7936954498291, 0.03376072458922863]\n",
      "  batch 20 loss: [45.446189880371094, 0.2554640807211399]\n",
      "  batch 22 loss: [32.462663650512695, 0.07823881693184376]\n",
      "  batch 24 loss: [37.385353088378906, 0.07173079997301102]\n",
      "  batch 26 loss: [45.28348731994629, 0.12051543965935707]\n",
      "  batch 28 loss: [45.138750076293945, 0.057445358484983444]\n",
      "  batch 30 loss: [38.708120346069336, 0.019546080380678177]\n",
      "  batch 32 loss: [40.50798416137695, 0.035793996416032314]\n",
      "  batch 34 loss: [37.46208572387695, 0.05710802134126425]\n",
      "  batch 36 loss: [43.539913177490234, 0.09347430616617203]\n",
      "  batch 38 loss: [41.84810829162598, 0.1028330996632576]\n",
      "  batch 40 loss: [28.470483779907227, 0.05199330113828182]\n",
      "  batch 42 loss: [41.091121673583984, 0.10650203377008438]\n",
      "  batch 44 loss: [40.99719047546387, 0.04946899972856045]\n",
      "  batch 46 loss: [38.562164306640625, 0.014289346057921648]\n",
      "  batch 48 loss: [35.46099090576172, 0.05280436761677265]\n",
      "  batch 50 loss: [36.238630294799805, 0.04147237632423639]\n",
      "  batch 52 loss: [36.68037986755371, 0.01621344918385148]\n",
      "  batch 54 loss: [36.9423713684082, 0.022177765145897865]\n",
      "LOSS generator 36.9423713684082 discriminator 0.022177765145897865\n",
      "EPOCH 38:\n",
      "  batch 0 loss: [42.70133972167969, 0.0585068054497242]\n",
      "  batch 2 loss: [39.29711723327637, 0.04858098737895489]\n",
      "  batch 4 loss: [43.422767639160156, 0.15973343839868903]\n",
      "  batch 6 loss: [32.684343338012695, 0.22171951364725828]\n",
      "  batch 8 loss: [44.238441467285156, 0.1877860128879547]\n",
      "  batch 10 loss: [36.284193992614746, 0.11914343014359474]\n",
      "  batch 12 loss: [36.52662467956543, 0.041912974789738655]\n",
      "  batch 14 loss: [34.83988380432129, 0.027740957215428352]\n",
      "  batch 16 loss: [41.20707893371582, 0.08179156668484211]\n",
      "  batch 18 loss: [32.517093658447266, 0.0477908905595541]\n",
      "  batch 20 loss: [32.3549747467041, 0.09951937850564718]\n",
      "  batch 22 loss: [45.445180892944336, 0.15059590339660645]\n",
      "  batch 24 loss: [34.445335388183594, 0.07969032600522041]\n",
      "  batch 26 loss: [52.128170013427734, 0.14925546944141388]\n",
      "  batch 28 loss: [30.98054790496826, 0.02385517582297325]\n",
      "  batch 30 loss: [36.743886947631836, 0.015501976478844881]\n",
      "  batch 32 loss: [37.23046684265137, 0.0801691384986043]\n",
      "  batch 34 loss: [40.606422424316406, 0.09828776866197586]\n",
      "  batch 36 loss: [42.867618560791016, 0.03513377998024225]\n",
      "  batch 38 loss: [47.27868843078613, 0.05654148291796446]\n",
      "  batch 40 loss: [39.839908599853516, 0.03561178967356682]\n",
      "  batch 42 loss: [30.004831314086914, 0.023792745545506477]\n",
      "  batch 44 loss: [38.78216743469238, 0.08291682973504066]\n",
      "  batch 46 loss: [44.0880126953125, 0.098366379737854]\n",
      "  batch 48 loss: [41.267486572265625, 0.07043210044503212]\n",
      "  batch 50 loss: [42.907270431518555, 0.011968635488301516]\n",
      "  batch 52 loss: [38.07488441467285, 0.04365661460906267]\n",
      "  batch 54 loss: [35.25279235839844, 0.025453703477978706]\n",
      "LOSS generator 35.25279235839844 discriminator 0.025453703477978706\n",
      "EPOCH 39:\n",
      "  batch 0 loss: [38.061649322509766, 0.060614556074142456]\n",
      "  batch 2 loss: [48.04905128479004, 0.07214581966400146]\n",
      "  batch 4 loss: [33.926307678222656, 0.03569982759654522]\n",
      "  batch 6 loss: [39.264774322509766, 0.03465513791888952]\n",
      "  batch 8 loss: [45.32630920410156, 0.05230908654630184]\n",
      "  batch 10 loss: [32.756513595581055, 0.017895712982863188]\n",
      "  batch 12 loss: [39.39738750457764, 0.031435394659638405]\n",
      "  batch 14 loss: [47.651899337768555, 0.0748708676546812]\n",
      "  batch 16 loss: [36.99788856506348, 0.04351857025176287]\n",
      "  batch 18 loss: [36.493085861206055, 0.017876900266855955]\n",
      "  batch 20 loss: [37.971866607666016, 0.012538996525108814]\n",
      "  batch 22 loss: [35.49228477478027, 0.04271635226905346]\n",
      "  batch 24 loss: [40.93544578552246, 0.06850432232022285]\n",
      "  batch 26 loss: [38.270193099975586, 0.03651794884353876]\n",
      "  batch 28 loss: [37.635087966918945, 0.017737286165356636]\n",
      "  batch 30 loss: [35.15484619140625, 0.01717974990606308]\n",
      "  batch 32 loss: [36.24434280395508, 0.09408168122172356]\n",
      "  batch 34 loss: [38.73855209350586, 0.05069627799093723]\n",
      "  batch 36 loss: [44.62934875488281, 0.09329534694552422]\n",
      "  batch 38 loss: [31.38841724395752, 0.017971081659197807]\n",
      "  batch 40 loss: [44.37233924865723, 0.04404303431510925]\n",
      "  batch 42 loss: [45.77725791931152, 0.05201718583703041]\n",
      "  batch 44 loss: [43.215097427368164, 0.028982922434806824]\n",
      "  batch 46 loss: [42.172800064086914, 0.05346874659880996]\n",
      "  batch 48 loss: [34.994707107543945, 0.16607098653912544]\n",
      "  batch 50 loss: [37.65896129608154, 0.05122596397995949]\n",
      "  batch 52 loss: [30.378372192382812, 0.03838923014700413]\n",
      "  batch 54 loss: [41.214982986450195, 0.05219950154423714]\n",
      "LOSS generator 41.214982986450195 discriminator 0.05219950154423714\n",
      "EPOCH 40:\n",
      "  batch 0 loss: [34.42376708984375, 0.01785840280354023]\n",
      "  batch 2 loss: [37.684213638305664, 0.027528480160981417]\n",
      "  batch 4 loss: [44.77737236022949, 0.08195342868566513]\n",
      "  batch 6 loss: [38.20686721801758, 0.042449782602488995]\n",
      "  batch 8 loss: [38.04439163208008, 0.030275615863502026]\n",
      "  batch 10 loss: [34.11814022064209, 0.03251495771110058]\n",
      "  batch 12 loss: [40.87385940551758, 0.05513397231698036]\n",
      "  batch 14 loss: [37.813804626464844, 0.04971541464328766]\n",
      "  batch 16 loss: [43.21478080749512, 0.06463425233960152]\n",
      "  batch 18 loss: [37.89284706115723, 0.017537272535264492]\n",
      "  batch 20 loss: [42.172335624694824, 0.09986623004078865]\n",
      "  batch 22 loss: [40.31079864501953, 0.030377200804650784]\n",
      "  batch 24 loss: [41.94454574584961, 0.04879847262054682]\n",
      "  batch 26 loss: [44.124032974243164, 0.09664076752960682]\n",
      "  batch 28 loss: [37.00715637207031, 0.014169691130518913]\n",
      "  batch 30 loss: [34.748146057128906, 0.02683325158432126]\n",
      "  batch 32 loss: [40.11055374145508, 0.026029545813798904]\n",
      "  batch 34 loss: [36.1556921005249, 0.04234541393816471]\n",
      "  batch 36 loss: [39.77756881713867, 0.05195356719195843]\n",
      "  batch 38 loss: [32.61278533935547, 0.08708575367927551]\n",
      "  batch 40 loss: [41.27312088012695, 0.07192410156130791]\n",
      "  batch 42 loss: [34.13953971862793, 0.026631050743162632]\n",
      "  batch 44 loss: [41.95075035095215, 0.04791536368429661]\n",
      "  batch 46 loss: [35.84507751464844, 0.019514717161655426]\n",
      "  batch 48 loss: [28.767187118530273, 1.5049983859062195]\n",
      "  batch 50 loss: [30.461037635803223, 1.7177258133888245]\n",
      "  batch 52 loss: [31.98426055908203, 1.6729965209960938]\n",
      "  batch 54 loss: [28.510820388793945, 0.941274106502533]\n",
      "LOSS generator 28.510820388793945 discriminator 0.941274106502533\n",
      "EPOCH 41:\n",
      "  batch 0 loss: [29.4714412689209, 0.7314027547836304]\n",
      "  batch 2 loss: [25.79868221282959, 0.7739022374153137]\n",
      "  batch 4 loss: [29.17164421081543, 0.7933478653430939]\n",
      "  batch 6 loss: [32.15943717956543, 0.9068294763565063]\n",
      "  batch 8 loss: [30.974452018737793, 0.7131325900554657]\n",
      "  batch 10 loss: [28.826688766479492, 0.7889080047607422]\n",
      "  batch 12 loss: [25.334558486938477, 0.7057337164878845]\n",
      "  batch 14 loss: [25.054723739624023, 0.694257527589798]\n",
      "  batch 16 loss: [26.50905704498291, 0.9151275157928467]\n",
      "  batch 18 loss: [27.516592979431152, 0.7286910116672516]\n",
      "  batch 20 loss: [35.50133514404297, 1.0321574807167053]\n",
      "  batch 22 loss: [25.780238151550293, 0.6855234801769257]\n",
      "  batch 24 loss: [28.32700824737549, 0.6839876770973206]\n",
      "  batch 26 loss: [23.904478073120117, 0.7041582465171814]\n",
      "  batch 28 loss: [23.39391803741455, 0.6917473077774048]\n",
      "  batch 30 loss: [28.063018798828125, 0.735748827457428]\n",
      "  batch 32 loss: [33.128150939941406, 0.7090232670307159]\n",
      "  batch 34 loss: [33.804656982421875, 0.8047711253166199]\n",
      "  batch 36 loss: [28.562535285949707, 0.6921544671058655]\n",
      "  batch 38 loss: [30.751999855041504, 0.7495724856853485]\n",
      "  batch 40 loss: [26.793062210083008, 0.693297952413559]\n",
      "  batch 42 loss: [29.15519905090332, 0.7015424966812134]\n",
      "  batch 44 loss: [30.22911834716797, 0.6697655618190765]\n",
      "  batch 46 loss: [26.691570281982422, 0.6538006663322449]\n",
      "  batch 48 loss: [27.29254150390625, 0.6371289491653442]\n",
      "  batch 50 loss: [34.67920112609863, 0.6591788828372955]\n",
      "  batch 52 loss: [28.388629913330078, 0.6181907951831818]\n",
      "  batch 54 loss: [31.52346706390381, 0.5958822667598724]\n",
      "LOSS generator 31.52346706390381 discriminator 0.5958822667598724\n",
      "EPOCH 42:\n",
      "  batch 0 loss: [33.81574630737305, 0.746241569519043]\n",
      "  batch 2 loss: [29.105141639709473, 0.824415534734726]\n",
      "  batch 4 loss: [28.5878849029541, 0.7353309988975525]\n",
      "  batch 6 loss: [26.6579532623291, 0.7489998936653137]\n",
      "  batch 8 loss: [29.35880470275879, 0.6757004261016846]\n",
      "  batch 10 loss: [22.423150062561035, 0.6573945879936218]\n",
      "  batch 12 loss: [27.746103286743164, 0.8059298992156982]\n",
      "  batch 14 loss: [34.1160774230957, 0.7823226451873779]\n",
      "  batch 16 loss: [31.46058750152588, 0.6980399489402771]\n",
      "  batch 18 loss: [28.903510093688965, 0.665401428937912]\n",
      "  batch 20 loss: [30.454052925109863, 0.654527097940445]\n",
      "  batch 22 loss: [26.34563446044922, 0.6421400606632233]\n",
      "  batch 24 loss: [30.934865951538086, 0.6353336572647095]\n",
      "  batch 26 loss: [25.210749626159668, 0.6201850771903992]\n",
      "  batch 28 loss: [28.79583740234375, 1.086345374584198]\n",
      "  batch 30 loss: [30.533109664916992, 0.6874798536300659]\n",
      "  batch 32 loss: [31.102188110351562, 0.6705547571182251]\n",
      "  batch 34 loss: [31.049979209899902, 0.6353666484355927]\n",
      "  batch 36 loss: [26.923736572265625, 0.6525678932666779]\n",
      "  batch 38 loss: [33.16510581970215, 0.6973193287849426]\n",
      "  batch 40 loss: [28.935068130493164, 0.6574473679065704]\n",
      "  batch 42 loss: [30.417689323425293, 0.6675105392932892]\n",
      "  batch 44 loss: [26.118057250976562, 0.5879694223403931]\n",
      "  batch 46 loss: [23.238346099853516, 0.6884577572345734]\n",
      "  batch 48 loss: [22.47471523284912, 0.6409900188446045]\n",
      "  batch 50 loss: [23.373624801635742, 0.6424216032028198]\n",
      "  batch 52 loss: [37.485535621643066, 0.6929287016391754]\n",
      "  batch 54 loss: [27.474844932556152, 0.6703116595745087]\n",
      "LOSS generator 27.474844932556152 discriminator 0.6703116595745087\n",
      "EPOCH 43:\n",
      "  batch 0 loss: [20.57294464111328, 0.6565206050872803]\n",
      "  batch 2 loss: [28.72511100769043, 0.724897176027298]\n",
      "  batch 4 loss: [36.39762878417969, 0.8265105187892914]\n",
      "  batch 6 loss: [27.59235191345215, 0.6105636954307556]\n",
      "  batch 8 loss: [30.841005325317383, 0.9394731819629669]\n",
      "  batch 10 loss: [27.584896087646484, 0.6546301543712616]\n",
      "  batch 12 loss: [30.85092544555664, 0.7785665988922119]\n",
      "  batch 14 loss: [33.665008544921875, 0.8026323914527893]\n",
      "  batch 16 loss: [26.38442325592041, 0.6634442508220673]\n",
      "  batch 18 loss: [26.89192771911621, 0.6248171627521515]\n",
      "  batch 20 loss: [25.364930152893066, 0.6188946068286896]\n",
      "  batch 22 loss: [31.982643127441406, 0.7242784202098846]\n",
      "  batch 24 loss: [28.218499183654785, 0.6593124270439148]\n",
      "  batch 26 loss: [22.12111473083496, 0.6773592531681061]\n",
      "  batch 28 loss: [29.386816024780273, 0.649601399898529]\n",
      "  batch 30 loss: [29.40000629425049, 0.6998486816883087]\n",
      "  batch 32 loss: [30.093807220458984, 0.623892605304718]\n",
      "  batch 34 loss: [28.55654525756836, 0.619894802570343]\n",
      "  batch 36 loss: [26.173842430114746, 0.7069166302680969]\n",
      "  batch 38 loss: [27.253225326538086, 0.6310713887214661]\n",
      "  batch 40 loss: [31.14273166656494, 0.7781361937522888]\n",
      "  batch 42 loss: [31.899311065673828, 0.6371212601661682]\n",
      "  batch 44 loss: [30.296207427978516, 0.6024200320243835]\n",
      "  batch 46 loss: [26.188796043395996, 0.6368511617183685]\n",
      "  batch 48 loss: [31.992878913879395, 0.5726669728755951]\n",
      "  batch 50 loss: [33.16371822357178, 0.5531720519065857]\n",
      "  batch 52 loss: [22.852627754211426, 0.6621586084365845]\n",
      "  batch 54 loss: [24.712148666381836, 0.61601123213768]\n",
      "LOSS generator 24.712148666381836 discriminator 0.61601123213768\n",
      "EPOCH 44:\n",
      "  batch 0 loss: [23.42291831970215, 0.7577330470085144]\n",
      "  batch 2 loss: [28.434351921081543, 0.7049655318260193]\n",
      "  batch 4 loss: [29.62610149383545, 0.7157107889652252]\n",
      "  batch 6 loss: [27.931690216064453, 0.6371106803417206]\n",
      "  batch 8 loss: [29.90321445465088, 0.6771408319473267]\n",
      "  batch 10 loss: [33.55826377868652, 0.6242413520812988]\n",
      "  batch 12 loss: [26.673827171325684, 1.0066449046134949]\n",
      "  batch 14 loss: [32.066386222839355, 0.7399490773677826]\n",
      "  batch 16 loss: [32.80082130432129, 0.7132983207702637]\n",
      "  batch 18 loss: [32.988651275634766, 0.6950535774230957]\n",
      "  batch 20 loss: [28.863526344299316, 0.6012690961360931]\n",
      "  batch 22 loss: [30.119426727294922, 0.6930500864982605]\n",
      "  batch 24 loss: [23.634702682495117, 0.6715216040611267]\n",
      "  batch 26 loss: [28.067516326904297, 0.5670051872730255]\n",
      "  batch 28 loss: [30.624075889587402, 0.6561029553413391]\n",
      "  batch 30 loss: [23.097352027893066, 0.565162181854248]\n",
      "  batch 32 loss: [28.19900894165039, 0.5278549045324326]\n",
      "  batch 34 loss: [28.054722785949707, 0.797381579875946]\n",
      "  batch 36 loss: [28.50155544281006, 0.9581027626991272]\n",
      "  batch 38 loss: [25.91333770751953, 0.6339702308177948]\n",
      "  batch 40 loss: [31.864548683166504, 0.657932847738266]\n",
      "  batch 42 loss: [30.148566246032715, 0.6090584397315979]\n",
      "  batch 44 loss: [27.16892719268799, 0.5996858775615692]\n",
      "  batch 46 loss: [23.97693634033203, 0.5485744774341583]\n",
      "  batch 48 loss: [29.403963088989258, 0.7748397886753082]\n",
      "  batch 50 loss: [32.50914287567139, 1.4028005003929138]\n",
      "  batch 52 loss: [32.27622890472412, 0.7624668478965759]\n",
      "  batch 54 loss: [31.874503135681152, 0.6583887040615082]\n",
      "LOSS generator 31.874503135681152 discriminator 0.6583887040615082\n",
      "EPOCH 45:\n",
      "  batch 0 loss: [22.712188720703125, 0.6126327514648438]\n",
      "  batch 2 loss: [28.741415977478027, 0.6387295722961426]\n",
      "  batch 4 loss: [28.36855411529541, 0.583803802728653]\n",
      "  batch 6 loss: [24.11375331878662, 0.5202942341566086]\n",
      "  batch 8 loss: [35.80955696105957, 0.532245397567749]\n",
      "  batch 10 loss: [25.20005702972412, 0.5906944870948792]\n",
      "  batch 12 loss: [29.12753200531006, 0.6338727176189423]\n",
      "  batch 14 loss: [28.146326065063477, 0.5521305501461029]\n",
      "  batch 16 loss: [28.84118938446045, 0.4865119159221649]\n",
      "  batch 18 loss: [28.14085292816162, 0.5886251330375671]\n",
      "  batch 20 loss: [28.690531730651855, 0.5843047797679901]\n",
      "  batch 22 loss: [27.626625061035156, 0.5691884756088257]\n",
      "  batch 24 loss: [33.69038772583008, 0.5817990601062775]\n",
      "  batch 26 loss: [35.01095199584961, 0.5558896511793137]\n",
      "  batch 28 loss: [24.508312225341797, 0.5966419279575348]\n",
      "  batch 30 loss: [26.69966697692871, 0.5264530330896378]\n",
      "  batch 32 loss: [24.754761695861816, 0.48830460011959076]\n",
      "  batch 34 loss: [28.91754150390625, 0.4136638641357422]\n",
      "  batch 36 loss: [23.860220909118652, 0.562659502029419]\n",
      "  batch 38 loss: [35.56117630004883, 0.8404015004634857]\n",
      "  batch 40 loss: [27.86387348175049, 0.4949340224266052]\n",
      "  batch 42 loss: [30.928939819335938, 0.6640547811985016]\n",
      "  batch 44 loss: [31.777562141418457, 0.5720801055431366]\n",
      "  batch 46 loss: [28.469759941101074, 0.4521937668323517]\n",
      "  batch 48 loss: [28.71019744873047, 0.36300332844257355]\n",
      "  batch 50 loss: [25.459476470947266, 0.5544053316116333]\n",
      "  batch 52 loss: [33.93802261352539, 0.490540087223053]\n",
      "  batch 54 loss: [25.77176284790039, 0.42628490924835205]\n",
      "LOSS generator 25.77176284790039 discriminator 0.42628490924835205\n",
      "EPOCH 46:\n",
      "  batch 0 loss: [32.131099700927734, 0.5220040082931519]\n",
      "  batch 2 loss: [21.19795036315918, 0.3904600739479065]\n",
      "  batch 4 loss: [28.699291229248047, 0.4152880162000656]\n",
      "  batch 6 loss: [32.21852779388428, 0.33579733967781067]\n",
      "  batch 8 loss: [28.600584983825684, 0.575726717710495]\n",
      "  batch 10 loss: [35.51692867279053, 0.45152635872364044]\n",
      "  batch 12 loss: [25.312936782836914, 0.44977691769599915]\n",
      "  batch 14 loss: [25.837164878845215, 0.5265068411827087]\n",
      "  batch 16 loss: [30.03504180908203, 0.39465656876564026]\n",
      "  batch 18 loss: [30.092923164367676, 0.293214850127697]\n",
      "  batch 20 loss: [33.598989486694336, 0.46830621361732483]\n",
      "  batch 22 loss: [31.755959510803223, 0.3870801329612732]\n",
      "  batch 24 loss: [30.969158172607422, 0.3159601539373398]\n",
      "  batch 26 loss: [22.131942749023438, 0.5798969268798828]\n",
      "  batch 28 loss: [32.621299743652344, 0.49347899854183197]\n",
      "  batch 30 loss: [29.504091262817383, 0.3369772285223007]\n",
      "  batch 32 loss: [26.846221923828125, 0.2553790509700775]\n",
      "  batch 34 loss: [37.52225685119629, 0.5328311622142792]\n",
      "  batch 36 loss: [28.032570838928223, 0.42546120285987854]\n",
      "  batch 38 loss: [31.638471603393555, 0.4149227440357208]\n",
      "  batch 40 loss: [29.507856369018555, 0.29492320120334625]\n",
      "  batch 42 loss: [30.288979530334473, 0.21560773253440857]\n",
      "  batch 44 loss: [25.232994079589844, 0.4334213584661484]\n",
      "  batch 46 loss: [27.797825813293457, 0.4966244399547577]\n",
      "  batch 48 loss: [32.34213066101074, 0.40267691016197205]\n",
      "  batch 50 loss: [33.16199970245361, 0.39112572371959686]\n",
      "  batch 52 loss: [30.416561126708984, 0.2670692801475525]\n",
      "  batch 54 loss: [28.449987411499023, 0.2766529768705368]\n",
      "LOSS generator 28.449987411499023 discriminator 0.2766529768705368\n",
      "EPOCH 47:\n",
      "  batch 0 loss: [34.87956237792969, 0.4321867823600769]\n",
      "  batch 2 loss: [37.723350524902344, 0.2828825116157532]\n",
      "  batch 4 loss: [33.49300575256348, 0.1993633285164833]\n",
      "  batch 6 loss: [27.16016387939453, 0.3438210040330887]\n",
      "  batch 8 loss: [26.190539360046387, 0.4762621521949768]\n",
      "  batch 10 loss: [33.00529670715332, 0.44645777344703674]\n",
      "  batch 12 loss: [33.10033702850342, 0.4149545431137085]\n",
      "  batch 14 loss: [35.66470146179199, 0.3950178027153015]\n",
      "  batch 16 loss: [30.216398239135742, 0.25661715120077133]\n",
      "  batch 18 loss: [26.6311674118042, 0.2740768790245056]\n",
      "  batch 20 loss: [32.00689888000488, 0.3299606144428253]\n",
      "  batch 22 loss: [27.10880470275879, 0.17855753004550934]\n",
      "  batch 24 loss: [28.76034641265869, 0.1558745838701725]\n",
      "  batch 26 loss: [26.220837593078613, 0.2435404509305954]\n",
      "  batch 28 loss: [33.95259475708008, 0.21945852786302567]\n",
      "  batch 30 loss: [29.596444129943848, 0.25093959271907806]\n",
      "  batch 32 loss: [27.680533409118652, 0.21844324469566345]\n",
      "  batch 34 loss: [33.65872383117676, 0.2163233980536461]\n",
      "  batch 36 loss: [31.187889099121094, 0.1208481602370739]\n",
      "  batch 38 loss: [30.796375274658203, 0.22832074016332626]\n",
      "  batch 40 loss: [25.287623405456543, 0.1918746754527092]\n",
      "  batch 42 loss: [28.914907455444336, 0.1839926615357399]\n",
      "  batch 44 loss: [26.1320743560791, 0.23396551981568336]\n",
      "  batch 46 loss: [34.637906074523926, 0.17710429430007935]\n",
      "  batch 48 loss: [31.37221050262451, 0.16847966238856316]\n",
      "  batch 50 loss: [28.626508712768555, 0.41583533585071564]\n",
      "  batch 52 loss: [29.71159553527832, 0.3793008178472519]\n",
      "  batch 54 loss: [26.86882781982422, 0.6324584931135178]\n",
      "LOSS generator 26.86882781982422 discriminator 0.6324584931135178\n",
      "EPOCH 48:\n",
      "  batch 0 loss: [21.3038272857666, 0.3386915326118469]\n",
      "  batch 2 loss: [32.61698532104492, 0.32088108360767365]\n",
      "  batch 4 loss: [35.804256439208984, 0.3524547815322876]\n",
      "  batch 6 loss: [30.590599060058594, 0.2748553305864334]\n",
      "  batch 8 loss: [27.474050521850586, 0.1452244445681572]\n",
      "  batch 10 loss: [30.374571800231934, 0.20687170326709747]\n",
      "  batch 12 loss: [33.60712432861328, 0.21539372950792313]\n",
      "  batch 14 loss: [28.338425636291504, 0.14247404783964157]\n",
      "  batch 16 loss: [31.56748104095459, 0.274738572537899]\n",
      "  batch 18 loss: [28.75816249847412, 0.24261245131492615]\n",
      "  batch 20 loss: [26.146567344665527, 0.1367080733180046]\n",
      "  batch 22 loss: [34.75973892211914, 0.27906790375709534]\n",
      "  batch 24 loss: [32.42410850524902, 0.14605391025543213]\n",
      "  batch 26 loss: [32.186102867126465, 0.20242691785097122]\n",
      "  batch 28 loss: [31.09338092803955, 0.16970300674438477]\n",
      "  batch 30 loss: [29.92005729675293, 0.3087228983640671]\n",
      "  batch 32 loss: [34.51211357116699, 0.33518533408641815]\n",
      "  batch 34 loss: [27.9039306640625, 0.26243022084236145]\n",
      "  batch 36 loss: [26.07846164703369, 0.16546418517827988]\n",
      "  batch 38 loss: [26.987642288208008, 0.15041915699839592]\n",
      "  batch 40 loss: [29.560959815979004, 0.42726126313209534]\n",
      "  batch 42 loss: [31.594234466552734, 0.1477488987147808]\n",
      "  batch 44 loss: [29.558594703674316, 0.25856559723615646]\n",
      "  batch 46 loss: [26.35068702697754, 0.254435271024704]\n",
      "  batch 48 loss: [38.558401107788086, 0.278493195772171]\n",
      "  batch 50 loss: [29.55667781829834, 0.11677813157439232]\n",
      "  batch 52 loss: [33.40786361694336, 0.1725003570318222]\n",
      "  batch 54 loss: [31.87978172302246, 0.20395591855049133]\n",
      "LOSS generator 31.87978172302246 discriminator 0.20395591855049133\n",
      "EPOCH 49:\n",
      "  batch 0 loss: [40.5992431640625, 0.20968864858150482]\n",
      "  batch 2 loss: [32.023820877075195, 0.5746666789054871]\n",
      "  batch 4 loss: [29.565345764160156, 0.6328440755605698]\n",
      "  batch 6 loss: [27.011241912841797, 0.4451140761375427]\n",
      "  batch 8 loss: [33.60409164428711, 0.3290964812040329]\n",
      "  batch 10 loss: [34.30397891998291, 0.37930436432361603]\n",
      "  batch 12 loss: [22.526836395263672, 0.2987426444888115]\n",
      "  batch 14 loss: [29.469172477722168, 0.1558980941772461]\n",
      "  batch 16 loss: [25.015524864196777, 0.21750803291797638]\n",
      "  batch 18 loss: [31.046762466430664, 0.14469782263040543]\n",
      "  batch 20 loss: [35.49949836730957, 0.1601773351430893]\n",
      "  batch 22 loss: [31.414424896240234, 0.23504452407360077]\n",
      "  batch 24 loss: [31.98706817626953, 0.1721583567559719]\n",
      "  batch 26 loss: [27.769322395324707, 0.15683399140834808]\n",
      "  batch 28 loss: [29.57790184020996, 0.12091582268476486]\n",
      "  batch 30 loss: [27.24076557159424, 0.18144547939300537]\n",
      "  batch 32 loss: [35.96490478515625, 0.1784154623746872]\n",
      "  batch 34 loss: [34.56020164489746, 0.12841789796948433]\n",
      "  batch 36 loss: [29.571809768676758, 0.12264799326658249]\n",
      "  batch 38 loss: [28.032644271850586, 0.16974518075585365]\n",
      "  batch 40 loss: [27.855202674865723, 0.10703407227993011]\n",
      "  batch 42 loss: [36.52389335632324, 0.1675046980381012]\n",
      "  batch 44 loss: [35.79972457885742, 0.2800722122192383]\n",
      "  batch 46 loss: [27.58817768096924, 0.1632479801774025]\n",
      "  batch 48 loss: [32.15578269958496, 0.39442464523017406]\n",
      "  batch 50 loss: [28.567712783813477, 0.8092925846576691]\n",
      "  batch 52 loss: [28.66962718963623, 0.3563014417886734]\n",
      "  batch 54 loss: [27.816691398620605, 0.3803621232509613]\n",
      "LOSS generator 27.816691398620605 discriminator 0.3803621232509613\n",
      "EPOCH 50:\n",
      "  batch 0 loss: [31.989482879638672, 0.12243042886257172]\n",
      "  batch 2 loss: [27.0751314163208, 0.196918785572052]\n",
      "  batch 4 loss: [27.902572631835938, 0.2463545799255371]\n",
      "  batch 6 loss: [32.08255672454834, 0.14237456023693085]\n",
      "  batch 8 loss: [28.958608627319336, 0.08385657146573067]\n",
      "  batch 10 loss: [31.278810501098633, 0.14752869307994843]\n",
      "  batch 12 loss: [32.103187561035156, 0.21742254495620728]\n",
      "  batch 14 loss: [26.00594425201416, 0.36156296730041504]\n",
      "  batch 16 loss: [27.245253562927246, 0.3086506128311157]\n",
      "  batch 18 loss: [30.11409091949463, 0.29219989478588104]\n",
      "  batch 20 loss: [26.164112091064453, 0.3043353259563446]\n",
      "  batch 22 loss: [29.86041259765625, 0.30489738285541534]\n",
      "  batch 24 loss: [28.838825225830078, 0.33522552251815796]\n",
      "  batch 26 loss: [32.799686431884766, 0.36213579773902893]\n",
      "  batch 28 loss: [25.474790573120117, 0.31308451294898987]\n",
      "  batch 30 loss: [32.46402931213379, 0.24531105160713196]\n",
      "  batch 32 loss: [28.512516975402832, 0.19616273045539856]\n",
      "  batch 34 loss: [29.790228843688965, 0.3025856912136078]\n",
      "  batch 36 loss: [34.553162574768066, 0.3209635466337204]\n",
      "  batch 38 loss: [35.194393157958984, 0.3042434900999069]\n",
      "  batch 40 loss: [26.195770263671875, 0.4758823812007904]\n",
      "  batch 42 loss: [29.742355346679688, 0.227726548910141]\n",
      "  batch 44 loss: [30.874056816101074, 0.23842139542102814]\n",
      "  batch 46 loss: [32.07217788696289, 0.2289550006389618]\n",
      "  batch 48 loss: [30.077340126037598, 0.1841176301240921]\n",
      "  batch 50 loss: [35.94500732421875, 0.14111194759607315]\n",
      "  batch 52 loss: [27.8577823638916, 0.1937280409038067]\n",
      "  batch 54 loss: [37.30759239196777, 0.2222716435790062]\n",
      "LOSS generator 37.30759239196777 discriminator 0.2222716435790062\n",
      "EPOCH 51:\n",
      "  batch 0 loss: [30.891002655029297, 0.3479178249835968]\n",
      "  batch 2 loss: [32.86079406738281, 0.18775638937950134]\n",
      "  batch 4 loss: [28.493715286254883, 0.21597817540168762]\n",
      "  batch 6 loss: [30.823840141296387, 0.2665218785405159]\n",
      "  batch 8 loss: [30.44274139404297, 0.17090782523155212]\n",
      "  batch 10 loss: [36.82592010498047, 0.1883365958929062]\n",
      "  batch 12 loss: [35.5369291305542, 0.14106446504592896]\n",
      "  batch 14 loss: [25.593685150146484, 0.15816447511315346]\n",
      "  batch 16 loss: [33.351219177246094, 0.1620018593966961]\n",
      "  batch 18 loss: [29.952548027038574, 0.06410770118236542]\n",
      "  batch 20 loss: [29.37825870513916, 0.12119633704423904]\n",
      "  batch 22 loss: [29.10887050628662, 0.17466167360544205]\n",
      "  batch 24 loss: [30.599385261535645, 0.21421416848897934]\n",
      "  batch 26 loss: [30.64219379425049, 0.22627631947398186]\n",
      "  batch 28 loss: [32.11242389678955, 0.22350800037384033]\n",
      "  batch 30 loss: [30.94132423400879, 0.2602859362959862]\n",
      "  batch 32 loss: [30.275015830993652, 0.2413809821009636]\n",
      "  batch 34 loss: [37.99410438537598, 0.1813877895474434]\n",
      "  batch 36 loss: [31.38837432861328, 0.07454016618430614]\n",
      "  batch 38 loss: [26.19975471496582, 0.20569606870412827]\n",
      "  batch 40 loss: [25.966176986694336, 0.13493378087878227]\n",
      "  batch 42 loss: [28.936705589294434, 0.056664880365133286]\n",
      "  batch 44 loss: [28.43753719329834, 0.14793211221694946]\n",
      "  batch 46 loss: [34.8795108795166, 0.10709205642342567]\n",
      "  batch 48 loss: [30.135598182678223, 0.18032799661159515]\n",
      "  batch 50 loss: [31.274581909179688, 0.09895956888794899]\n",
      "  batch 52 loss: [35.37853813171387, 0.11051854118704796]\n",
      "  batch 54 loss: [29.686294555664062, 0.06864097341895103]\n",
      "LOSS generator 29.686294555664062 discriminator 0.06864097341895103\n",
      "EPOCH 52:\n",
      "  batch 0 loss: [36.88826370239258, 0.25827157497406006]\n",
      "  batch 2 loss: [26.591952323913574, 0.07779281586408615]\n",
      "  batch 4 loss: [33.899760246276855, 0.09645065665245056]\n",
      "  batch 6 loss: [28.842379570007324, 0.061135632917284966]\n",
      "  batch 8 loss: [31.362574577331543, 0.1419808715581894]\n",
      "  batch 10 loss: [28.977356910705566, 0.11272048950195312]\n",
      "  batch 12 loss: [29.63209056854248, 0.1185050718486309]\n",
      "  batch 14 loss: [28.2087984085083, 0.07394425570964813]\n",
      "  batch 16 loss: [28.819016456604004, 0.12668967992067337]\n",
      "  batch 18 loss: [37.209144592285156, 0.09868655353784561]\n",
      "  batch 20 loss: [29.485689163208008, 0.10593060962855816]\n",
      "  batch 22 loss: [30.448200225830078, 0.10667231678962708]\n",
      "  batch 24 loss: [36.315778732299805, 0.1471179099753499]\n",
      "  batch 26 loss: [29.54871940612793, 0.11594109237194061]\n",
      "  batch 28 loss: [32.069512367248535, 0.14797377586364746]\n",
      "  batch 30 loss: [30.325956344604492, 0.10475150495767593]\n",
      "  batch 32 loss: [30.973502159118652, 0.11932404339313507]\n",
      "  batch 34 loss: [31.472177505493164, 0.15754353255033493]\n",
      "  batch 36 loss: [28.35762596130371, 0.10822200030088425]\n",
      "  batch 38 loss: [34.643497467041016, 0.2192172408103943]\n",
      "  batch 40 loss: [31.07055950164795, 0.21786780655384064]\n",
      "  batch 42 loss: [30.46992015838623, 0.09960844740271568]\n",
      "  batch 44 loss: [35.39183807373047, 0.15603116899728775]\n",
      "  batch 46 loss: [33.0749568939209, 0.09600022435188293]\n",
      "  batch 48 loss: [38.45494842529297, 0.28565578907728195]\n",
      "  batch 50 loss: [32.98900032043457, 0.1457199677824974]\n",
      "  batch 52 loss: [25.90614604949951, 0.18053506314754486]\n",
      "  batch 54 loss: [30.87778949737549, 0.13782593980431557]\n",
      "LOSS generator 30.87778949737549 discriminator 0.13782593980431557\n",
      "EPOCH 53:\n",
      "  batch 0 loss: [30.10210609436035, 0.1864778846502304]\n",
      "  batch 2 loss: [36.11818885803223, 0.15550710260868073]\n",
      "  batch 4 loss: [29.745542526245117, 0.16916722059249878]\n",
      "  batch 6 loss: [28.10782527923584, 0.14948024600744247]\n",
      "  batch 8 loss: [33.00589179992676, 0.10812964476644993]\n",
      "  batch 10 loss: [35.04470252990723, 0.0907584447413683]\n",
      "  batch 12 loss: [31.733139991760254, 0.16415895521640778]\n",
      "  batch 14 loss: [28.315011978149414, 0.08716569654643536]\n",
      "  batch 16 loss: [34.74607753753662, 0.1585443913936615]\n",
      "  batch 18 loss: [33.991729736328125, 0.06581142544746399]\n",
      "  batch 20 loss: [31.08743953704834, 0.05518993083387613]\n",
      "  batch 22 loss: [29.426307678222656, 0.1473342701792717]\n",
      "  batch 24 loss: [28.62650203704834, 0.06793810427188873]\n",
      "  batch 26 loss: [38.22629737854004, 0.2463860921561718]\n",
      "  batch 28 loss: [36.425039291381836, 0.3016159310936928]\n",
      "  batch 30 loss: [28.85323429107666, 0.18101392686367035]\n",
      "  batch 32 loss: [29.684639930725098, 0.1316867470741272]\n",
      "  batch 34 loss: [31.59830379486084, 0.0744149275124073]\n",
      "  batch 36 loss: [33.79767417907715, 0.11517654359340668]\n",
      "  batch 38 loss: [30.82119083404541, 0.06992724537849426]\n",
      "  batch 40 loss: [31.4099760055542, 0.09616545960307121]\n",
      "  batch 42 loss: [28.450748443603516, 0.11237854138016701]\n",
      "  batch 44 loss: [30.828903198242188, 0.11348308622837067]\n",
      "  batch 46 loss: [35.098934173583984, 0.05485397391021252]\n",
      "  batch 48 loss: [33.39375686645508, 0.14277560263872147]\n",
      "  batch 50 loss: [29.43131923675537, 0.05402462184429169]\n",
      "  batch 52 loss: [30.18398952484131, 0.12938779965043068]\n",
      "  batch 54 loss: [28.332111358642578, 0.053119832649827003]\n",
      "LOSS generator 28.332111358642578 discriminator 0.053119832649827003\n",
      "EPOCH 54:\n",
      "  batch 0 loss: [28.445232391357422, 0.10238014906644821]\n",
      "  batch 2 loss: [28.621384620666504, 0.16665537655353546]\n",
      "  batch 4 loss: [30.233469009399414, 0.050870202481746674]\n",
      "  batch 6 loss: [32.544891357421875, 0.08453200943768024]\n",
      "  batch 8 loss: [29.685873985290527, 0.06032758951187134]\n",
      "  batch 10 loss: [33.21718883514404, 0.06981864478439093]\n",
      "  batch 12 loss: [30.237984657287598, 0.12217538058757782]\n",
      "  batch 14 loss: [31.048911094665527, 0.06452731415629387]\n",
      "  batch 16 loss: [30.44054412841797, 0.02752750739455223]\n",
      "  batch 18 loss: [38.851776123046875, 0.12000881135463715]\n",
      "  batch 20 loss: [22.88722324371338, 0.19490624964237213]\n",
      "  batch 22 loss: [29.22662925720215, 0.06729939766228199]\n",
      "  batch 24 loss: [29.014474868774414, 0.04543113149702549]\n",
      "  batch 26 loss: [33.445648193359375, 0.051581183448433876]\n",
      "  batch 28 loss: [32.00161933898926, 0.08067304827272892]\n",
      "  batch 30 loss: [28.856752395629883, 0.12143413349986076]\n",
      "  batch 32 loss: [36.379815101623535, 0.27839066833257675]\n",
      "  batch 34 loss: [32.627174377441406, 0.3369014859199524]\n",
      "  batch 36 loss: [28.133387565612793, 0.09534195810556412]\n",
      "  batch 38 loss: [35.55575752258301, 0.2868923395872116]\n",
      "  batch 40 loss: [32.651180267333984, 0.3612951338291168]\n",
      "  batch 42 loss: [34.38470458984375, 0.2774382345378399]\n",
      "  batch 44 loss: [28.544527053833008, 0.34462566673755646]\n",
      "  batch 46 loss: [30.170357704162598, 0.39533694088459015]\n",
      "  batch 48 loss: [33.366512298583984, 0.3735704943537712]\n",
      "  batch 50 loss: [28.971129417419434, 0.20924639701843262]\n",
      "  batch 52 loss: [32.7674446105957, 0.1461719274520874]\n",
      "  batch 54 loss: [40.561811447143555, 0.31503574550151825]\n",
      "LOSS generator 40.561811447143555 discriminator 0.31503574550151825\n",
      "EPOCH 55:\n",
      "  batch 0 loss: [34.730403900146484, 0.04481310769915581]\n",
      "  batch 2 loss: [32.55052089691162, 0.20450719818472862]\n",
      "  batch 4 loss: [28.423041343688965, 0.09148282930254936]\n",
      "  batch 6 loss: [25.505828857421875, 0.13708185404539108]\n",
      "  batch 8 loss: [33.4098014831543, 0.11569513380527496]\n",
      "  batch 10 loss: [28.652623176574707, 0.2976243942975998]\n",
      "  batch 12 loss: [28.044791221618652, 0.08126165345311165]\n",
      "  batch 14 loss: [29.160820960998535, 0.1351558044552803]\n",
      "  batch 16 loss: [38.32762145996094, 0.1449747532606125]\n",
      "  batch 18 loss: [23.796804428100586, 0.13920407742261887]\n",
      "  batch 20 loss: [38.19308662414551, 0.18987654149532318]\n",
      "  batch 22 loss: [34.45382881164551, 0.2248513177037239]\n",
      "  batch 24 loss: [29.90920352935791, 0.1038070023059845]\n",
      "  batch 26 loss: [34.36362171173096, 0.100394943729043]\n",
      "  batch 28 loss: [31.196313858032227, 0.07519605569541454]\n",
      "  batch 30 loss: [37.661399841308594, 0.06592823937535286]\n",
      "  batch 32 loss: [32.91910743713379, 0.11943576671183109]\n",
      "  batch 34 loss: [31.147729873657227, 0.03830426651984453]\n",
      "  batch 36 loss: [33.66211795806885, 0.0910298265516758]\n",
      "  batch 38 loss: [29.07749080657959, 0.048134444281458855]\n",
      "  batch 40 loss: [28.24018383026123, 0.10808558017015457]\n",
      "  batch 42 loss: [34.872069358825684, 0.08170624636113644]\n",
      "  batch 44 loss: [32.242430686950684, 0.1055496595799923]\n",
      "  batch 46 loss: [26.56242561340332, 0.12048500031232834]\n",
      "  batch 48 loss: [32.78815937042236, 0.06696410849690437]\n",
      "  batch 50 loss: [27.589077949523926, 0.07317318022251129]\n",
      "  batch 52 loss: [25.136917114257812, 0.09719308465719223]\n",
      "  batch 54 loss: [37.32818412780762, 0.11201394349336624]\n",
      "LOSS generator 37.32818412780762 discriminator 0.11201394349336624\n",
      "EPOCH 56:\n",
      "  batch 0 loss: [26.28020668029785, 0.1026361733675003]\n",
      "  batch 2 loss: [31.835891723632812, 0.08473604917526245]\n",
      "  batch 4 loss: [33.298216819763184, 0.07948263175785542]\n",
      "  batch 6 loss: [31.775567054748535, 0.13993696123361588]\n",
      "  batch 8 loss: [33.1097412109375, 0.05489627085626125]\n",
      "  batch 10 loss: [33.62481117248535, 0.14005541056394577]\n",
      "  batch 12 loss: [33.5191650390625, 0.05313150957226753]\n",
      "  batch 14 loss: [28.772323608398438, 0.03389775473624468]\n",
      "  batch 16 loss: [32.3212194442749, 0.08344503492116928]\n",
      "  batch 18 loss: [29.27515697479248, 0.20823759585618973]\n",
      "  batch 20 loss: [36.50344276428223, 0.15226434916257858]\n",
      "  batch 22 loss: [32.19493389129639, 0.19068565219640732]\n",
      "  batch 24 loss: [34.19792556762695, 0.09733913466334343]\n",
      "  batch 26 loss: [33.348777770996094, 0.1417204812169075]\n",
      "  batch 28 loss: [31.69815444946289, 0.12347522377967834]\n",
      "  batch 30 loss: [28.810885429382324, 0.04624956659972668]\n",
      "  batch 32 loss: [36.622426986694336, 0.11947357654571533]\n",
      "  batch 34 loss: [28.589733123779297, 0.05413871072232723]\n",
      "  batch 36 loss: [34.807464599609375, 0.10944060981273651]\n",
      "  batch 38 loss: [28.842690467834473, 0.0725501999258995]\n",
      "  batch 40 loss: [32.863648414611816, 0.07746301591396332]\n",
      "  batch 42 loss: [30.655317306518555, 0.07281969487667084]\n",
      "  batch 44 loss: [29.230280876159668, 0.18611466512084007]\n",
      "  batch 46 loss: [30.02257251739502, 0.14951795898377895]\n",
      "  batch 48 loss: [31.23047161102295, 0.1230173334479332]\n",
      "  batch 50 loss: [32.02205181121826, 0.06108063459396362]\n",
      "  batch 52 loss: [33.062209129333496, 0.05398866720497608]\n",
      "  batch 54 loss: [32.3817138671875, 0.1901899166405201]\n",
      "LOSS generator 32.3817138671875 discriminator 0.1901899166405201\n",
      "EPOCH 57:\n",
      "  batch 0 loss: [31.765565872192383, 0.10778771340847015]\n",
      "  batch 2 loss: [34.805301666259766, 0.10637139528989792]\n",
      "  batch 4 loss: [28.451704025268555, 0.06365776062011719]\n",
      "  batch 6 loss: [36.67608833312988, 0.19316045567393303]\n",
      "  batch 8 loss: [27.038872718811035, 0.08492744341492653]\n",
      "  batch 10 loss: [37.739511489868164, 0.3706933371722698]\n",
      "  batch 12 loss: [28.444329261779785, 0.2273680493235588]\n",
      "  batch 14 loss: [33.81545829772949, 0.4310423582792282]\n",
      "  batch 16 loss: [29.958147048950195, 0.32083964347839355]\n",
      "  batch 18 loss: [22.50685405731201, 0.23072557151317596]\n",
      "  batch 20 loss: [28.555075645446777, 0.08960741013288498]\n",
      "  batch 22 loss: [28.96393394470215, 0.16417253762483597]\n",
      "  batch 24 loss: [35.444427490234375, 0.20825491100549698]\n",
      "  batch 26 loss: [24.97071361541748, 0.0728120394051075]\n",
      "  batch 28 loss: [32.98456382751465, 0.18324349261820316]\n",
      "  batch 30 loss: [36.04939937591553, 0.13537123426795006]\n",
      "  batch 32 loss: [29.868613243103027, 0.03637279663234949]\n",
      "  batch 34 loss: [35.53237724304199, 0.09270074684172869]\n",
      "  batch 36 loss: [30.827713012695312, 0.09116042405366898]\n",
      "  batch 38 loss: [32.581637382507324, 0.10662477649748325]\n",
      "  batch 40 loss: [35.08759117126465, 0.13531272485852242]\n",
      "  batch 42 loss: [29.988203048706055, 0.06640812754631042]\n",
      "  batch 44 loss: [31.92266845703125, 0.09144823625683784]\n",
      "  batch 46 loss: [32.13226509094238, 0.05532902665436268]\n",
      "  batch 48 loss: [35.11592674255371, 0.16852384060621262]\n",
      "  batch 50 loss: [30.641874313354492, 0.09943443536758423]\n",
      "  batch 52 loss: [36.86238098144531, 0.08731791377067566]\n",
      "  batch 54 loss: [30.965354919433594, 0.08870892971754074]\n",
      "LOSS generator 30.965354919433594 discriminator 0.08870892971754074\n",
      "EPOCH 58:\n",
      "  batch 0 loss: [31.802417755126953, 0.03515668958425522]\n",
      "  batch 2 loss: [29.824935913085938, 0.0649452842772007]\n",
      "  batch 4 loss: [34.62923049926758, 0.0601761881262064]\n",
      "  batch 6 loss: [32.13884162902832, 0.03515470400452614]\n",
      "  batch 8 loss: [36.2683219909668, 0.11776240915060043]\n",
      "  batch 10 loss: [32.477782249450684, 0.1591560523957014]\n",
      "  batch 12 loss: [30.37519645690918, 0.15030040219426155]\n",
      "  batch 14 loss: [37.06660079956055, 0.20590141415596008]\n",
      "  batch 16 loss: [31.944583892822266, 0.11223146691918373]\n",
      "  batch 18 loss: [30.81155300140381, 0.03524039685726166]\n",
      "  batch 20 loss: [27.23080348968506, 0.041336121037602425]\n",
      "  batch 22 loss: [36.642767906188965, 0.07719910889863968]\n",
      "  batch 24 loss: [37.03632354736328, 0.11234571784734726]\n",
      "  batch 26 loss: [34.138235092163086, 0.0865088626742363]\n",
      "  batch 28 loss: [33.38717746734619, 0.04103647917509079]\n",
      "  batch 30 loss: [27.724632263183594, 0.05495778098702431]\n",
      "  batch 32 loss: [28.494394302368164, 0.03020996693521738]\n",
      "  batch 34 loss: [33.587223052978516, 0.044689711183309555]\n",
      "  batch 36 loss: [29.13442611694336, 0.04081808030605316]\n",
      "  batch 38 loss: [30.411240577697754, 0.042252903804183006]\n",
      "  batch 40 loss: [30.611592292785645, 0.21028202027082443]\n",
      "  batch 42 loss: [30.604880332946777, 0.3805307596921921]\n",
      "  batch 44 loss: [27.524968147277832, 0.115374606102705]\n",
      "  batch 46 loss: [30.595291137695312, 0.12374749779701233]\n",
      "  batch 48 loss: [28.747655868530273, 0.06635161489248276]\n",
      "  batch 50 loss: [27.658252716064453, 0.13745789416134357]\n",
      "  batch 52 loss: [38.728816986083984, 0.11728837713599205]\n",
      "  batch 54 loss: [37.925045013427734, 0.13520993292331696]\n",
      "LOSS generator 37.925045013427734 discriminator 0.13520993292331696\n",
      "EPOCH 59:\n",
      "  batch 0 loss: [33.03777313232422, 0.09014907479286194]\n",
      "  batch 2 loss: [28.461739540100098, 0.08407578244805336]\n",
      "  batch 4 loss: [29.64558506011963, 0.0733647532761097]\n",
      "  batch 6 loss: [32.669111251831055, 0.07861969992518425]\n",
      "  batch 8 loss: [33.53144645690918, 0.055152107030153275]\n",
      "  batch 10 loss: [35.07837104797363, 0.07980026118457317]\n",
      "  batch 12 loss: [31.464292526245117, 0.12329231947660446]\n",
      "  batch 14 loss: [30.375388145446777, 0.0796166518703103]\n",
      "  batch 16 loss: [35.113908767700195, 0.054941751062870026]\n",
      "  batch 18 loss: [29.186244010925293, 0.10251592099666595]\n",
      "  batch 20 loss: [33.71884727478027, 0.11274813488125801]\n",
      "  batch 22 loss: [30.510003089904785, 0.05094795115292072]\n",
      "  batch 24 loss: [35.431671142578125, 0.09690622240304947]\n",
      "  batch 26 loss: [31.910022735595703, 0.06396199762821198]\n",
      "  batch 28 loss: [32.50907516479492, 0.09660929441452026]\n",
      "  batch 30 loss: [30.892236709594727, 0.08967825770378113]\n",
      "  batch 32 loss: [33.39459800720215, 0.0442958939820528]\n",
      "  batch 34 loss: [30.84317398071289, 0.0882873497903347]\n",
      "  batch 36 loss: [37.07023048400879, 0.11528670787811279]\n",
      "  batch 38 loss: [31.866793632507324, 0.0540350079536438]\n",
      "  batch 40 loss: [36.31093788146973, 0.06327379308640957]\n",
      "  batch 42 loss: [28.57192611694336, 0.13739288598299026]\n",
      "  batch 44 loss: [33.04807662963867, 0.023373025469481945]\n",
      "  batch 46 loss: [32.334811210632324, 0.11817459017038345]\n",
      "  batch 48 loss: [28.71896743774414, 0.11689774692058563]\n",
      "  batch 50 loss: [32.212342262268066, 0.027176625095307827]\n",
      "  batch 52 loss: [30.6162109375, 0.04435805603861809]\n",
      "  batch 54 loss: [30.601573944091797, 0.02628372423350811]\n",
      "LOSS generator 30.601573944091797 discriminator 0.02628372423350811\n",
      "EPOCH 60:\n",
      "  batch 0 loss: [36.44526672363281, 0.04526752606034279]\n",
      "  batch 2 loss: [33.61677360534668, 0.10317664965987206]\n",
      "  batch 4 loss: [30.223137855529785, 0.063335120677948]\n",
      "  batch 6 loss: [30.757841110229492, 0.033410049974918365]\n",
      "  batch 8 loss: [30.654690742492676, 0.062101101502776146]\n",
      "  batch 10 loss: [31.912386894226074, 0.049409013241529465]\n",
      "  batch 12 loss: [34.40648651123047, 0.01334192929789424]\n",
      "  batch 14 loss: [32.2741813659668, 0.1199469193816185]\n",
      "  batch 16 loss: [37.49343681335449, 0.10130205005407333]\n",
      "  batch 18 loss: [31.472126007080078, 0.034785013645887375]\n",
      "  batch 20 loss: [32.396568298339844, 0.1138383150100708]\n",
      "  batch 22 loss: [29.73078727722168, 0.04314067214727402]\n",
      "  batch 24 loss: [30.855453491210938, 0.038526514545083046]\n",
      "  batch 26 loss: [31.416227340698242, 0.16668488644063473]\n",
      "  batch 28 loss: [35.90696144104004, 0.05515596084296703]\n",
      "  batch 30 loss: [35.62998008728027, 0.04515633452683687]\n",
      "  batch 32 loss: [34.175527572631836, 0.07894225418567657]\n",
      "  batch 34 loss: [30.83982276916504, 0.07157925888895988]\n",
      "  batch 36 loss: [27.15168857574463, 0.10532740503549576]\n",
      "  batch 38 loss: [32.44773292541504, 0.05081509053707123]\n",
      "  batch 40 loss: [35.196109771728516, 0.028828707989305258]\n",
      "  batch 42 loss: [30.70981502532959, 0.01847009500488639]\n",
      "  batch 44 loss: [28.092001914978027, 0.026897145435214043]\n",
      "  batch 46 loss: [36.23349189758301, 0.09223528020083904]\n",
      "  batch 48 loss: [38.314476013183594, 0.1784534901380539]\n",
      "  batch 50 loss: [35.89337921142578, 0.05749867670238018]\n",
      "  batch 52 loss: [27.7636079788208, 0.05162270739674568]\n",
      "  batch 54 loss: [27.16602325439453, 0.0489585530012846]\n",
      "LOSS generator 27.16602325439453 discriminator 0.0489585530012846\n",
      "EPOCH 61:\n",
      "  batch 0 loss: [34.330726623535156, 0.05412190034985542]\n",
      "  batch 2 loss: [42.73514938354492, 0.136539027094841]\n",
      "  batch 4 loss: [31.41346263885498, 0.14894147962331772]\n",
      "  batch 6 loss: [26.840237617492676, 0.07536420226097107]\n",
      "  batch 8 loss: [31.38123893737793, 0.07757852971553802]\n",
      "  batch 10 loss: [34.64383506774902, 0.06792718917131424]\n",
      "  batch 12 loss: [32.52632713317871, 0.01648782193660736]\n",
      "  batch 14 loss: [31.172828674316406, 0.04763820022344589]\n",
      "  batch 16 loss: [35.07010269165039, 0.13200675696134567]\n",
      "  batch 18 loss: [30.259760856628418, 0.13617984764277935]\n",
      "  batch 20 loss: [35.99510192871094, 0.07130254805088043]\n",
      "  batch 22 loss: [32.64494514465332, 0.03844595141708851]\n",
      "  batch 24 loss: [34.08767604827881, 0.04326812922954559]\n",
      "  batch 26 loss: [28.130128860473633, 0.030105939134955406]\n",
      "  batch 28 loss: [34.553470611572266, 0.08837412297725677]\n",
      "  batch 30 loss: [37.34147262573242, 0.03201552573591471]\n",
      "  batch 32 loss: [30.65616798400879, 0.15975875593721867]\n",
      "  batch 34 loss: [29.089804649353027, 0.4681592881679535]\n",
      "  batch 36 loss: [31.168912887573242, 0.4107882082462311]\n",
      "  batch 38 loss: [29.07423686981201, 0.0703806933015585]\n",
      "  batch 40 loss: [35.238508224487305, 0.28926991671323776]\n",
      "  batch 42 loss: [26.1136417388916, 0.07659051567316055]\n",
      "  batch 44 loss: [31.275446891784668, 0.03971300274133682]\n",
      "  batch 46 loss: [26.635204315185547, 0.1320125050842762]\n",
      "  batch 48 loss: [32.96572971343994, 0.027229015715420246]\n",
      "  batch 50 loss: [35.347787857055664, 0.06262033060193062]\n",
      "  batch 52 loss: [29.072298049926758, 0.16010574251413345]\n",
      "  batch 54 loss: [30.689279556274414, 0.08415083587169647]\n",
      "LOSS generator 30.689279556274414 discriminator 0.08415083587169647\n",
      "EPOCH 62:\n",
      "  batch 0 loss: [28.845317840576172, 0.03835863620042801]\n",
      "  batch 2 loss: [37.723026275634766, 0.06289036106318235]\n",
      "  batch 4 loss: [34.28727149963379, 0.06927540339529514]\n",
      "  batch 6 loss: [32.959330558776855, 0.0777805894613266]\n",
      "  batch 8 loss: [33.841068267822266, 0.11130212061107159]\n",
      "  batch 10 loss: [36.356682777404785, 0.2655678763985634]\n",
      "  batch 12 loss: [33.49549198150635, 0.10757981240749359]\n",
      "  batch 14 loss: [32.46412944793701, 0.018636051565408707]\n",
      "  batch 16 loss: [26.69649600982666, 0.03440575487911701]\n",
      "  batch 18 loss: [34.12376308441162, 0.0951123759150505]\n",
      "  batch 20 loss: [27.08824348449707, 0.04448870196938515]\n",
      "  batch 22 loss: [31.01445484161377, 0.056511505506932735]\n",
      "  batch 24 loss: [32.441144943237305, 0.08678294159471989]\n",
      "  batch 26 loss: [33.181522369384766, 0.14674111269414425]\n",
      "  batch 28 loss: [33.84349060058594, 0.11654237471520901]\n",
      "  batch 30 loss: [29.77077865600586, 0.2024969980120659]\n",
      "  batch 32 loss: [29.263620376586914, 0.7668195366859436]\n",
      "  batch 34 loss: [29.185972213745117, 1.8879725933074951]\n",
      "  batch 36 loss: [28.783499717712402, 1.3872670531272888]\n",
      "  batch 38 loss: [28.443968772888184, 1.5310600996017456]\n",
      "  batch 40 loss: [29.701242446899414, 1.2316385507583618]\n",
      "  batch 42 loss: [26.35338020324707, 1.2050989866256714]\n",
      "  batch 44 loss: [30.99018096923828, 0.9275660514831543]\n",
      "  batch 46 loss: [21.73666477203369, 0.8484247326850891]\n",
      "  batch 48 loss: [34.17746162414551, 1.116770625114441]\n",
      "  batch 50 loss: [26.551952362060547, 0.7632022798061371]\n",
      "  batch 52 loss: [31.672508239746094, 0.8106592297554016]\n",
      "  batch 54 loss: [31.342883110046387, 0.9693564772605896]\n",
      "LOSS generator 31.342883110046387 discriminator 0.9693564772605896\n",
      "EPOCH 63:\n",
      "  batch 0 loss: [29.647920608520508, 0.7616608142852783]\n",
      "  batch 2 loss: [26.316311836242676, 0.7134662866592407]\n",
      "  batch 4 loss: [29.02453327178955, 0.7620689570903778]\n",
      "  batch 6 loss: [30.352401733398438, 0.727534294128418]\n",
      "  batch 8 loss: [31.286463737487793, 0.9305456578731537]\n",
      "  batch 10 loss: [26.386327743530273, 0.7228109240531921]\n",
      "  batch 12 loss: [24.871867179870605, 0.761819064617157]\n",
      "  batch 14 loss: [25.750555992126465, 0.72604700922966]\n",
      "  batch 16 loss: [29.241987228393555, 0.6977132558822632]\n",
      "  batch 18 loss: [26.234529495239258, 0.6811152100563049]\n",
      "  batch 20 loss: [26.883708953857422, 0.6786171197891235]\n",
      "  batch 22 loss: [23.71779155731201, 0.7005344033241272]\n",
      "  batch 24 loss: [32.06405162811279, 0.8055736124515533]\n",
      "  batch 26 loss: [27.71389102935791, 0.6997056007385254]\n",
      "  batch 28 loss: [25.174866676330566, 0.741072803735733]\n",
      "  batch 30 loss: [34.76667022705078, 0.6979873776435852]\n",
      "  batch 32 loss: [24.90304470062256, 0.7021448910236359]\n",
      "  batch 34 loss: [31.378368377685547, 0.7839044332504272]\n",
      "  batch 36 loss: [32.96231269836426, 0.7375265955924988]\n",
      "  batch 38 loss: [35.75133514404297, 0.8462672233581543]\n",
      "  batch 40 loss: [28.442731857299805, 0.6897730529308319]\n",
      "  batch 42 loss: [28.41019344329834, 0.7349123954772949]\n",
      "  batch 44 loss: [25.4641056060791, 0.671122670173645]\n",
      "  batch 46 loss: [23.575736045837402, 0.6894614100456238]\n",
      "  batch 48 loss: [30.86049461364746, 0.7305838763713837]\n",
      "  batch 50 loss: [25.639086723327637, 0.6897077858448029]\n",
      "  batch 52 loss: [31.073259353637695, 0.6535607874393463]\n",
      "  batch 54 loss: [33.06857109069824, 0.7120769023895264]\n",
      "LOSS generator 33.06857109069824 discriminator 0.7120769023895264\n",
      "EPOCH 64:\n",
      "  batch 0 loss: [26.69115447998047, 0.6703964471817017]\n",
      "  batch 2 loss: [25.49437141418457, 0.720393717288971]\n",
      "  batch 4 loss: [24.421072006225586, 0.6679245829582214]\n",
      "  batch 6 loss: [30.491880416870117, 0.6738930344581604]\n",
      "  batch 8 loss: [25.783369064331055, 0.6587232649326324]\n",
      "  batch 10 loss: [30.835124969482422, 0.6791060864925385]\n",
      "  batch 12 loss: [29.70323657989502, 0.6678088903427124]\n",
      "  batch 14 loss: [28.254945755004883, 0.6695994734764099]\n",
      "  batch 16 loss: [25.623849868774414, 0.6718705892562866]\n",
      "  batch 18 loss: [32.09397602081299, 0.6666383743286133]\n",
      "  batch 20 loss: [25.39805793762207, 0.6854400634765625]\n",
      "  batch 22 loss: [28.86804962158203, 0.7067663371562958]\n",
      "  batch 24 loss: [31.551921844482422, 0.6791102588176727]\n",
      "  batch 26 loss: [26.50642681121826, 0.6806313395500183]\n",
      "  batch 28 loss: [23.214160919189453, 0.6386757791042328]\n",
      "  batch 30 loss: [32.73657703399658, 0.6457893252372742]\n",
      "  batch 32 loss: [28.65363597869873, 0.6254601776599884]\n",
      "  batch 34 loss: [27.19722843170166, 0.6923176348209381]\n",
      "  batch 36 loss: [28.658536911010742, 0.6492946147918701]\n",
      "  batch 38 loss: [27.047698974609375, 0.6024234890937805]\n",
      "  batch 40 loss: [33.29360771179199, 0.6696636974811554]\n",
      "  batch 42 loss: [30.345025062561035, 0.6761239171028137]\n",
      "  batch 44 loss: [33.584768295288086, 0.6874445676803589]\n",
      "  batch 46 loss: [28.42209815979004, 0.6196429133415222]\n",
      "  batch 48 loss: [26.369154930114746, 0.5933000445365906]\n",
      "  batch 50 loss: [29.86658763885498, 0.5639856159687042]\n",
      "  batch 52 loss: [27.975727081298828, 0.6310677528381348]\n",
      "  batch 54 loss: [30.57841682434082, 0.6285809874534607]\n",
      "LOSS generator 30.57841682434082 discriminator 0.6285809874534607\n",
      "EPOCH 65:\n",
      "  batch 0 loss: [31.584163665771484, 0.7328446507453918]\n",
      "  batch 2 loss: [34.8928108215332, 0.6809142827987671]\n",
      "  batch 4 loss: [30.219740867614746, 0.6290635764598846]\n",
      "  batch 6 loss: [30.214197158813477, 0.5949514508247375]\n",
      "  batch 8 loss: [31.60054588317871, 0.5932553112506866]\n",
      "  batch 10 loss: [29.394309997558594, 0.5315475463867188]\n",
      "  batch 12 loss: [27.228879928588867, 0.5070831179618835]\n",
      "  batch 14 loss: [26.491004943847656, 0.48935556411743164]\n",
      "  batch 16 loss: [26.729001998901367, 0.6152960360050201]\n",
      "  batch 18 loss: [29.18781280517578, 0.5477824062108994]\n",
      "  batch 20 loss: [24.52828884124756, 0.5309590101242065]\n",
      "  batch 22 loss: [28.712757110595703, 0.5946143567562103]\n",
      "  batch 24 loss: [24.183189392089844, 0.5846714973449707]\n",
      "  batch 26 loss: [30.05287742614746, 0.6076121628284454]\n",
      "  batch 28 loss: [24.843759536743164, 0.5548314452171326]\n",
      "  batch 30 loss: [29.819965362548828, 0.6893102824687958]\n",
      "  batch 32 loss: [33.13997268676758, 0.8096815943717957]\n",
      "  batch 34 loss: [25.781826972961426, 0.5394695401191711]\n",
      "  batch 36 loss: [26.675392150878906, 0.5635609924793243]\n",
      "  batch 38 loss: [28.39927101135254, 0.9136831760406494]\n",
      "  batch 40 loss: [26.507678031921387, 0.7293568849563599]\n",
      "  batch 42 loss: [27.59976577758789, 0.6660288572311401]\n",
      "  batch 44 loss: [28.088212966918945, 0.6741091012954712]\n",
      "  batch 46 loss: [28.22648525238037, 0.6076571941375732]\n",
      "  batch 48 loss: [36.82019329071045, 0.660415768623352]\n",
      "  batch 50 loss: [24.112842559814453, 0.605611115694046]\n",
      "  batch 52 loss: [31.69044017791748, 0.5977455675601959]\n",
      "  batch 54 loss: [32.54863739013672, 0.5991557836532593]\n",
      "LOSS generator 32.54863739013672 discriminator 0.5991557836532593\n",
      "EPOCH 66:\n",
      "  batch 0 loss: [38.2261962890625, 0.8440213203430176]\n",
      "  batch 2 loss: [27.201319694519043, 0.5336129367351532]\n",
      "  batch 4 loss: [31.409180641174316, 0.618066668510437]\n",
      "  batch 6 loss: [25.612919807434082, 0.6191148161888123]\n",
      "  batch 8 loss: [31.394492149353027, 0.5905815958976746]\n",
      "  batch 10 loss: [30.002137184143066, 0.4389001727104187]\n",
      "  batch 12 loss: [33.78377151489258, 0.4849724769592285]\n",
      "  batch 14 loss: [28.141637802124023, 0.4760248064994812]\n",
      "  batch 16 loss: [30.814494132995605, 0.40617503225803375]\n",
      "  batch 18 loss: [27.25914478302002, 0.4581651836633682]\n",
      "  batch 20 loss: [25.546059608459473, 0.4832099378108978]\n",
      "  batch 22 loss: [26.967811584472656, 0.4724136292934418]\n",
      "  batch 24 loss: [31.880117416381836, 0.668517529964447]\n",
      "  batch 26 loss: [29.65054702758789, 1.117132544517517]\n",
      "  batch 28 loss: [31.93377113342285, 0.7268755733966827]\n",
      "  batch 30 loss: [30.587393760681152, 0.5502810478210449]\n",
      "  batch 32 loss: [28.86325454711914, 0.4993458390235901]\n",
      "  batch 34 loss: [32.49586296081543, 0.5186804234981537]\n",
      "  batch 36 loss: [23.206997871398926, 0.5094472169876099]\n",
      "  batch 38 loss: [29.31569480895996, 0.5745535790920258]\n",
      "  batch 40 loss: [30.44555377960205, 0.4409336596727371]\n",
      "  batch 42 loss: [30.660764694213867, 0.4058528244495392]\n",
      "  batch 44 loss: [24.904056549072266, 0.460563063621521]\n",
      "  batch 46 loss: [22.969016075134277, 0.48115625977516174]\n",
      "  batch 48 loss: [28.708739280700684, 0.4720073342323303]\n",
      "  batch 50 loss: [28.20938777923584, 0.3387480676174164]\n",
      "  batch 52 loss: [28.962992668151855, 0.3588093966245651]\n",
      "  batch 54 loss: [33.009477615356445, 0.3903142362833023]\n",
      "LOSS generator 33.009477615356445 discriminator 0.3903142362833023\n",
      "EPOCH 67:\n",
      "  batch 0 loss: [31.83686637878418, 0.4546689987182617]\n",
      "  batch 2 loss: [27.251463890075684, 0.2814416289329529]\n",
      "  batch 4 loss: [37.12994384765625, 0.5258912146091461]\n",
      "  batch 6 loss: [32.22562026977539, 0.5279097259044647]\n",
      "  batch 8 loss: [27.160991668701172, 0.31088097393512726]\n",
      "  batch 10 loss: [27.274105072021484, 0.5402280688285828]\n",
      "  batch 12 loss: [30.69034767150879, 0.4423714727163315]\n",
      "  batch 14 loss: [26.401552200317383, 0.42737261950969696]\n",
      "  batch 16 loss: [25.729098320007324, 0.3811216503381729]\n",
      "  batch 18 loss: [28.59769630432129, 0.4505266547203064]\n",
      "  batch 20 loss: [30.21277904510498, 0.5054779648780823]\n",
      "  batch 22 loss: [35.25260353088379, 0.5559757649898529]\n",
      "  batch 24 loss: [31.40860080718994, 0.45311465859413147]\n",
      "  batch 26 loss: [26.022334098815918, 0.49976640939712524]\n",
      "  batch 28 loss: [25.68936252593994, 0.48739148676395416]\n",
      "  batch 30 loss: [25.08166217803955, 0.4828934669494629]\n",
      "  batch 32 loss: [24.518474578857422, 0.4046987295150757]\n",
      "  batch 34 loss: [32.734365463256836, 0.4125414490699768]\n",
      "  batch 36 loss: [27.20527744293213, 0.3726261109113693]\n",
      "  batch 38 loss: [32.02150535583496, 0.5025869011878967]\n",
      "  batch 40 loss: [31.172536849975586, 0.614235132932663]\n",
      "  batch 42 loss: [29.729199409484863, 0.3516588509082794]\n",
      "  batch 44 loss: [28.556386947631836, 0.4039789140224457]\n",
      "  batch 46 loss: [29.17821502685547, 0.294410839676857]\n",
      "  batch 48 loss: [29.439414024353027, 0.4801071435213089]\n",
      "  batch 50 loss: [33.31331253051758, 0.5036413371562958]\n",
      "  batch 52 loss: [28.94089984893799, 0.5394648313522339]\n",
      "  batch 54 loss: [28.635984420776367, 0.4058179557323456]\n",
      "LOSS generator 28.635984420776367 discriminator 0.4058179557323456\n",
      "EPOCH 68:\n",
      "  batch 0 loss: [24.224214553833008, 0.5742520689964294]\n",
      "  batch 2 loss: [32.0029239654541, 0.32683609426021576]\n",
      "  batch 4 loss: [31.9145450592041, 0.26011157035827637]\n",
      "  batch 6 loss: [32.90482807159424, 0.26040519028902054]\n",
      "  batch 8 loss: [33.86447811126709, 0.3944568336009979]\n",
      "  batch 10 loss: [22.172176361083984, 0.39277561008930206]\n",
      "  batch 12 loss: [27.593647003173828, 0.3368890732526779]\n",
      "  batch 14 loss: [27.047502517700195, 0.27519257366657257]\n",
      "  batch 16 loss: [27.035496711730957, 0.2554379552602768]\n",
      "  batch 18 loss: [25.385597229003906, 0.2803717106580734]\n",
      "  batch 20 loss: [33.28020477294922, 0.39684687554836273]\n",
      "  batch 22 loss: [32.88784885406494, 0.388429194688797]\n",
      "  batch 24 loss: [27.772111892700195, 0.2533913403749466]\n",
      "  batch 26 loss: [32.70145225524902, 0.5634998679161072]\n",
      "  batch 28 loss: [30.858293533325195, 0.3389994502067566]\n",
      "  batch 30 loss: [31.78998851776123, 0.2532874196767807]\n",
      "  batch 32 loss: [25.1620512008667, 0.3387766182422638]\n",
      "  batch 34 loss: [31.614118576049805, 0.23827046155929565]\n",
      "  batch 36 loss: [32.574480056762695, 0.3707272559404373]\n",
      "  batch 38 loss: [30.472871780395508, 0.26632893085479736]\n",
      "  batch 40 loss: [34.58145999908447, 0.2889125645160675]\n",
      "  batch 42 loss: [29.72867774963379, 0.22980213165283203]\n",
      "  batch 44 loss: [29.30574131011963, 0.3532131463289261]\n",
      "  batch 46 loss: [29.57423686981201, 0.37796923518180847]\n",
      "  batch 48 loss: [28.54762363433838, 0.34180621802806854]\n",
      "  batch 50 loss: [27.095955848693848, 0.5149957239627838]\n",
      "  batch 52 loss: [23.677122116088867, 0.5478116273880005]\n",
      "  batch 54 loss: [28.072307586669922, 0.442901611328125]\n",
      "LOSS generator 28.072307586669922 discriminator 0.442901611328125\n",
      "EPOCH 69:\n",
      "  batch 0 loss: [35.60272979736328, 0.8247033953666687]\n",
      "  batch 2 loss: [33.66818618774414, 0.7684805989265442]\n",
      "  batch 4 loss: [33.59347152709961, 0.4109446406364441]\n",
      "  batch 6 loss: [25.618288040161133, 0.41169707477092743]\n",
      "  batch 8 loss: [27.673827171325684, 0.401927649974823]\n",
      "  batch 10 loss: [24.84490394592285, 0.2974460870027542]\n",
      "  batch 12 loss: [29.191781997680664, 0.2701544910669327]\n",
      "  batch 14 loss: [30.491366386413574, 0.3305797576904297]\n",
      "  batch 16 loss: [29.10927391052246, 0.18862685561180115]\n",
      "  batch 18 loss: [28.7436466217041, 0.30944859981536865]\n",
      "  batch 20 loss: [29.94942855834961, 0.25801025331020355]\n",
      "  batch 22 loss: [30.899147033691406, 0.29633402079343796]\n",
      "  batch 24 loss: [30.407261848449707, 0.31989362835884094]\n",
      "  batch 26 loss: [29.045287132263184, 0.19359812885522842]\n",
      "  batch 28 loss: [35.0043888092041, 0.2089873030781746]\n",
      "  batch 30 loss: [25.342639923095703, 0.4164234697818756]\n",
      "  batch 32 loss: [31.04786205291748, 0.26539190113544464]\n",
      "  batch 34 loss: [30.807915687561035, 0.3535866290330887]\n",
      "  batch 36 loss: [29.907999992370605, 0.2939452528953552]\n",
      "  batch 38 loss: [31.505236625671387, 0.33645443618297577]\n",
      "  batch 40 loss: [24.030848503112793, 0.304019495844841]\n",
      "  batch 42 loss: [30.468183517456055, 0.35845546424388885]\n",
      "  batch 44 loss: [28.187490463256836, 0.27046705037355423]\n",
      "  batch 46 loss: [33.625739097595215, 0.3988206833600998]\n",
      "  batch 48 loss: [26.887080192565918, 0.36342501640319824]\n",
      "  batch 50 loss: [24.37951946258545, 0.2693913206458092]\n",
      "  batch 52 loss: [32.41672229766846, 0.40670980513095856]\n",
      "  batch 54 loss: [34.7935266494751, 0.2949594259262085]\n",
      "LOSS generator 34.7935266494751 discriminator 0.2949594259262085\n",
      "EPOCH 70:\n",
      "  batch 0 loss: [26.6672420501709, 0.18226101994514465]\n",
      "  batch 2 loss: [29.368799209594727, 0.18275123089551926]\n",
      "  batch 4 loss: [22.76231288909912, 0.23312459886074066]\n",
      "  batch 6 loss: [26.52398681640625, 0.18947847187519073]\n",
      "  batch 8 loss: [27.93071937561035, 0.23231060057878494]\n",
      "  batch 10 loss: [36.72164535522461, 0.3485960066318512]\n",
      "  batch 12 loss: [34.14608955383301, 0.3672878071665764]\n",
      "  batch 14 loss: [28.78433895111084, 0.258670836687088]\n",
      "  batch 16 loss: [30.17490291595459, 0.3281365782022476]\n",
      "  batch 18 loss: [27.919068336486816, 0.3348725438117981]\n",
      "  batch 20 loss: [27.891562461853027, 0.16303688287734985]\n",
      "  batch 22 loss: [34.603373527526855, 0.3284645229578018]\n",
      "  batch 24 loss: [30.73420524597168, 0.14336879551410675]\n",
      "  batch 26 loss: [26.343453407287598, 0.2411448359489441]\n",
      "  batch 28 loss: [34.308926582336426, 0.3079439550638199]\n",
      "  batch 30 loss: [28.90788173675537, 0.2489739954471588]\n",
      "  batch 32 loss: [31.439743995666504, 0.22340445220470428]\n",
      "  batch 34 loss: [32.80574893951416, 0.382079616189003]\n",
      "  batch 36 loss: [30.234522819519043, 0.2171849012374878]\n",
      "  batch 38 loss: [32.83900451660156, 0.17253011465072632]\n",
      "  batch 40 loss: [30.1631498336792, 0.18849800527095795]\n",
      "  batch 42 loss: [33.89659309387207, 0.31356342881917953]\n",
      "  batch 44 loss: [32.104105949401855, 0.28174860775470734]\n",
      "  batch 46 loss: [29.951247215270996, 0.17735418304800987]\n",
      "  batch 48 loss: [22.974326133728027, 0.30031872540712357]\n",
      "  batch 50 loss: [33.09357929229736, 0.23102225363254547]\n",
      "  batch 52 loss: [34.4039306640625, 0.3059270977973938]\n",
      "  batch 54 loss: [27.57109832763672, 0.38390766829252243]\n",
      "LOSS generator 27.57109832763672 discriminator 0.38390766829252243\n",
      "EPOCH 71:\n",
      "  batch 0 loss: [25.6541748046875, 0.25168052315711975]\n",
      "  batch 2 loss: [27.959856033325195, 0.20611459016799927]\n",
      "  batch 4 loss: [35.14430618286133, 0.12105994671583176]\n",
      "  batch 6 loss: [33.673583984375, 0.2399986833333969]\n",
      "  batch 8 loss: [34.611040115356445, 0.16608025133609772]\n",
      "  batch 10 loss: [32.81881332397461, 0.18286266922950745]\n",
      "  batch 12 loss: [27.18059539794922, 0.35927680134773254]\n",
      "  batch 14 loss: [24.601137161254883, 0.21335382759571075]\n",
      "  batch 16 loss: [25.590596199035645, 0.18854069709777832]\n",
      "  batch 18 loss: [32.24359703063965, 0.15392392128705978]\n",
      "  batch 20 loss: [28.835148811340332, 0.32040072977542877]\n",
      "  batch 22 loss: [28.259449005126953, 0.2993827238678932]\n",
      "  batch 24 loss: [30.724206924438477, 0.4194934815168381]\n",
      "  batch 26 loss: [34.20298194885254, 0.2726670205593109]\n",
      "  batch 28 loss: [29.81717014312744, 0.28088561445474625]\n",
      "  batch 30 loss: [27.413570404052734, 0.20586348325014114]\n",
      "  batch 32 loss: [35.43921089172363, 0.27505408227443695]\n",
      "  batch 34 loss: [26.509549140930176, 0.3622117191553116]\n",
      "  batch 36 loss: [29.1365385055542, 0.3117464482784271]\n",
      "  batch 38 loss: [26.762500762939453, 0.32304510474205017]\n",
      "  batch 40 loss: [33.40401649475098, 0.19255900382995605]\n",
      "  batch 42 loss: [26.746216773986816, 0.19902142137289047]\n",
      "  batch 44 loss: [31.950778007507324, 0.1916564367711544]\n",
      "  batch 46 loss: [26.37628173828125, 0.23717397451400757]\n",
      "  batch 48 loss: [38.96076583862305, 0.4055366963148117]\n",
      "  batch 50 loss: [30.822267532348633, 0.2569514065980911]\n",
      "  batch 52 loss: [31.981443405151367, 0.20827852189540863]\n",
      "  batch 54 loss: [30.06879997253418, 0.1909966617822647]\n",
      "LOSS generator 30.06879997253418 discriminator 0.1909966617822647\n",
      "EPOCH 72:\n",
      "  batch 0 loss: [29.44969367980957, 0.20477277040481567]\n",
      "  batch 2 loss: [28.976149559020996, 0.14949636161327362]\n",
      "  batch 4 loss: [25.154765129089355, 0.20184624940156937]\n",
      "  batch 6 loss: [35.28150749206543, 0.29268819093704224]\n",
      "  batch 8 loss: [27.67409896850586, 0.16269785910844803]\n",
      "  batch 10 loss: [26.701736450195312, 0.2461840957403183]\n",
      "  batch 12 loss: [30.177470207214355, 0.35233116149902344]\n",
      "  batch 14 loss: [29.621006965637207, 0.3542880266904831]\n",
      "  batch 16 loss: [31.106749534606934, 0.25146377831697464]\n",
      "  batch 18 loss: [28.065122604370117, 0.32091642916202545]\n",
      "  batch 20 loss: [30.185270309448242, 0.256069079041481]\n",
      "  batch 22 loss: [30.928523063659668, 0.21159148216247559]\n",
      "  batch 24 loss: [28.459882736206055, 0.20499064773321152]\n",
      "  batch 26 loss: [27.825393676757812, 0.2225777953863144]\n",
      "  batch 28 loss: [37.5050106048584, 0.254585362970829]\n",
      "  batch 30 loss: [35.32307243347168, 0.1437530517578125]\n",
      "  batch 32 loss: [31.10323715209961, 0.09123187512159348]\n",
      "  batch 34 loss: [28.64708137512207, 0.07560429722070694]\n",
      "  batch 36 loss: [29.716535568237305, 0.14795449376106262]\n",
      "  batch 38 loss: [32.75074863433838, 0.15040837228298187]\n",
      "  batch 40 loss: [32.367923736572266, 0.07945514470338821]\n",
      "  batch 42 loss: [32.06183910369873, 0.2711498364806175]\n",
      "  batch 44 loss: [28.669279098510742, 0.22123787552118301]\n",
      "  batch 46 loss: [31.197327613830566, 0.08551859110593796]\n",
      "  batch 48 loss: [32.74525165557861, 0.04837942495942116]\n",
      "  batch 50 loss: [32.075276374816895, 0.1375836245715618]\n",
      "  batch 52 loss: [36.34274101257324, 0.29908186197280884]\n",
      "  batch 54 loss: [30.457332611083984, 0.16339122503995895]\n",
      "LOSS generator 30.457332611083984 discriminator 0.16339122503995895\n",
      "EPOCH 73:\n",
      "  batch 0 loss: [25.04410171508789, 0.19472676515579224]\n",
      "  batch 2 loss: [30.92161750793457, 0.2012684866786003]\n",
      "  batch 4 loss: [28.42942523956299, 0.16433778405189514]\n",
      "  batch 6 loss: [35.750600814819336, 0.1266852542757988]\n",
      "  batch 8 loss: [29.379825592041016, 0.12306009978055954]\n",
      "  batch 10 loss: [36.651296615600586, 0.23268812894821167]\n",
      "  batch 12 loss: [33.013733863830566, 0.1975911185145378]\n",
      "  batch 14 loss: [30.51349925994873, 0.13356313109397888]\n",
      "  batch 16 loss: [34.777605056762695, 0.20175398886203766]\n",
      "  batch 18 loss: [27.816659927368164, 0.09692746587097645]\n",
      "  batch 20 loss: [25.892518043518066, 0.10843591392040253]\n",
      "  batch 22 loss: [29.24669361114502, 0.16425234824419022]\n",
      "  batch 24 loss: [29.776028633117676, 0.10876202210783958]\n",
      "  batch 26 loss: [26.83644390106201, 0.24737678468227386]\n",
      "  batch 28 loss: [40.00701713562012, 0.25567666441202164]\n",
      "  batch 30 loss: [33.554819107055664, 0.07085291668772697]\n",
      "  batch 32 loss: [27.950077056884766, 0.11510151252150536]\n",
      "  batch 34 loss: [29.482341766357422, 0.12537818029522896]\n",
      "  batch 36 loss: [31.716285705566406, 0.360604926943779]\n",
      "  batch 38 loss: [33.51289367675781, 0.3271380737423897]\n",
      "  batch 40 loss: [27.290746688842773, 0.3435206785798073]\n",
      "  batch 42 loss: [33.485307693481445, 0.17189110070466995]\n",
      "  batch 44 loss: [23.796576499938965, 0.26232267916202545]\n",
      "  batch 46 loss: [30.019210815429688, 0.16162197291851044]\n",
      "  batch 48 loss: [32.53882312774658, 0.14634880796074867]\n",
      "  batch 50 loss: [28.026482582092285, 0.17532635107636452]\n",
      "  batch 52 loss: [33.17500305175781, 0.30017152428627014]\n",
      "  batch 54 loss: [33.15959548950195, 0.2691747397184372]\n",
      "LOSS generator 33.15959548950195 discriminator 0.2691747397184372\n",
      "EPOCH 74:\n",
      "  batch 0 loss: [35.928646087646484, 0.1652768850326538]\n",
      "  batch 2 loss: [33.869794845581055, 0.2347104251384735]\n",
      "  batch 4 loss: [25.000473976135254, 0.20404187589883804]\n",
      "  batch 6 loss: [35.04685592651367, 0.2491849884390831]\n",
      "  batch 8 loss: [33.934091567993164, 0.4422938823699951]\n",
      "  batch 10 loss: [35.85757637023926, 0.18937598168849945]\n",
      "  batch 12 loss: [28.07771396636963, 0.19737572222948074]\n",
      "  batch 14 loss: [34.64187431335449, 0.14084689132869244]\n",
      "  batch 16 loss: [32.19630718231201, 0.1686292216181755]\n",
      "  batch 18 loss: [31.932523727416992, 0.27846160531044006]\n",
      "  batch 20 loss: [31.717819213867188, 0.09679218009114265]\n",
      "  batch 22 loss: [24.873226165771484, 0.12081804126501083]\n",
      "  batch 24 loss: [28.586039543151855, 0.08057515509426594]\n",
      "  batch 26 loss: [30.12704086303711, 0.13623972237110138]\n",
      "  batch 28 loss: [32.5178165435791, 0.10266219079494476]\n",
      "  batch 30 loss: [28.02872657775879, 0.160522922873497]\n",
      "  batch 32 loss: [27.841428756713867, 0.15056447684764862]\n",
      "  batch 34 loss: [35.665733337402344, 0.18904539197683334]\n",
      "  batch 36 loss: [33.176326751708984, 0.1132654920220375]\n",
      "  batch 38 loss: [24.800853729248047, 0.22827351093292236]\n",
      "  batch 40 loss: [36.60829734802246, 0.24063000828027725]\n",
      "  batch 42 loss: [31.573583602905273, 0.2760052904486656]\n",
      "  batch 44 loss: [35.42741584777832, 0.1439062375575304]\n",
      "  batch 46 loss: [25.634288787841797, 0.13313806429505348]\n",
      "  batch 48 loss: [26.542420387268066, 0.19418621063232422]\n",
      "  batch 50 loss: [26.550710678100586, 0.17797939479351044]\n",
      "  batch 52 loss: [30.29337787628174, 0.07382547482848167]\n",
      "  batch 54 loss: [36.84146499633789, 0.1605641096830368]\n",
      "LOSS generator 36.84146499633789 discriminator 0.1605641096830368\n",
      "EPOCH 75:\n",
      "  batch 0 loss: [30.3867244720459, 0.06256578117609024]\n",
      "  batch 2 loss: [31.634044647216797, 0.1062493696808815]\n",
      "  batch 4 loss: [30.559088706970215, 0.11485073901712894]\n",
      "  batch 6 loss: [32.00325584411621, 0.13323790207505226]\n",
      "  batch 8 loss: [27.168262481689453, 0.14944346994161606]\n",
      "  batch 10 loss: [32.65613269805908, 0.09501992166042328]\n",
      "  batch 12 loss: [30.019128799438477, 0.15056044608354568]\n",
      "  batch 14 loss: [33.41936111450195, 0.4167802035808563]\n",
      "  batch 16 loss: [26.853057861328125, 0.7458845376968384]\n",
      "  batch 18 loss: [29.701619148254395, 0.45870639383792877]\n",
      "  batch 20 loss: [30.63371467590332, 0.1923394501209259]\n",
      "  batch 22 loss: [31.785778999328613, 0.27698585391044617]\n",
      "  batch 24 loss: [31.380276679992676, 0.16260555386543274]\n",
      "  batch 26 loss: [24.951579093933105, 0.2318393588066101]\n",
      "  batch 28 loss: [33.06717872619629, 0.12961170077323914]\n",
      "  batch 30 loss: [29.187378883361816, 0.1386910118162632]\n",
      "  batch 32 loss: [27.87798309326172, 0.2864958792924881]\n",
      "  batch 34 loss: [32.50174427032471, 0.12745651975274086]\n",
      "  batch 36 loss: [33.35962677001953, 0.3395005092024803]\n",
      "  batch 38 loss: [25.938678741455078, 0.21505209058523178]\n",
      "  batch 40 loss: [33.43615531921387, 0.09921567142009735]\n",
      "  batch 42 loss: [33.90543556213379, 0.08999646082520485]\n",
      "  batch 44 loss: [29.41111660003662, 0.10702716559171677]\n",
      "  batch 46 loss: [30.067069053649902, 0.11510030552744865]\n",
      "  batch 48 loss: [31.308932304382324, 0.09238522499799728]\n",
      "  batch 50 loss: [31.982657432556152, 0.08127180300652981]\n",
      "  batch 52 loss: [33.8518009185791, 0.14160627126693726]\n",
      "  batch 54 loss: [35.1740665435791, 0.11469543725252151]\n",
      "LOSS generator 35.1740665435791 discriminator 0.11469543725252151\n",
      "EPOCH 76:\n",
      "  batch 0 loss: [29.162067413330078, 0.13545848429203033]\n",
      "  batch 2 loss: [33.358819007873535, 0.13022830337285995]\n",
      "  batch 4 loss: [27.384419441223145, 0.1826683208346367]\n",
      "  batch 6 loss: [31.834259033203125, 0.18876292556524277]\n",
      "  batch 8 loss: [32.7403450012207, 0.12123610824346542]\n",
      "  batch 10 loss: [25.719969749450684, 0.21263163536787033]\n",
      "  batch 12 loss: [28.95945930480957, 0.09067864902317524]\n",
      "  batch 14 loss: [32.63209247589111, 0.1997799575328827]\n",
      "  batch 16 loss: [30.274892807006836, 0.05867094546556473]\n",
      "  batch 18 loss: [36.011847496032715, 0.09686620905995369]\n",
      "  batch 20 loss: [39.1915864944458, 0.2747485190629959]\n",
      "  batch 22 loss: [35.86419868469238, 0.15069619566202164]\n",
      "  batch 24 loss: [27.94553279876709, 0.11230374500155449]\n",
      "  batch 26 loss: [33.272244453430176, 0.12078364565968513]\n",
      "  batch 28 loss: [31.124221801757812, 0.10137375444173813]\n",
      "  batch 30 loss: [32.28940200805664, 0.11115388199687004]\n",
      "  batch 32 loss: [33.34039306640625, 0.10944114997982979]\n",
      "  batch 34 loss: [26.81292724609375, 0.10532926023006439]\n",
      "  batch 36 loss: [30.736897468566895, 0.10552172362804413]\n",
      "  batch 38 loss: [32.56536102294922, 0.07650214061141014]\n",
      "  batch 40 loss: [30.074039459228516, 0.04570768587291241]\n",
      "  batch 42 loss: [31.867006301879883, 0.08543290942907333]\n",
      "  batch 44 loss: [28.316411018371582, 0.07296179234981537]\n",
      "  batch 46 loss: [31.466015815734863, 0.11321330070495605]\n",
      "  batch 48 loss: [25.427228927612305, 0.09993570297956467]\n",
      "  batch 50 loss: [28.482925415039062, 0.13567779958248138]\n",
      "  batch 52 loss: [32.619704246520996, 0.13806385919451714]\n",
      "  batch 54 loss: [34.93521308898926, 0.18324944376945496]\n",
      "LOSS generator 34.93521308898926 discriminator 0.18324944376945496\n",
      "EPOCH 77:\n",
      "  batch 0 loss: [31.408382415771484, 0.15379703044891357]\n",
      "  batch 2 loss: [26.29277992248535, 0.15433308482170105]\n",
      "  batch 4 loss: [32.14980125427246, 0.15022846311330795]\n",
      "  batch 6 loss: [27.250364303588867, 0.08692777529358864]\n",
      "  batch 8 loss: [32.005231857299805, 0.12375359237194061]\n",
      "  batch 10 loss: [32.52284812927246, 0.20536786317825317]\n",
      "  batch 12 loss: [29.211249351501465, 0.10566100850701332]\n",
      "  batch 14 loss: [31.176210403442383, 0.1600736677646637]\n",
      "  batch 16 loss: [33.86488723754883, 0.12667878344655037]\n",
      "  batch 18 loss: [32.792396545410156, 0.05043957382440567]\n",
      "  batch 20 loss: [32.603760719299316, 0.02879344020038843]\n",
      "  batch 22 loss: [33.28560256958008, 0.03018769808113575]\n",
      "  batch 24 loss: [30.34943675994873, 0.08718884736299515]\n",
      "  batch 26 loss: [27.820993423461914, 0.09230527654290199]\n",
      "  batch 28 loss: [35.53902721405029, 0.16078219562768936]\n",
      "  batch 30 loss: [37.61381530761719, 0.20817244797945023]\n",
      "  batch 32 loss: [29.295849800109863, 0.49980132281780243]\n",
      "  batch 34 loss: [25.983606338500977, 0.3291596621274948]\n",
      "  batch 36 loss: [36.95703887939453, 0.21942481398582458]\n",
      "  batch 38 loss: [27.461029052734375, 0.18214856088161469]\n",
      "  batch 40 loss: [31.689916610717773, 0.10955076105892658]\n",
      "  batch 42 loss: [31.989662170410156, 0.19988618791103363]\n",
      "  batch 44 loss: [27.96046257019043, 0.9225826412439346]\n",
      "  batch 46 loss: [32.97043991088867, 1.0244641304016113]\n",
      "  batch 48 loss: [26.09878921508789, 1.1194833517074585]\n",
      "  batch 50 loss: [32.350457191467285, 0.8983503580093384]\n",
      "  batch 52 loss: [32.592814445495605, 0.9194098114967346]\n",
      "  batch 54 loss: [28.445924758911133, 0.6633907556533813]\n",
      "LOSS generator 28.445924758911133 discriminator 0.6633907556533813\n",
      "EPOCH 78:\n",
      "  batch 0 loss: [23.011926651000977, 0.6132230758666992]\n",
      "  batch 2 loss: [29.30072021484375, 0.5767392218112946]\n",
      "  batch 4 loss: [28.972286224365234, 0.49372997879981995]\n",
      "  batch 6 loss: [25.395076751708984, 0.5540520995855331]\n",
      "  batch 8 loss: [28.044297218322754, 0.603382796049118]\n",
      "  batch 10 loss: [27.17857074737549, 0.8026619851589203]\n",
      "  batch 12 loss: [27.264187812805176, 0.6276837587356567]\n",
      "  batch 14 loss: [28.19670295715332, 0.5906347632408142]\n",
      "  batch 16 loss: [26.120768547058105, 0.552017092704773]\n",
      "  batch 18 loss: [27.50334644317627, 0.55089271068573]\n",
      "  batch 20 loss: [28.773548126220703, 0.3878796398639679]\n",
      "  batch 22 loss: [28.510683059692383, 0.403039813041687]\n",
      "  batch 24 loss: [25.784050941467285, 0.50072380900383]\n",
      "  batch 26 loss: [33.81369972229004, 0.5181346535682678]\n",
      "  batch 28 loss: [38.52447700500488, 0.5899279415607452]\n",
      "  batch 30 loss: [28.815800666809082, 0.47027212381362915]\n",
      "  batch 32 loss: [27.7451810836792, 0.3807542473077774]\n",
      "  batch 34 loss: [33.23397254943848, 0.3915039598941803]\n",
      "  batch 36 loss: [28.136853218078613, 0.38759179413318634]\n",
      "  batch 38 loss: [32.77321243286133, 0.40532785654067993]\n",
      "  batch 40 loss: [28.032602310180664, 0.3730819672346115]\n",
      "  batch 42 loss: [31.129018783569336, 0.23820039629936218]\n",
      "  batch 44 loss: [30.419923782348633, 0.2948635369539261]\n",
      "  batch 46 loss: [29.32198143005371, 0.2770916819572449]\n",
      "  batch 48 loss: [36.451066970825195, 0.3676362782716751]\n",
      "  batch 50 loss: [26.826844215393066, 0.1915649026632309]\n",
      "  batch 52 loss: [25.69480609893799, 0.18153341114521027]\n",
      "  batch 54 loss: [31.633877754211426, 0.28613893687725067]\n",
      "LOSS generator 31.633877754211426 discriminator 0.28613893687725067\n",
      "EPOCH 79:\n",
      "  batch 0 loss: [37.052947998046875, 0.32024234533309937]\n",
      "  batch 2 loss: [34.22736740112305, 0.16473015770316124]\n",
      "  batch 4 loss: [32.85486698150635, 0.1532035954296589]\n",
      "  batch 6 loss: [22.336109161376953, 0.41387420892715454]\n",
      "  batch 8 loss: [28.973583221435547, 0.3646998181939125]\n",
      "  batch 10 loss: [28.687366485595703, 0.18516549468040466]\n",
      "  batch 12 loss: [29.10331630706787, 0.3758369982242584]\n",
      "  batch 14 loss: [26.539587020874023, 0.3051460087299347]\n",
      "  batch 16 loss: [30.60252285003662, 0.23468783497810364]\n",
      "  batch 18 loss: [27.67758560180664, 0.23083358258008957]\n",
      "  batch 20 loss: [27.94182777404785, 0.23193316906690598]\n",
      "  batch 22 loss: [32.9915075302124, 0.33056963980197906]\n",
      "  batch 24 loss: [27.0820369720459, 0.5044115781784058]\n",
      "  batch 26 loss: [31.443674087524414, 0.5026492774486542]\n",
      "  batch 28 loss: [33.755587577819824, 0.5197892189025879]\n",
      "  batch 30 loss: [27.622140884399414, 0.448009729385376]\n",
      "  batch 32 loss: [28.917452812194824, 0.48712296783924103]\n",
      "  batch 34 loss: [37.12685775756836, 0.521196722984314]\n",
      "  batch 36 loss: [31.68252182006836, 0.44800588488578796]\n",
      "  batch 38 loss: [26.92218017578125, 0.4047362357378006]\n",
      "  batch 40 loss: [34.06184673309326, 0.3478114604949951]\n",
      "  batch 42 loss: [27.951376914978027, 0.26158080250024796]\n",
      "  batch 44 loss: [34.18618392944336, 0.14789320528507233]\n",
      "  batch 46 loss: [30.831079483032227, 0.08284734189510345]\n",
      "  batch 48 loss: [25.242239952087402, 0.25901201367378235]\n",
      "  batch 50 loss: [35.40739440917969, 0.1996871531009674]\n",
      "  batch 52 loss: [25.920973777770996, 0.34560854732990265]\n",
      "  batch 54 loss: [31.187185287475586, 0.23626498878002167]\n",
      "LOSS generator 31.187185287475586 discriminator 0.23626498878002167\n",
      "EPOCH 80:\n",
      "  batch 0 loss: [38.55497360229492, 0.1906166523694992]\n",
      "  batch 2 loss: [25.182281494140625, 0.27371926605701447]\n",
      "  batch 4 loss: [30.130642890930176, 0.1948142796754837]\n",
      "  batch 6 loss: [34.21661567687988, 0.25858401507139206]\n",
      "  batch 8 loss: [26.34147548675537, 0.2750001698732376]\n",
      "  batch 10 loss: [33.031354904174805, 0.2604735344648361]\n",
      "  batch 12 loss: [27.47102451324463, 0.2754604071378708]\n",
      "  batch 14 loss: [28.00704574584961, 0.22280804067850113]\n",
      "  batch 16 loss: [26.77692413330078, 0.15247074887156487]\n",
      "  batch 18 loss: [32.16776466369629, 0.1146920919418335]\n",
      "  batch 20 loss: [29.522537231445312, 0.1819947510957718]\n",
      "  batch 22 loss: [32.141212463378906, 0.20842547714710236]\n",
      "  batch 24 loss: [29.376355171203613, 0.21625201404094696]\n",
      "  batch 26 loss: [35.37912082672119, 0.25614286959171295]\n",
      "  batch 28 loss: [32.98008918762207, 0.21039234846830368]\n",
      "  batch 30 loss: [35.3612003326416, 0.21792945265769958]\n",
      "  batch 32 loss: [36.998247146606445, 0.19293398410081863]\n",
      "  batch 34 loss: [29.803153038024902, 0.23157989978790283]\n",
      "  batch 36 loss: [25.33655834197998, 0.15794727206230164]\n",
      "  batch 38 loss: [30.51533794403076, 0.1868981495499611]\n",
      "  batch 40 loss: [32.19010353088379, 0.1510302796959877]\n",
      "  batch 42 loss: [28.70417022705078, 0.18043816089630127]\n",
      "  batch 44 loss: [35.08264350891113, 0.1481833979487419]\n",
      "  batch 46 loss: [28.186945915222168, 0.09396597743034363]\n",
      "  batch 48 loss: [28.74800395965576, 0.10230832546949387]\n",
      "  batch 50 loss: [25.353861808776855, 0.13424097374081612]\n",
      "  batch 52 loss: [25.108623504638672, 0.4604998975992203]\n",
      "  batch 54 loss: [31.662829399108887, 0.43259674310684204]\n",
      "LOSS generator 31.662829399108887 discriminator 0.43259674310684204\n",
      "EPOCH 81:\n",
      "  batch 0 loss: [31.05150032043457, 0.21322166919708252]\n",
      "  batch 2 loss: [31.67245864868164, 0.2237808182835579]\n",
      "  batch 4 loss: [38.933815002441406, 0.2758871540427208]\n",
      "  batch 6 loss: [33.802019119262695, 0.25168972462415695]\n",
      "  batch 8 loss: [26.710132598876953, 0.255443274974823]\n",
      "  batch 10 loss: [23.30874252319336, 0.22284162044525146]\n",
      "  batch 12 loss: [28.17420768737793, 0.14589332789182663]\n",
      "  batch 14 loss: [38.06313133239746, 0.17564363777637482]\n",
      "  batch 16 loss: [26.741114616394043, 0.12905456498265266]\n",
      "  batch 18 loss: [32.013877868652344, 0.16348130255937576]\n",
      "  batch 20 loss: [28.986889839172363, 0.13234756141901016]\n",
      "  batch 22 loss: [28.074559211730957, 0.09765276312828064]\n",
      "  batch 24 loss: [26.82804775238037, 0.0946173332631588]\n",
      "  batch 26 loss: [34.284098625183105, 0.17790449410676956]\n",
      "  batch 28 loss: [30.641427040100098, 0.16901247948408127]\n",
      "  batch 30 loss: [34.23596000671387, 0.14525354281067848]\n",
      "  batch 32 loss: [29.92416477203369, 0.18890758603811264]\n",
      "  batch 34 loss: [34.65625858306885, 0.10809676349163055]\n",
      "  batch 36 loss: [27.397515296936035, 0.33113302290439606]\n",
      "  batch 38 loss: [31.543232917785645, 0.1230718269944191]\n",
      "  batch 40 loss: [24.623270988464355, 0.18574677407741547]\n",
      "  batch 42 loss: [29.91383457183838, 0.19790056347846985]\n",
      "  batch 44 loss: [30.509614944458008, 0.19876998662948608]\n",
      "  batch 46 loss: [31.08731746673584, 0.19776120781898499]\n",
      "  batch 48 loss: [32.725568771362305, 0.14817755669355392]\n",
      "  batch 50 loss: [29.017759323120117, 0.15985508263111115]\n",
      "  batch 52 loss: [33.89963912963867, 0.2048744410276413]\n",
      "  batch 54 loss: [33.71652793884277, 0.18567202985286713]\n",
      "LOSS generator 33.71652793884277 discriminator 0.18567202985286713\n",
      "EPOCH 82:\n",
      "  batch 0 loss: [26.459674835205078, 0.08881694823503494]\n",
      "  batch 2 loss: [32.081729888916016, 0.22749750316143036]\n",
      "  batch 4 loss: [31.13118553161621, 0.08333737403154373]\n",
      "  batch 6 loss: [36.68812561035156, 0.173814557492733]\n",
      "  batch 8 loss: [31.458260536193848, 0.08103874884545803]\n",
      "  batch 10 loss: [30.752785682678223, 0.1486121416091919]\n",
      "  batch 12 loss: [34.02290916442871, 0.13488753139972687]\n",
      "  batch 14 loss: [28.529436111450195, 0.09200117364525795]\n",
      "  batch 16 loss: [32.47838592529297, 0.07383406534790993]\n",
      "  batch 18 loss: [36.23079299926758, 0.1337023749947548]\n",
      "  batch 20 loss: [31.272476196289062, 0.09506363049149513]\n",
      "  batch 22 loss: [36.46449089050293, 0.11974278092384338]\n",
      "  batch 24 loss: [31.965831756591797, 0.0959132220596075]\n",
      "  batch 26 loss: [29.921170234680176, 0.11957782879471779]\n",
      "  batch 28 loss: [26.217467308044434, 0.09944456815719604]\n",
      "  batch 30 loss: [32.19352149963379, 0.13787701725959778]\n",
      "  batch 32 loss: [30.81881046295166, 0.13758641481399536]\n",
      "  batch 34 loss: [29.456299781799316, 0.26319127529859543]\n",
      "  batch 36 loss: [28.75755023956299, 0.19777865707874298]\n",
      "  batch 38 loss: [32.27525997161865, 0.08996590599417686]\n",
      "  batch 40 loss: [25.365467071533203, 0.27263547480106354]\n",
      "  batch 42 loss: [27.765463829040527, 0.36837635934352875]\n",
      "  batch 44 loss: [25.377869606018066, 0.38748517632484436]\n",
      "  batch 46 loss: [30.727131843566895, 0.15749892592430115]\n",
      "  batch 48 loss: [30.346726417541504, 0.1377636380493641]\n",
      "  batch 50 loss: [30.801527976989746, 0.2017020285129547]\n",
      "  batch 52 loss: [33.31830883026123, 0.14737915247678757]\n",
      "  batch 54 loss: [32.95850086212158, 0.1708482801914215]\n",
      "LOSS generator 32.95850086212158 discriminator 0.1708482801914215\n",
      "EPOCH 83:\n",
      "  batch 0 loss: [34.45445251464844, 0.1070137470960617]\n",
      "  batch 2 loss: [34.116472244262695, 0.07958786189556122]\n",
      "  batch 4 loss: [34.11232566833496, 0.04001552052795887]\n",
      "  batch 6 loss: [29.172677993774414, 0.22111916542053223]\n",
      "  batch 8 loss: [30.878509521484375, 0.1731802225112915]\n",
      "  batch 10 loss: [31.936802864074707, 0.4359995275735855]\n",
      "  batch 12 loss: [32.497859954833984, 0.24116787314414978]\n",
      "  batch 14 loss: [33.03322982788086, 0.2099233865737915]\n",
      "  batch 16 loss: [29.86488628387451, 0.16950969398021698]\n",
      "  batch 18 loss: [32.509501457214355, 0.07987545430660248]\n",
      "  batch 20 loss: [27.03905963897705, 0.14162153005599976]\n",
      "  batch 22 loss: [28.250146865844727, 0.10890068858861923]\n",
      "  batch 24 loss: [32.13420009613037, 0.15444520488381386]\n",
      "  batch 26 loss: [26.34083843231201, 0.10572759062051773]\n",
      "  batch 28 loss: [29.539148330688477, 0.12436143308877945]\n",
      "  batch 30 loss: [33.33186149597168, 0.1132082175463438]\n",
      "  batch 32 loss: [31.726743698120117, 0.16101595014333725]\n",
      "  batch 34 loss: [32.988383293151855, 0.15187086910009384]\n",
      "  batch 36 loss: [34.22696495056152, 0.05456054024398327]\n",
      "  batch 38 loss: [31.491558074951172, 0.1619163677096367]\n",
      "  batch 40 loss: [26.600013732910156, 0.27715811878442764]\n",
      "  batch 42 loss: [30.730618476867676, 0.19787106662988663]\n",
      "  batch 44 loss: [29.632532119750977, 0.15649020671844482]\n",
      "  batch 46 loss: [36.27528953552246, 0.13398008793592453]\n",
      "  batch 48 loss: [30.7388858795166, 0.22594133764505386]\n",
      "  batch 50 loss: [24.768478393554688, 0.11418835818767548]\n",
      "  batch 52 loss: [33.26198673248291, 0.12572293728590012]\n",
      "  batch 54 loss: [35.19917678833008, 0.10105213522911072]\n",
      "LOSS generator 35.19917678833008 discriminator 0.10105213522911072\n",
      "EPOCH 84:\n",
      "  batch 0 loss: [33.14966583251953, 0.05637287348508835]\n",
      "  batch 2 loss: [29.90346908569336, 0.042514994740486145]\n",
      "  batch 4 loss: [33.59373378753662, 0.08082469552755356]\n",
      "  batch 6 loss: [33.55024528503418, 0.029961789026856422]\n",
      "  batch 8 loss: [26.019559860229492, 0.3170633763074875]\n",
      "  batch 10 loss: [28.182186126708984, 0.2600802704691887]\n",
      "  batch 12 loss: [28.903409957885742, 0.19476435333490372]\n",
      "  batch 14 loss: [25.845109939575195, 0.15120530501008034]\n",
      "  batch 16 loss: [27.56552505493164, 0.12416999787092209]\n",
      "  batch 18 loss: [30.092971801757812, 0.05661416985094547]\n",
      "  batch 20 loss: [33.23359966278076, 0.24857603758573532]\n",
      "  batch 22 loss: [39.57815933227539, 0.21626032888889313]\n",
      "  batch 24 loss: [27.370853424072266, 0.18711280077695847]\n",
      "  batch 26 loss: [40.4155330657959, 0.24423251301050186]\n",
      "  batch 28 loss: [29.373964309692383, 0.16359075903892517]\n",
      "  batch 30 loss: [40.362661361694336, 0.23009367287158966]\n",
      "  batch 32 loss: [31.750908851623535, 0.11388526111841202]\n",
      "  batch 34 loss: [29.219032287597656, 0.17682509869337082]\n",
      "  batch 36 loss: [31.71278953552246, 0.09622816368937492]\n",
      "  batch 38 loss: [31.474984169006348, 0.12600750103592873]\n",
      "  batch 40 loss: [34.625200271606445, 0.15987293422222137]\n",
      "  batch 42 loss: [32.18238925933838, 0.1849326454102993]\n",
      "  batch 44 loss: [29.438244819641113, 0.11456726118922234]\n",
      "  batch 46 loss: [28.587810516357422, 0.08460419252514839]\n",
      "  batch 48 loss: [30.73006248474121, 0.30230123549699783]\n",
      "  batch 50 loss: [35.26503372192383, 0.20329420268535614]\n",
      "  batch 52 loss: [32.03295707702637, 0.06275752559304237]\n",
      "  batch 54 loss: [27.546380043029785, 0.1087956614792347]\n",
      "LOSS generator 27.546380043029785 discriminator 0.1087956614792347\n",
      "EPOCH 85:\n",
      "  batch 0 loss: [39.5145263671875, 0.17602314054965973]\n",
      "  batch 2 loss: [25.525866508483887, 0.11916500329971313]\n",
      "  batch 4 loss: [31.758137702941895, 0.04937807284295559]\n",
      "  batch 6 loss: [33.49068737030029, 0.10019396618008614]\n",
      "  batch 8 loss: [30.95588970184326, 0.08811570703983307]\n",
      "  batch 10 loss: [37.03434181213379, 0.12525131553411484]\n",
      "  batch 12 loss: [32.19749355316162, 0.1508641168475151]\n",
      "  batch 14 loss: [32.123971939086914, 0.13925449550151825]\n",
      "  batch 16 loss: [30.768101692199707, 0.15634052827954292]\n",
      "  batch 18 loss: [30.360400199890137, 0.11132215708494186]\n",
      "  batch 20 loss: [30.083555221557617, 0.10192964226007462]\n",
      "  batch 22 loss: [31.18467617034912, 0.1255236342549324]\n",
      "  batch 24 loss: [31.85863494873047, 0.07003983110189438]\n",
      "  batch 26 loss: [26.327153205871582, 0.2395397275686264]\n",
      "  batch 28 loss: [35.05012130737305, 0.08437489904463291]\n",
      "  batch 30 loss: [27.646696090698242, 0.12025752663612366]\n",
      "  batch 32 loss: [33.305341720581055, 0.18554700911045074]\n",
      "  batch 34 loss: [34.31625556945801, 0.1231384240090847]\n",
      "  batch 36 loss: [36.18086624145508, 0.030034007504582405]\n",
      "  batch 38 loss: [29.351959228515625, 0.04899686761200428]\n",
      "  batch 40 loss: [29.758480072021484, 0.05625016428530216]\n",
      "  batch 42 loss: [32.96310043334961, 0.139188751578331]\n",
      "  batch 44 loss: [29.37348747253418, 0.10790655761957169]\n",
      "  batch 46 loss: [30.6915922164917, 0.13328860700130463]\n",
      "  batch 48 loss: [26.948434829711914, 0.14834639802575111]\n",
      "  batch 50 loss: [30.68930721282959, 0.08222854882478714]\n",
      "  batch 52 loss: [37.76555061340332, 0.0964147076010704]\n",
      "  batch 54 loss: [34.91806888580322, 0.18501422554254532]\n",
      "LOSS generator 34.91806888580322 discriminator 0.18501422554254532\n",
      "EPOCH 86:\n",
      "  batch 0 loss: [31.90127944946289, 0.19743159413337708]\n",
      "  batch 2 loss: [30.752092361450195, 0.12891200184822083]\n",
      "  batch 4 loss: [36.36083793640137, 0.11939678341150284]\n",
      "  batch 6 loss: [34.12076950073242, 0.11049924045801163]\n",
      "  batch 8 loss: [25.83200740814209, 0.14891840517520905]\n",
      "  batch 10 loss: [31.372230529785156, 0.13717207312583923]\n",
      "  batch 12 loss: [25.795159339904785, 0.1500907801091671]\n",
      "  batch 14 loss: [29.924457550048828, 0.16688167676329613]\n",
      "  batch 16 loss: [32.30586242675781, 0.1976374052464962]\n",
      "  batch 18 loss: [36.369977951049805, 0.11266984418034554]\n",
      "  batch 20 loss: [30.14714241027832, 0.3325823098421097]\n",
      "  batch 22 loss: [27.7966890335083, 0.4198093116283417]\n",
      "  batch 24 loss: [25.596729278564453, 0.33909932523965836]\n",
      "  batch 26 loss: [31.18173313140869, 0.11863875761628151]\n",
      "  batch 28 loss: [28.985754013061523, 0.19093536585569382]\n",
      "  batch 30 loss: [28.995718955993652, 0.1064976193010807]\n",
      "  batch 32 loss: [29.612882614135742, 0.08403411507606506]\n",
      "  batch 34 loss: [29.96225643157959, 0.055944861844182014]\n",
      "  batch 36 loss: [32.795433044433594, 0.13529813289642334]\n",
      "  batch 38 loss: [30.83590793609619, 0.07657047361135483]\n",
      "  batch 40 loss: [32.2264404296875, 0.05629265680909157]\n",
      "  batch 42 loss: [32.92485809326172, 0.09474136680364609]\n",
      "  batch 44 loss: [31.64955711364746, 0.07733422331511974]\n",
      "  batch 46 loss: [33.22080898284912, 0.10807118192315102]\n",
      "  batch 48 loss: [32.65289497375488, 0.07847972959280014]\n",
      "  batch 50 loss: [34.969085693359375, 0.04685621149837971]\n",
      "  batch 52 loss: [35.82722091674805, 0.06073686107993126]\n",
      "  batch 54 loss: [33.32136917114258, 0.07438015006482601]\n",
      "LOSS generator 33.32136917114258 discriminator 0.07438015006482601\n",
      "EPOCH 87:\n",
      "  batch 0 loss: [33.747169494628906, 0.06827404350042343]\n",
      "  batch 2 loss: [40.46069526672363, 0.15903499722480774]\n",
      "  batch 4 loss: [31.51187515258789, 0.03936031740158796]\n",
      "  batch 6 loss: [33.77062225341797, 0.059601398184895515]\n",
      "  batch 8 loss: [32.20108222961426, 0.29991021752357483]\n",
      "  batch 10 loss: [35.10480880737305, 0.13298868760466576]\n",
      "  batch 12 loss: [24.646401405334473, 0.3798459768295288]\n",
      "  batch 14 loss: [35.05298614501953, 0.39962348341941833]\n",
      "  batch 16 loss: [28.021839141845703, 0.17624056339263916]\n",
      "  batch 18 loss: [25.71333885192871, 0.1532749980688095]\n",
      "  batch 20 loss: [30.363518714904785, 0.12700210511684418]\n",
      "  batch 22 loss: [27.374462127685547, 0.0775599405169487]\n",
      "  batch 24 loss: [25.0565128326416, 0.1039305031299591]\n",
      "  batch 26 loss: [31.612679481506348, 0.15486985445022583]\n",
      "  batch 28 loss: [36.75914764404297, 0.07652634382247925]\n",
      "  batch 30 loss: [35.23085021972656, 0.0634995885193348]\n",
      "  batch 32 loss: [30.71336841583252, 0.08058656007051468]\n",
      "  batch 34 loss: [30.51119613647461, 0.03484128229320049]\n",
      "  batch 36 loss: [30.797273635864258, 0.084749024361372]\n",
      "  batch 38 loss: [29.976496696472168, 0.10591700673103333]\n",
      "  batch 40 loss: [31.10489559173584, 0.06320875138044357]\n",
      "  batch 42 loss: [31.89432430267334, 0.1207781289704144]\n",
      "  batch 44 loss: [31.60513687133789, 0.03619317710399628]\n",
      "  batch 46 loss: [35.600637435913086, 0.015116517897695303]\n",
      "  batch 48 loss: [31.71890163421631, 0.1069081611931324]\n",
      "  batch 50 loss: [30.572509765625, 0.12213491648435593]\n",
      "  batch 52 loss: [33.500407218933105, 0.10638144984841347]\n",
      "  batch 54 loss: [35.53614807128906, 0.09827850945293903]\n",
      "LOSS generator 35.53614807128906 discriminator 0.09827850945293903\n",
      "EPOCH 88:\n",
      "  batch 0 loss: [38.518760681152344, 0.14389565587043762]\n",
      "  batch 2 loss: [34.45863723754883, 0.1384468860924244]\n",
      "  batch 4 loss: [27.594237327575684, 0.0943593792617321]\n",
      "  batch 6 loss: [27.43451690673828, 0.1730617769062519]\n",
      "  batch 8 loss: [30.361980438232422, 0.10398406069725752]\n",
      "  batch 10 loss: [31.471016883850098, 0.11190340854227543]\n",
      "  batch 12 loss: [32.26814079284668, 0.07918696850538254]\n",
      "  batch 14 loss: [35.3242130279541, 0.12021671608090401]\n",
      "  batch 16 loss: [32.66672897338867, 0.1378030776977539]\n",
      "  batch 18 loss: [28.05083656311035, 0.11431626975536346]\n",
      "  batch 20 loss: [33.36350631713867, 0.06634838320314884]\n",
      "  batch 22 loss: [30.296621322631836, 0.06256775557994843]\n",
      "  batch 24 loss: [39.41923522949219, 0.18141698092222214]\n",
      "  batch 26 loss: [38.3652229309082, 0.12225990369915962]\n",
      "  batch 28 loss: [31.625061988830566, 0.0851893424987793]\n",
      "  batch 30 loss: [30.74889087677002, 0.07079697586596012]\n",
      "  batch 32 loss: [30.87322998046875, 0.1440172716975212]\n",
      "  batch 34 loss: [27.010075569152832, 0.10849917680025101]\n",
      "  batch 36 loss: [30.235456466674805, 0.07418948411941528]\n",
      "  batch 38 loss: [34.34411430358887, 0.08403906598687172]\n",
      "  batch 40 loss: [30.007753372192383, 0.05059879086911678]\n",
      "  batch 42 loss: [29.477231979370117, 0.05452574975788593]\n",
      "  batch 44 loss: [36.096235275268555, 0.09882380813360214]\n",
      "  batch 46 loss: [35.63956642150879, 0.10588504979386926]\n",
      "  batch 48 loss: [28.598769187927246, 0.10901102051138878]\n",
      "  batch 50 loss: [33.66717529296875, 0.09023801982402802]\n",
      "  batch 52 loss: [29.60759449005127, 0.12425386905670166]\n",
      "  batch 54 loss: [30.852609634399414, 0.06828378140926361]\n",
      "LOSS generator 30.852609634399414 discriminator 0.06828378140926361\n",
      "EPOCH 89:\n",
      "  batch 0 loss: [27.24317169189453, 0.18859846889972687]\n",
      "  batch 2 loss: [31.70547580718994, 0.1749405413866043]\n",
      "  batch 4 loss: [28.18916130065918, 0.08504978567361832]\n",
      "  batch 6 loss: [31.076165199279785, 0.09010776318609715]\n",
      "  batch 8 loss: [38.17865562438965, 0.12457948923110962]\n",
      "  batch 10 loss: [29.51938819885254, 0.07448439672589302]\n",
      "  batch 12 loss: [25.147513389587402, 0.08616700395941734]\n",
      "  batch 14 loss: [28.726435661315918, 0.04872556962072849]\n",
      "  batch 16 loss: [35.933570861816406, 0.04114818014204502]\n",
      "  batch 18 loss: [32.13851261138916, 0.06724194809794426]\n",
      "  batch 20 loss: [32.232261657714844, 0.051261771470308304]\n",
      "  batch 22 loss: [33.44559669494629, 0.05797444470226765]\n",
      "  batch 24 loss: [35.475830078125, 0.03762223199009895]\n",
      "  batch 26 loss: [30.982778549194336, 0.08054808154702187]\n",
      "  batch 28 loss: [28.587515830993652, 0.13563310354948044]\n",
      "  batch 30 loss: [36.245840072631836, 0.08885856345295906]\n",
      "  batch 32 loss: [36.53567123413086, 0.10747171193361282]\n",
      "  batch 34 loss: [33.984127044677734, 0.0926910974085331]\n",
      "  batch 36 loss: [30.24163818359375, 0.10785188898444176]\n",
      "  batch 38 loss: [30.379502296447754, 0.07673779129981995]\n",
      "  batch 40 loss: [27.079254150390625, 0.08463163673877716]\n",
      "  batch 42 loss: [35.146111488342285, 0.17413965612649918]\n",
      "  batch 44 loss: [29.25225830078125, 0.07137937285006046]\n",
      "  batch 46 loss: [28.4052095413208, 0.08693091943860054]\n",
      "  batch 48 loss: [29.5907039642334, 0.11545032635331154]\n",
      "  batch 50 loss: [34.99542045593262, 0.07795785181224346]\n",
      "  batch 52 loss: [37.72601127624512, 0.07600235287100077]\n",
      "  batch 54 loss: [35.678327560424805, 0.09140429273247719]\n",
      "LOSS generator 35.678327560424805 discriminator 0.09140429273247719\n",
      "EPOCH 90:\n",
      "  batch 0 loss: [29.662696838378906, 0.06331080198287964]\n",
      "  batch 2 loss: [30.20032501220703, 0.06293188966810703]\n",
      "  batch 4 loss: [35.62828254699707, 0.10648747533559799]\n",
      "  batch 6 loss: [30.923911094665527, 0.03905352018773556]\n",
      "  batch 8 loss: [38.54091835021973, 0.10660825669765472]\n",
      "  batch 10 loss: [25.762971878051758, 0.12612751871347427]\n",
      "  batch 12 loss: [32.486037254333496, 0.11408166214823723]\n",
      "  batch 14 loss: [33.96124267578125, 0.05774372257292271]\n",
      "  batch 16 loss: [31.622084617614746, 0.07515622302889824]\n",
      "  batch 18 loss: [36.47443771362305, 0.06466097757220268]\n",
      "  batch 20 loss: [26.634225845336914, 0.19258713722229004]\n",
      "  batch 22 loss: [34.36876201629639, 0.19652581959962845]\n",
      "  batch 24 loss: [34.165385246276855, 0.13041424006223679]\n",
      "  batch 26 loss: [34.57531547546387, 0.06226968578994274]\n",
      "  batch 28 loss: [30.691834449768066, 0.04578421264886856]\n",
      "  batch 30 loss: [32.503573417663574, 0.2949323505163193]\n",
      "  batch 32 loss: [34.573280334472656, 0.09451736137270927]\n",
      "  batch 34 loss: [32.2205696105957, 0.12162208929657936]\n",
      "  batch 36 loss: [28.247888565063477, 0.10871482640504837]\n",
      "  batch 38 loss: [28.97159767150879, 0.15671199560165405]\n",
      "  batch 40 loss: [28.545573234558105, 0.12201906368136406]\n",
      "  batch 42 loss: [36.54269218444824, 0.055254194885492325]\n",
      "  batch 44 loss: [30.962371826171875, 0.0717049092054367]\n",
      "  batch 46 loss: [35.30556678771973, 0.03485618904232979]\n",
      "  batch 48 loss: [29.587444305419922, 0.045282513834536076]\n",
      "  batch 50 loss: [32.572834968566895, 0.09551000781357288]\n",
      "  batch 52 loss: [31.389676094055176, 0.059009160846471786]\n",
      "  batch 54 loss: [32.268625259399414, 0.13879996538162231]\n",
      "LOSS generator 32.268625259399414 discriminator 0.13879996538162231\n",
      "EPOCH 91:\n",
      "  batch 0 loss: [42.30976867675781, 0.1132843941450119]\n",
      "  batch 2 loss: [31.939608573913574, 0.0504147931933403]\n",
      "  batch 4 loss: [36.942073822021484, 0.2603904902935028]\n",
      "  batch 6 loss: [30.73263931274414, 0.07047691382467747]\n",
      "  batch 8 loss: [30.33315944671631, 0.061655959114432335]\n",
      "  batch 10 loss: [27.42849349975586, 0.08786559663712978]\n",
      "  batch 12 loss: [24.74153995513916, 0.23974769562482834]\n",
      "  batch 14 loss: [33.90290832519531, 0.057123249396681786]\n",
      "  batch 16 loss: [38.1265983581543, 0.13242393732070923]\n",
      "  batch 18 loss: [33.19783306121826, 0.09600649401545525]\n",
      "  batch 20 loss: [28.418167114257812, 0.14011451601982117]\n",
      "  batch 22 loss: [28.041179656982422, 0.057343821972608566]\n",
      "  batch 24 loss: [31.32801055908203, 0.10052214935421944]\n",
      "  batch 26 loss: [29.683476448059082, 0.06009417772293091]\n",
      "  batch 28 loss: [30.20094871520996, 0.03646418172866106]\n",
      "  batch 30 loss: [34.019707679748535, 0.0543053075671196]\n",
      "  batch 32 loss: [32.764774322509766, 0.02278166264295578]\n",
      "  batch 34 loss: [30.42891788482666, 0.07104574888944626]\n",
      "  batch 36 loss: [33.05510139465332, 0.08902211673557758]\n",
      "  batch 38 loss: [31.97939968109131, 0.05838727578520775]\n",
      "  batch 40 loss: [35.056074142456055, 0.07501812651753426]\n",
      "  batch 42 loss: [31.887968063354492, 0.016952769830822945]\n",
      "  batch 44 loss: [42.85742378234863, 0.13778433203697205]\n",
      "  batch 46 loss: [36.18729019165039, 0.07293538749217987]\n",
      "  batch 48 loss: [34.087608337402344, 0.030790074728429317]\n",
      "  batch 50 loss: [34.613266944885254, 0.08954013884067535]\n",
      "  batch 52 loss: [27.886380195617676, 0.10272740945219994]\n",
      "  batch 54 loss: [29.337615966796875, 0.11122189089655876]\n",
      "LOSS generator 29.337615966796875 discriminator 0.11122189089655876\n",
      "EPOCH 92:\n",
      "  batch 0 loss: [35.29609680175781, 0.13246259093284607]\n",
      "  batch 2 loss: [34.71147346496582, 0.05904743820428848]\n",
      "  batch 4 loss: [34.7656192779541, 0.047333273105323315]\n",
      "  batch 6 loss: [33.29936408996582, 0.04702175222337246]\n",
      "  batch 8 loss: [25.670472145080566, 0.055869996547698975]\n",
      "  batch 10 loss: [30.42683506011963, 0.04755276441574097]\n",
      "  batch 12 loss: [30.775419235229492, 0.05890989303588867]\n",
      "  batch 14 loss: [40.1650276184082, 0.08312487229704857]\n",
      "  batch 16 loss: [31.067933082580566, 0.05680147930979729]\n",
      "  batch 18 loss: [27.882100105285645, 0.08000052347779274]\n",
      "  batch 20 loss: [32.55485725402832, 0.05256858840584755]\n",
      "  batch 22 loss: [28.38143253326416, 0.09210614860057831]\n",
      "  batch 24 loss: [30.669503211975098, 0.13148128986358643]\n",
      "  batch 26 loss: [32.796488761901855, 0.013458487577736378]\n",
      "  batch 28 loss: [33.57017135620117, 0.05438886024057865]\n",
      "  batch 30 loss: [32.721195220947266, 0.04947787057608366]\n",
      "  batch 32 loss: [34.90142631530762, 0.0870424248278141]\n",
      "  batch 34 loss: [31.296058654785156, 0.0642978111281991]\n",
      "  batch 36 loss: [37.688175201416016, 0.07144566997885704]\n",
      "  batch 38 loss: [33.533124923706055, 0.040650296956300735]\n",
      "  batch 40 loss: [32.46146297454834, 0.05508150905370712]\n",
      "  batch 42 loss: [35.7757453918457, 0.05747387558221817]\n",
      "  batch 44 loss: [34.41708183288574, 0.01304690446704626]\n",
      "  batch 46 loss: [36.875125885009766, 0.046239159535616636]\n",
      "  batch 48 loss: [29.614336013793945, 0.03479241207242012]\n",
      "  batch 50 loss: [30.99003791809082, 0.04184615286067128]\n",
      "  batch 52 loss: [32.801642417907715, 0.04521501623094082]\n",
      "  batch 54 loss: [31.446792602539062, 0.04131345450878143]\n",
      "LOSS generator 31.446792602539062 discriminator 0.04131345450878143\n",
      "EPOCH 93:\n",
      "  batch 0 loss: [31.3232421875, 0.02434343472123146]\n",
      "  batch 2 loss: [37.90678024291992, 0.4153359979391098]\n",
      "  batch 4 loss: [37.717376708984375, 0.2607698291540146]\n",
      "  batch 6 loss: [36.900047302246094, 0.1337768193334341]\n",
      "  batch 8 loss: [33.735504150390625, 0.10187848657369614]\n",
      "  batch 10 loss: [26.694501876831055, 0.09724113345146179]\n",
      "  batch 12 loss: [34.00058937072754, 0.09512198250740767]\n",
      "  batch 14 loss: [27.2540340423584, 0.08593743667006493]\n",
      "  batch 16 loss: [34.5272216796875, 0.06846528686583042]\n",
      "  batch 18 loss: [29.052173614501953, 0.20015791058540344]\n",
      "  batch 20 loss: [27.407363891601562, 0.10353881120681763]\n",
      "  batch 22 loss: [31.21370792388916, 0.05683153122663498]\n",
      "  batch 24 loss: [28.786006927490234, 0.13808338344097137]\n",
      "  batch 26 loss: [30.850321769714355, 0.0849497988820076]\n",
      "  batch 28 loss: [34.63010787963867, 0.06374391354620457]\n",
      "  batch 30 loss: [33.068366050720215, 0.025568369310349226]\n",
      "  batch 32 loss: [31.413021087646484, 0.012055489234626293]\n",
      "  batch 34 loss: [34.48994541168213, 0.06313556618988514]\n",
      "  batch 36 loss: [27.119428634643555, 0.10467296466231346]\n",
      "  batch 38 loss: [36.49229049682617, 0.05787278711795807]\n",
      "  batch 40 loss: [31.22679042816162, 0.068703792989254]\n",
      "  batch 42 loss: [32.427724838256836, 0.03239032672718167]\n",
      "  batch 44 loss: [29.386505126953125, 0.054704977199435234]\n",
      "  batch 46 loss: [33.802711486816406, 0.09442857280373573]\n",
      "  batch 48 loss: [33.92769241333008, 0.06233492121100426]\n",
      "  batch 50 loss: [28.413068771362305, 0.030979616567492485]\n",
      "  batch 52 loss: [38.787397384643555, 0.03788742050528526]\n",
      "  batch 54 loss: [32.89597225189209, 0.02598408330231905]\n",
      "LOSS generator 32.89597225189209 discriminator 0.02598408330231905\n",
      "EPOCH 94:\n",
      "  batch 0 loss: [33.45709991455078, 0.06450331211090088]\n",
      "  batch 2 loss: [32.289581298828125, 0.08472019992768764]\n",
      "  batch 4 loss: [33.53708267211914, 0.043461043387651443]\n",
      "  batch 6 loss: [33.898985862731934, 0.09573111310601234]\n",
      "  batch 8 loss: [37.07315635681152, 0.07944376766681671]\n",
      "  batch 10 loss: [29.55535888671875, 0.032286553643643856]\n",
      "  batch 12 loss: [30.781896591186523, 0.055203188210725784]\n",
      "  batch 14 loss: [33.507001876831055, 0.058830348774790764]\n",
      "  batch 16 loss: [32.965378761291504, 0.04463331587612629]\n",
      "  batch 18 loss: [31.387956619262695, 0.10079112276434898]\n",
      "  batch 20 loss: [29.72398567199707, 0.04186303075402975]\n",
      "  batch 22 loss: [34.593994140625, 0.0238247187808156]\n",
      "  batch 24 loss: [34.49043273925781, 0.047973623499274254]\n",
      "  batch 26 loss: [35.05587959289551, 0.03602621238678694]\n",
      "  batch 28 loss: [31.73806858062744, 0.03481511678546667]\n",
      "  batch 30 loss: [34.69332695007324, 0.05945889465510845]\n",
      "  batch 32 loss: [30.77553081512451, 0.037843745201826096]\n",
      "  batch 34 loss: [32.010597229003906, 0.026048263534903526]\n",
      "  batch 36 loss: [34.82943058013916, 0.017978140152990818]\n",
      "  batch 38 loss: [33.57915687561035, 0.018782005179673433]\n",
      "  batch 40 loss: [29.60211753845215, 0.10873903147876263]\n",
      "  batch 42 loss: [35.3579683303833, 0.05501199886202812]\n",
      "  batch 44 loss: [29.48624324798584, 0.13600192591547966]\n",
      "  batch 46 loss: [30.093527793884277, 0.05404220102354884]\n",
      "  batch 48 loss: [30.52884006500244, 0.05381569731980562]\n",
      "  batch 50 loss: [29.06143283843994, 0.09015063941478729]\n",
      "  batch 52 loss: [34.50339698791504, 0.07414021529257298]\n",
      "  batch 54 loss: [32.72078514099121, 0.04530667793005705]\n",
      "LOSS generator 32.72078514099121 discriminator 0.04530667793005705\n",
      "EPOCH 95:\n",
      "  batch 0 loss: [40.0255126953125, 0.17441442608833313]\n",
      "  batch 2 loss: [32.125213623046875, 0.06162549741566181]\n",
      "  batch 4 loss: [25.26839256286621, 0.05842102784663439]\n",
      "  batch 6 loss: [28.044471740722656, 0.07241411041468382]\n",
      "  batch 8 loss: [34.182966232299805, 0.047005390748381615]\n",
      "  batch 10 loss: [35.26583290100098, 0.04227284528315067]\n",
      "  batch 12 loss: [28.991663932800293, 0.03226521983742714]\n",
      "  batch 14 loss: [29.88048267364502, 0.03236882109194994]\n",
      "  batch 16 loss: [27.010205268859863, 0.032051773741841316]\n",
      "  batch 18 loss: [32.212717056274414, 0.021326067391783]\n",
      "  batch 20 loss: [37.14077186584473, 0.026796048507094383]\n",
      "  batch 22 loss: [35.767568588256836, 0.017058310098946095]\n",
      "  batch 24 loss: [30.934460639953613, 0.026378748007118702]\n",
      "  batch 26 loss: [32.817341804504395, 0.014693956356495619]\n",
      "  batch 28 loss: [31.459494590759277, 0.22580288723111153]\n",
      "  batch 30 loss: [29.659321784973145, 0.03410773351788521]\n",
      "  batch 32 loss: [31.877399444580078, 0.038962412159889936]\n",
      "  batch 34 loss: [31.511144638061523, 0.04154978133738041]\n",
      "  batch 36 loss: [33.301636695861816, 0.04931051656603813]\n",
      "  batch 38 loss: [31.281368255615234, 0.03855731524527073]\n",
      "  batch 40 loss: [29.87102699279785, 0.04455861635506153]\n",
      "  batch 42 loss: [33.27504825592041, 0.06007894314825535]\n",
      "  batch 44 loss: [36.21270561218262, 0.0497246035374701]\n",
      "  batch 46 loss: [34.99668502807617, 0.040734369307756424]\n",
      "  batch 48 loss: [33.19376564025879, 0.048193100374192]\n",
      "  batch 50 loss: [39.129411697387695, 0.05564292334020138]\n",
      "  batch 52 loss: [40.374794006347656, 0.08178866282105446]\n",
      "  batch 54 loss: [32.07437705993652, 0.025022885762155056]\n",
      "LOSS generator 32.07437705993652 discriminator 0.025022885762155056\n",
      "EPOCH 96:\n",
      "  batch 0 loss: [28.797975540161133, 0.01812875270843506]\n",
      "  batch 2 loss: [31.950824737548828, 0.033554548397660255]\n",
      "  batch 4 loss: [31.563549041748047, 0.04669932276010513]\n",
      "  batch 6 loss: [33.11017990112305, 0.027479706332087517]\n",
      "  batch 8 loss: [31.74600601196289, 0.025781101547181606]\n",
      "  batch 10 loss: [35.124619483947754, 0.011329935397952795]\n",
      "  batch 12 loss: [33.85479164123535, 0.024517497047781944]\n",
      "  batch 14 loss: [34.49453258514404, 0.08944493532180786]\n",
      "  batch 16 loss: [33.60201454162598, 0.03770790062844753]\n",
      "  batch 18 loss: [32.154537200927734, 0.021927958354353905]\n",
      "  batch 20 loss: [35.24284553527832, 0.04010178707540035]\n",
      "  batch 22 loss: [32.65187644958496, 0.03209792450070381]\n",
      "  batch 24 loss: [37.628522872924805, 0.055278945714235306]\n",
      "  batch 26 loss: [30.60931968688965, 0.034134311601519585]\n",
      "  batch 28 loss: [29.778446197509766, 0.02885308302938938]\n",
      "  batch 30 loss: [33.750667572021484, 0.018569833133369684]\n",
      "  batch 32 loss: [38.59606742858887, 0.0605307025834918]\n",
      "  batch 34 loss: [34.70102024078369, 0.06376820616424084]\n",
      "  batch 36 loss: [30.03850555419922, 0.034905750304460526]\n",
      "  batch 38 loss: [34.303067207336426, 0.025195837952196598]\n",
      "  batch 40 loss: [39.069942474365234, 0.04522770643234253]\n",
      "  batch 42 loss: [33.349910736083984, 0.05573043413460255]\n",
      "  batch 44 loss: [28.326712608337402, 0.02494870638474822]\n",
      "  batch 46 loss: [33.336069107055664, 0.049546604976058006]\n",
      "  batch 48 loss: [29.64921283721924, 0.049970366060733795]\n",
      "  batch 50 loss: [32.924190521240234, 0.05059661529958248]\n",
      "  batch 52 loss: [33.666372299194336, 0.024492298252880573]\n",
      "  batch 54 loss: [29.856093406677246, 0.08139779418706894]\n",
      "LOSS generator 29.856093406677246 discriminator 0.08139779418706894\n",
      "EPOCH 97:\n",
      "  batch 0 loss: [31.43984031677246, 0.010203179903328419]\n",
      "  batch 2 loss: [34.98442268371582, 0.022647200152277946]\n",
      "  batch 4 loss: [35.275814056396484, 0.049520486034452915]\n",
      "  batch 6 loss: [32.59486389160156, 0.07425745204091072]\n",
      "  batch 8 loss: [35.48427772521973, 0.05016973242163658]\n",
      "  batch 10 loss: [34.32676887512207, 0.007117376662790775]\n",
      "  batch 12 loss: [38.351783752441406, 0.030225176364183426]\n",
      "  batch 14 loss: [34.2347412109375, 0.038533235900104046]\n",
      "  batch 16 loss: [33.248406410217285, 0.053733840584754944]\n",
      "  batch 18 loss: [29.378847122192383, 0.025168905965983868]\n",
      "  batch 20 loss: [31.185686111450195, 0.02809526026248932]\n",
      "  batch 22 loss: [28.806038856506348, 0.02123075001873076]\n",
      "  batch 24 loss: [28.701008796691895, 0.0274001844227314]\n",
      "  batch 26 loss: [33.843732833862305, 0.01863489579409361]\n",
      "  batch 28 loss: [27.218278884887695, 0.038806844502687454]\n",
      "  batch 30 loss: [32.12389087677002, 0.018862746190279722]\n",
      "  batch 32 loss: [33.488901138305664, 0.04875897243618965]\n",
      "  batch 34 loss: [29.346071243286133, 0.10218558460474014]\n",
      "  batch 36 loss: [36.39662170410156, 0.05582443065941334]\n",
      "  batch 38 loss: [33.186445236206055, 0.12760476395487785]\n",
      "  batch 40 loss: [32.72820472717285, 0.03375531919300556]\n",
      "  batch 42 loss: [39.18400764465332, 0.05139951594173908]\n",
      "  batch 44 loss: [35.60349082946777, 0.007785670226439834]\n",
      "  batch 46 loss: [35.70647716522217, 0.016250270884484053]\n",
      "  batch 48 loss: [32.47022819519043, 0.011717988643795252]\n",
      "  batch 50 loss: [30.697911262512207, 0.028051087632775307]\n",
      "  batch 52 loss: [32.08808708190918, 0.024628467857837677]\n",
      "  batch 54 loss: [37.06182098388672, 0.01709606871008873]\n",
      "LOSS generator 37.06182098388672 discriminator 0.01709606871008873\n",
      "EPOCH 98:\n",
      "  batch 0 loss: [27.977943420410156, 0.1093592494726181]\n",
      "  batch 2 loss: [36.02628707885742, 0.03394365310668945]\n",
      "  batch 4 loss: [29.50153350830078, 0.021130734123289585]\n",
      "  batch 6 loss: [32.949951171875, 0.025344799272716045]\n",
      "  batch 8 loss: [35.46675491333008, 0.034502098336815834]\n",
      "  batch 10 loss: [36.21499252319336, 0.04967984836548567]\n",
      "  batch 12 loss: [31.850393295288086, 0.06462623365223408]\n",
      "  batch 14 loss: [38.71361541748047, 0.08446405827999115]\n",
      "  batch 16 loss: [33.30869674682617, 0.022040010429918766]\n",
      "  batch 18 loss: [30.60406494140625, 0.007667917991057038]\n",
      "  batch 20 loss: [30.81724739074707, 0.01810781517997384]\n",
      "  batch 22 loss: [30.69292449951172, 0.0119426054880023]\n",
      "  batch 24 loss: [33.016536712646484, 0.024696364998817444]\n",
      "  batch 26 loss: [32.942277908325195, 0.017337490571662784]\n",
      "  batch 28 loss: [34.40755081176758, 0.009452952537685633]\n",
      "  batch 30 loss: [33.87599277496338, 0.10403188318014145]\n",
      "  batch 32 loss: [37.777326583862305, 0.03623669780790806]\n",
      "  batch 34 loss: [42.0961799621582, 0.098704494535923]\n",
      "  batch 36 loss: [31.391531944274902, 0.039318525698035955]\n",
      "  batch 38 loss: [32.566328048706055, 0.040300153195858]\n",
      "  batch 40 loss: [30.144021034240723, 0.024875073693692684]\n",
      "  batch 42 loss: [28.10606575012207, 0.018987657967954874]\n",
      "  batch 44 loss: [36.78823471069336, 0.0317310094833374]\n",
      "  batch 46 loss: [33.73174285888672, 0.008878580294549465]\n",
      "  batch 48 loss: [34.510464668273926, 0.02035071887075901]\n",
      "  batch 50 loss: [32.138771057128906, 0.07075245678424835]\n",
      "  batch 52 loss: [31.58526611328125, 0.027589691802859306]\n",
      "  batch 54 loss: [29.56477165222168, 0.03445192612707615]\n",
      "LOSS generator 29.56477165222168 discriminator 0.03445192612707615\n",
      "EPOCH 99:\n",
      "  batch 0 loss: [27.578025817871094, 0.02760380506515503]\n",
      "  batch 2 loss: [30.948410987854004, 0.014099711552262306]\n",
      "  batch 4 loss: [31.721667289733887, 0.026723346672952175]\n",
      "  batch 6 loss: [37.89827537536621, 0.022398903034627438]\n",
      "  batch 8 loss: [34.352304458618164, 0.03840227797627449]\n",
      "  batch 10 loss: [41.51311492919922, 0.06229580007493496]\n",
      "  batch 12 loss: [36.26161003112793, 0.02049256698228419]\n",
      "  batch 14 loss: [31.124107360839844, 0.11847039870917797]\n",
      "  batch 16 loss: [28.128031730651855, 0.01779211964458227]\n",
      "  batch 18 loss: [33.687320709228516, 0.03453318774700165]\n",
      "  batch 20 loss: [29.937589645385742, 0.04957693861797452]\n",
      "  batch 22 loss: [27.416460037231445, 0.019001628272235394]\n",
      "  batch 24 loss: [29.81279468536377, 0.07787234522402287]\n",
      "  batch 26 loss: [40.303611755371094, 0.31725455820560455]\n",
      "  batch 28 loss: [32.892812728881836, 0.29925480484962463]\n",
      "  batch 30 loss: [27.955851554870605, 0.12474514171481133]\n",
      "  batch 32 loss: [30.572226524353027, 0.07725147530436516]\n",
      "  batch 34 loss: [29.45347309112549, 0.04333864711225033]\n",
      "  batch 36 loss: [32.41739845275879, 0.10173119604587555]\n",
      "  batch 38 loss: [33.916072845458984, 0.02710714004933834]\n",
      "  batch 40 loss: [29.156771659851074, 0.033549897372722626]\n",
      "  batch 42 loss: [38.32774543762207, 0.05766957998275757]\n",
      "  batch 44 loss: [34.662763595581055, 0.039509660098701715]\n",
      "  batch 46 loss: [33.91492748260498, 0.02341057825833559]\n",
      "  batch 48 loss: [37.397451400756836, 0.08050133008509874]\n",
      "  batch 50 loss: [27.255050659179688, 0.039392754435539246]\n",
      "  batch 52 loss: [37.24435997009277, 0.08544629067182541]\n",
      "  batch 54 loss: [33.075066566467285, 0.0239170053973794]\n",
      "LOSS generator 33.075066566467285 discriminator 0.0239170053973794\n",
      "EPOCH 100:\n",
      "  batch 0 loss: [29.831161499023438, 0.03431396186351776]\n",
      "  batch 2 loss: [30.382726669311523, 0.03452774789184332]\n",
      "  batch 4 loss: [39.85208511352539, 0.07185094617307186]\n",
      "  batch 6 loss: [40.99813652038574, 0.04673111066222191]\n",
      "  batch 8 loss: [32.891860008239746, 0.011445431038737297]\n",
      "  batch 10 loss: [35.280043601989746, 0.05864418298006058]\n",
      "  batch 12 loss: [33.76769256591797, 0.04611453600227833]\n",
      "  batch 14 loss: [32.19654369354248, 0.03753684740513563]\n",
      "  batch 16 loss: [29.57457447052002, 0.00828981027007103]\n",
      "  batch 18 loss: [32.41804599761963, 0.036880942061543465]\n",
      "  batch 20 loss: [35.41494560241699, 0.038134532049298286]\n",
      "  batch 22 loss: [28.209975242614746, 0.030039191246032715]\n",
      "  batch 24 loss: [34.57967185974121, 0.013371197041124105]\n",
      "  batch 26 loss: [31.371009826660156, 0.027521698735654354]\n",
      "  batch 28 loss: [27.01044273376465, 0.09127784613519907]\n",
      "  batch 30 loss: [38.94191932678223, 0.03853711672127247]\n",
      "  batch 32 loss: [29.599273681640625, 0.052820611745119095]\n",
      "  batch 34 loss: [33.035573959350586, 0.057921532075852156]\n",
      "  batch 36 loss: [30.637523651123047, 0.030928320717066526]\n",
      "  batch 38 loss: [32.09041881561279, 0.03491032123565674]\n",
      "  batch 40 loss: [29.255979537963867, 0.05402160994708538]\n",
      "  batch 42 loss: [27.899200439453125, 0.021317520178854465]\n",
      "  batch 44 loss: [29.89822006225586, 0.03580724634230137]\n",
      "  batch 46 loss: [36.36481475830078, 0.026672702049836516]\n",
      "  batch 48 loss: [40.6136417388916, 0.06371467933058739]\n",
      "  batch 50 loss: [33.5699405670166, 0.025427423417568207]\n",
      "  batch 52 loss: [32.617523193359375, 0.0150296064093709]\n",
      "  batch 54 loss: [33.296640396118164, 0.01593028847128153]\n",
      "LOSS generator 33.296640396118164 discriminator 0.01593028847128153\n",
      "EPOCH 101:\n",
      "  batch 0 loss: [27.0694522857666, 0.1754704862833023]\n",
      "  batch 2 loss: [30.59369945526123, 0.31810007989406586]\n",
      "  batch 4 loss: [27.501529693603516, 0.5171602815389633]\n",
      "  batch 6 loss: [22.092204093933105, 1.2555243372917175]\n",
      "  batch 8 loss: [26.08940315246582, 1.12518510222435]\n",
      "  batch 10 loss: [33.83400249481201, 1.6271910667419434]\n",
      "  batch 12 loss: [28.183924674987793, 1.081161081790924]\n",
      "  batch 14 loss: [33.159502029418945, 0.4894469976425171]\n",
      "  batch 16 loss: [35.28350639343262, 0.24349816143512726]\n",
      "  batch 18 loss: [30.113128662109375, 0.12011183798313141]\n",
      "  batch 20 loss: [32.42557621002197, 0.05070618353784084]\n",
      "  batch 22 loss: [27.608830451965332, 0.2974483370780945]\n",
      "  batch 24 loss: [33.01529502868652, 0.1585588902235031]\n",
      "  batch 26 loss: [27.7493257522583, 0.13715989142656326]\n",
      "  batch 28 loss: [28.254972457885742, 0.09436142817139626]\n",
      "  batch 30 loss: [26.87372875213623, 0.19774195551872253]\n",
      "  batch 32 loss: [27.713662147521973, 0.10704196989536285]\n",
      "  batch 34 loss: [31.565088272094727, 0.07381477952003479]\n",
      "  batch 36 loss: [30.971332550048828, 0.13916346803307533]\n",
      "  batch 38 loss: [32.04075813293457, 0.16117270290851593]\n",
      "  batch 40 loss: [32.41218376159668, 0.09325304627418518]\n",
      "  batch 42 loss: [31.901676177978516, 0.03671097755432129]\n",
      "  batch 44 loss: [33.63363265991211, 0.12217207998037338]\n",
      "  batch 46 loss: [38.18739700317383, 0.11645860224962234]\n",
      "  batch 48 loss: [31.522809982299805, 0.08447009325027466]\n",
      "  batch 50 loss: [29.27002239227295, 0.053465547040104866]\n",
      "  batch 52 loss: [34.077226638793945, 0.10679644346237183]\n",
      "  batch 54 loss: [44.0468864440918, 0.12083780020475388]\n",
      "LOSS generator 44.0468864440918 discriminator 0.12083780020475388\n",
      "EPOCH 102:\n",
      "  batch 0 loss: [34.358314514160156, 0.07702283561229706]\n",
      "  batch 2 loss: [32.18570137023926, 0.03761399816721678]\n",
      "  batch 4 loss: [25.99375343322754, 0.24549642950296402]\n",
      "  batch 6 loss: [31.331828117370605, 0.10122823342680931]\n",
      "  batch 8 loss: [28.93748664855957, 0.08407405577600002]\n",
      "  batch 10 loss: [31.948421478271484, 0.1242498829960823]\n",
      "  batch 12 loss: [26.482088088989258, 0.131057133898139]\n",
      "  batch 14 loss: [36.464176177978516, 0.05753127485513687]\n",
      "  batch 16 loss: [30.990214347839355, 0.13821789622306824]\n",
      "  batch 18 loss: [36.98381328582764, 0.09577321633696556]\n",
      "  batch 20 loss: [31.44587993621826, 0.05347786983475089]\n",
      "  batch 22 loss: [29.61527442932129, 0.041577260941267014]\n",
      "  batch 24 loss: [31.029741287231445, 0.154561385512352]\n",
      "  batch 26 loss: [33.02890110015869, 0.04762114677578211]\n",
      "  batch 28 loss: [35.837989807128906, 0.08971617743372917]\n",
      "  batch 30 loss: [28.38110065460205, 0.04885294660925865]\n",
      "  batch 32 loss: [32.67582130432129, 0.03403468430042267]\n",
      "  batch 34 loss: [34.628671646118164, 0.01408162945881486]\n",
      "  batch 36 loss: [32.00803089141846, 0.0585838221013546]\n",
      "  batch 38 loss: [25.398138999938965, 0.05444037541747093]\n",
      "  batch 40 loss: [39.58408164978027, 0.09692934527993202]\n",
      "  batch 42 loss: [28.679155349731445, 0.10320745408535004]\n",
      "  batch 44 loss: [38.296213150024414, 0.27144186198711395]\n",
      "  batch 46 loss: [28.174254417419434, 0.16578783094882965]\n",
      "  batch 48 loss: [29.696773529052734, 0.09008002653717995]\n",
      "  batch 50 loss: [32.58509540557861, 0.14058326371014118]\n",
      "  batch 52 loss: [28.32066059112549, 0.22174949571490288]\n",
      "  batch 54 loss: [37.573368072509766, 0.07059488818049431]\n",
      "LOSS generator 37.573368072509766 discriminator 0.07059488818049431\n",
      "EPOCH 103:\n",
      "  batch 0 loss: [34.20330047607422, 0.025968972593545914]\n",
      "  batch 2 loss: [34.37799644470215, 0.04311381280422211]\n",
      "  batch 4 loss: [34.05807113647461, 0.08781647123396397]\n",
      "  batch 6 loss: [32.32218933105469, 0.026439161971211433]\n",
      "  batch 8 loss: [30.829883575439453, 0.09057953953742981]\n",
      "  batch 10 loss: [31.30147647857666, 0.08382098004221916]\n",
      "  batch 12 loss: [31.406415939331055, 0.07237144187092781]\n",
      "  batch 14 loss: [35.24186992645264, 0.05458164028823376]\n",
      "  batch 16 loss: [32.03348445892334, 0.027768168598413467]\n",
      "  batch 18 loss: [32.31016540527344, 0.06375623866915703]\n",
      "  batch 20 loss: [32.3353214263916, 0.04479078110307455]\n",
      "  batch 22 loss: [28.160457611083984, 0.07443813234567642]\n",
      "  batch 24 loss: [29.597935676574707, 0.07458552718162537]\n",
      "  batch 26 loss: [35.43401908874512, 0.09541857615113258]\n",
      "  batch 28 loss: [29.043917655944824, 0.13053581304848194]\n",
      "  batch 30 loss: [28.75899887084961, 0.19694728404283524]\n",
      "  batch 32 loss: [31.98683738708496, 0.05631621554493904]\n",
      "  batch 34 loss: [36.61813163757324, 0.16317230463027954]\n",
      "  batch 36 loss: [35.96607208251953, 0.17240217328071594]\n",
      "  batch 38 loss: [29.1028413772583, 0.07154848799109459]\n",
      "  batch 40 loss: [28.96473789215088, 0.15269489958882332]\n",
      "  batch 42 loss: [32.81363105773926, 0.07452728226780891]\n",
      "  batch 44 loss: [31.647326469421387, 0.040534915402531624]\n",
      "  batch 46 loss: [32.30436706542969, 0.0439283512532711]\n",
      "  batch 48 loss: [38.027198791503906, 0.0580754023976624]\n",
      "  batch 50 loss: [36.87698173522949, 0.057250624522566795]\n",
      "  batch 52 loss: [33.97384262084961, 0.08614090085029602]\n",
      "  batch 54 loss: [26.706317901611328, 0.04643505439162254]\n",
      "LOSS generator 26.706317901611328 discriminator 0.04643505439162254\n",
      "EPOCH 104:\n",
      "  batch 0 loss: [36.323177337646484, 0.04593809321522713]\n",
      "  batch 2 loss: [33.538570404052734, 0.041730768978595734]\n",
      "  batch 4 loss: [34.41203689575195, 0.12502692081034184]\n",
      "  batch 6 loss: [28.53291606903076, 0.07747182063758373]\n",
      "  batch 8 loss: [33.47085094451904, 0.3181030973792076]\n",
      "  batch 10 loss: [30.36268901824951, 0.3613688573241234]\n",
      "  batch 12 loss: [40.70155906677246, 0.4969238340854645]\n",
      "  batch 14 loss: [27.821048736572266, 0.264376737177372]\n",
      "  batch 16 loss: [36.5122013092041, 0.3347005248069763]\n",
      "  batch 18 loss: [28.682230949401855, 0.1107863038778305]\n",
      "  batch 20 loss: [26.036516189575195, 0.09917861968278885]\n",
      "  batch 22 loss: [33.49527359008789, 0.09870973415672779]\n",
      "  batch 24 loss: [36.48892879486084, 0.17755627259612083]\n",
      "  batch 26 loss: [25.44453716278076, 0.1262277513742447]\n",
      "  batch 28 loss: [32.497965812683105, 0.09906228631734848]\n",
      "  batch 30 loss: [32.78182506561279, 0.04685516469180584]\n",
      "  batch 32 loss: [29.553417205810547, 0.05343574099242687]\n",
      "  batch 34 loss: [34.38433647155762, 0.0413199607282877]\n",
      "  batch 36 loss: [28.52980136871338, 0.12942217662930489]\n",
      "  batch 38 loss: [35.94615364074707, 0.06388450413942337]\n",
      "  batch 40 loss: [38.172136306762695, 0.035051995888352394]\n",
      "  batch 42 loss: [33.090352058410645, 0.04301993548870087]\n",
      "  batch 44 loss: [34.51851940155029, 0.04916081205010414]\n",
      "  batch 46 loss: [32.83812141418457, 0.08043262548744678]\n",
      "  batch 48 loss: [34.19505023956299, 0.10019675642251968]\n",
      "  batch 50 loss: [30.121639251708984, 0.09724371507763863]\n",
      "  batch 52 loss: [31.583580017089844, 0.04581464594230056]\n",
      "  batch 54 loss: [34.58159828186035, 0.07802128791809082]\n",
      "LOSS generator 34.58159828186035 discriminator 0.07802128791809082\n",
      "EPOCH 105:\n",
      "  batch 0 loss: [32.7581672668457, 0.022241774946451187]\n",
      "  batch 2 loss: [34.90159606933594, 0.054971447214484215]\n",
      "  batch 4 loss: [28.983410835266113, 0.10439748503267765]\n",
      "  batch 6 loss: [28.44977855682373, 0.047540707513689995]\n",
      "  batch 8 loss: [26.16636085510254, 0.17596334591507912]\n",
      "  batch 10 loss: [33.1585750579834, 0.08369346102699637]\n",
      "  batch 12 loss: [37.6008186340332, 0.06450708210468292]\n",
      "  batch 14 loss: [37.10757064819336, 0.059439174830913544]\n",
      "  batch 16 loss: [33.58576965332031, 0.009813540615141392]\n",
      "  batch 18 loss: [36.52405834197998, 0.06629806570708752]\n",
      "  batch 20 loss: [36.58943176269531, 0.014421543572098017]\n",
      "  batch 22 loss: [30.949752807617188, 0.0443135891109705]\n",
      "  batch 24 loss: [37.12682914733887, 0.0566382366232574]\n",
      "  batch 26 loss: [35.46960639953613, 0.06256140768527985]\n",
      "  batch 28 loss: [30.87956428527832, 0.050139328464865685]\n",
      "  batch 30 loss: [34.2204704284668, 0.02036925218999386]\n",
      "  batch 32 loss: [33.710927963256836, 0.04032122157514095]\n",
      "  batch 34 loss: [37.584815979003906, 0.04887371324002743]\n",
      "  batch 36 loss: [34.008758544921875, 0.03733797837048769]\n",
      "  batch 38 loss: [31.554580688476562, 0.034000067971646786]\n",
      "  batch 40 loss: [32.45793342590332, 0.1115278210490942]\n",
      "  batch 42 loss: [30.327075958251953, 0.07529938034713268]\n",
      "  batch 44 loss: [25.106325149536133, 0.17541322112083435]\n",
      "  batch 46 loss: [32.817386627197266, 0.07380867749452591]\n",
      "  batch 48 loss: [30.738245010375977, 0.03382810391485691]\n",
      "  batch 50 loss: [29.898727416992188, 0.062150999903678894]\n",
      "  batch 52 loss: [35.32089614868164, 0.019947576336562634]\n",
      "  batch 54 loss: [30.086121559143066, 0.07417670264840126]\n",
      "LOSS generator 30.086121559143066 discriminator 0.07417670264840126\n",
      "EPOCH 106:\n",
      "  batch 0 loss: [41.087135314941406, 0.05991744250059128]\n",
      "  batch 2 loss: [33.739999771118164, 0.06834802404046059]\n",
      "  batch 4 loss: [34.2212610244751, 0.03399306535720825]\n",
      "  batch 6 loss: [35.684926986694336, 0.058075129985809326]\n",
      "  batch 8 loss: [33.71876335144043, 0.0422172611579299]\n",
      "  batch 10 loss: [36.50583839416504, 0.038454167544841766]\n",
      "  batch 12 loss: [33.66135501861572, 0.06500063836574554]\n",
      "  batch 14 loss: [27.981728553771973, 0.08515654876828194]\n",
      "  batch 16 loss: [28.58236026763916, 0.049462951719760895]\n",
      "  batch 18 loss: [34.793487548828125, 0.03557424899190664]\n",
      "  batch 20 loss: [31.679829597473145, 0.0633193850517273]\n",
      "  batch 22 loss: [28.868648529052734, 0.03775051236152649]\n",
      "  batch 24 loss: [32.50673580169678, 0.07221384160220623]\n",
      "  batch 26 loss: [35.59521675109863, 0.03727101348340511]\n",
      "  batch 28 loss: [34.1924991607666, 0.013771842699497938]\n",
      "  batch 30 loss: [34.16984748840332, 0.07129660062491894]\n",
      "  batch 32 loss: [29.79757022857666, 0.20645509660243988]\n",
      "  batch 34 loss: [28.110549926757812, 0.036526226438581944]\n",
      "  batch 36 loss: [31.69644832611084, 0.08198535442352295]\n",
      "  batch 38 loss: [34.72565841674805, 0.05577244609594345]\n",
      "  batch 40 loss: [32.99921131134033, 0.023733558133244514]\n",
      "  batch 42 loss: [33.230215072631836, 0.03295539692044258]\n",
      "  batch 44 loss: [33.66679382324219, 0.028338327072560787]\n",
      "  batch 46 loss: [33.201473236083984, 0.03738156519830227]\n",
      "  batch 48 loss: [30.345253944396973, 0.04389255587011576]\n",
      "  batch 50 loss: [31.944937705993652, 0.06651793047785759]\n",
      "  batch 52 loss: [31.340599060058594, 0.02376515930518508]\n",
      "  batch 54 loss: [35.21121788024902, 0.08055135980248451]\n",
      "LOSS generator 35.21121788024902 discriminator 0.08055135980248451\n",
      "EPOCH 107:\n",
      "  batch 0 loss: [40.34088134765625, 0.054539039731025696]\n",
      "  batch 2 loss: [38.92281532287598, 0.04615152254700661]\n",
      "  batch 4 loss: [35.69279479980469, 0.019070024602115154]\n",
      "  batch 6 loss: [30.90135669708252, 0.04996566753834486]\n",
      "  batch 8 loss: [30.05602264404297, 0.04694283381104469]\n",
      "  batch 10 loss: [34.22101974487305, 0.033013198524713516]\n",
      "  batch 12 loss: [30.667110443115234, 0.06269060540944338]\n",
      "  batch 14 loss: [34.07824230194092, 0.0761289969086647]\n",
      "  batch 16 loss: [32.13005828857422, 0.018662238493561745]\n",
      "  batch 18 loss: [32.77316761016846, 0.047274887561798096]\n",
      "  batch 20 loss: [30.8334903717041, 0.06915640830993652]\n",
      "  batch 22 loss: [33.143381118774414, 0.015850928612053394]\n",
      "  batch 24 loss: [26.941381454467773, 0.05816573649644852]\n",
      "  batch 26 loss: [34.08306312561035, 0.016614919528365135]\n",
      "  batch 28 loss: [33.55377197265625, 0.02201642282307148]\n",
      "  batch 30 loss: [31.52724838256836, 0.014717706944793463]\n",
      "  batch 32 loss: [35.42656707763672, 0.04949064925312996]\n",
      "  batch 34 loss: [32.20163536071777, 0.058462418615818024]\n",
      "  batch 36 loss: [38.80730056762695, 0.05838491767644882]\n",
      "  batch 38 loss: [32.17153263092041, 0.04227630328387022]\n",
      "  batch 40 loss: [31.60277271270752, 0.030139701440930367]\n",
      "  batch 42 loss: [28.863792419433594, 0.03305205516517162]\n",
      "  batch 44 loss: [34.59991264343262, 0.05928106978535652]\n",
      "  batch 46 loss: [37.831621170043945, 0.07425164803862572]\n",
      "  batch 48 loss: [31.32064723968506, 0.03076237067580223]\n",
      "  batch 50 loss: [29.878843307495117, 0.05340042058378458]\n",
      "  batch 52 loss: [38.9121208190918, 0.08103031106293201]\n",
      "  batch 54 loss: [32.15586757659912, 0.12185691297054291]\n",
      "LOSS generator 32.15586757659912 discriminator 0.12185691297054291\n",
      "EPOCH 108:\n",
      "  batch 0 loss: [26.00013542175293, 0.03236702084541321]\n",
      "  batch 2 loss: [31.633185386657715, 0.04366721957921982]\n",
      "  batch 4 loss: [31.046855926513672, 0.022495606914162636]\n",
      "  batch 6 loss: [33.53615379333496, 0.06454218365252018]\n",
      "  batch 8 loss: [27.283815383911133, 0.14126230031251907]\n",
      "  batch 10 loss: [34.536882400512695, 0.08118664473295212]\n",
      "  batch 12 loss: [39.64141082763672, 0.08695056289434433]\n",
      "  batch 14 loss: [35.03629112243652, 0.017390121705830097]\n",
      "  batch 16 loss: [30.41507911682129, 0.03607943281531334]\n",
      "  batch 18 loss: [37.820749282836914, 0.04103865101933479]\n",
      "  batch 20 loss: [37.35075569152832, 0.022521340288221836]\n",
      "  batch 22 loss: [38.056495666503906, 0.0635027065873146]\n",
      "  batch 24 loss: [30.04339599609375, 0.04008350148797035]\n",
      "  batch 26 loss: [35.52884292602539, 0.06103033758699894]\n",
      "  batch 28 loss: [32.510725021362305, 0.02256434876471758]\n",
      "  batch 30 loss: [30.962604522705078, 0.029187774285674095]\n",
      "  batch 32 loss: [35.87332534790039, 0.02929161861538887]\n",
      "  batch 34 loss: [28.926057815551758, 0.024107245728373528]\n",
      "  batch 36 loss: [33.79210186004639, 0.039265033788979053]\n",
      "  batch 38 loss: [31.646038055419922, 0.014513574307784438]\n",
      "  batch 40 loss: [31.2605037689209, 0.0694119781255722]\n",
      "  batch 42 loss: [31.476232528686523, 0.0410239826887846]\n",
      "  batch 44 loss: [34.7122859954834, 0.0428276602178812]\n",
      "  batch 46 loss: [30.585424423217773, 0.048423899337649345]\n",
      "  batch 48 loss: [35.353506088256836, 0.05083291977643967]\n",
      "  batch 50 loss: [34.55800533294678, 0.08755915984511375]\n",
      "  batch 52 loss: [31.037612915039062, 0.03242052858695388]\n",
      "  batch 54 loss: [32.54993438720703, 0.09371460974216461]\n",
      "LOSS generator 32.54993438720703 discriminator 0.09371460974216461\n",
      "EPOCH 109:\n",
      "  batch 0 loss: [35.11912536621094, 0.05489534139633179]\n",
      "  batch 2 loss: [40.04991340637207, 0.03602199675515294]\n",
      "  batch 4 loss: [28.74712085723877, 0.03126370348036289]\n",
      "  batch 6 loss: [30.82986545562744, 0.03470028378069401]\n",
      "  batch 8 loss: [37.87110424041748, 0.07659831829369068]\n",
      "  batch 10 loss: [29.272449493408203, 0.060870613902807236]\n",
      "  batch 12 loss: [32.14315700531006, 0.09916930086910725]\n",
      "  batch 14 loss: [36.023542404174805, 0.009475728962570429]\n",
      "  batch 16 loss: [33.787986755371094, 0.03406136855483055]\n",
      "  batch 18 loss: [33.612735748291016, 0.02714640088379383]\n",
      "  batch 20 loss: [31.073259353637695, 0.03203955106437206]\n",
      "  batch 22 loss: [32.01768493652344, 0.04773334972560406]\n",
      "  batch 24 loss: [30.45232391357422, 0.09507931768894196]\n",
      "  batch 26 loss: [31.281394958496094, 0.017990244552493095]\n",
      "  batch 28 loss: [29.652925491333008, 0.04176121298223734]\n",
      "  batch 30 loss: [35.60447120666504, 0.05135578475892544]\n",
      "  batch 32 loss: [33.071776390075684, 0.06533423252403736]\n",
      "  batch 34 loss: [30.921812057495117, 0.029402378015220165]\n",
      "  batch 36 loss: [30.422815322875977, 0.02806707937270403]\n",
      "  batch 38 loss: [38.71018409729004, 0.014708406757563353]\n",
      "  batch 40 loss: [36.28666114807129, 0.03810088150203228]\n",
      "  batch 42 loss: [32.83358955383301, 0.04420934710651636]\n",
      "  batch 44 loss: [37.88955307006836, 0.02151117566972971]\n",
      "  batch 46 loss: [29.737062454223633, 0.021074945107102394]\n",
      "  batch 48 loss: [36.59543228149414, 0.02819879539310932]\n",
      "  batch 50 loss: [31.601479530334473, 0.07864921912550926]\n",
      "  batch 52 loss: [33.13408660888672, 0.06525786593556404]\n",
      "  batch 54 loss: [31.264307022094727, 0.0386904813349247]\n",
      "LOSS generator 31.264307022094727 discriminator 0.0386904813349247\n",
      "EPOCH 110:\n",
      "  batch 0 loss: [33.417640686035156, 0.007438279688358307]\n",
      "  batch 2 loss: [39.7677526473999, 0.46679704636335373]\n",
      "  batch 4 loss: [34.521822929382324, 0.5415459871292114]\n",
      "  batch 6 loss: [31.300209999084473, 0.5954594314098358]\n",
      "  batch 8 loss: [29.959832191467285, 0.3659229278564453]\n",
      "  batch 10 loss: [38.507192611694336, 0.3008561283349991]\n",
      "  batch 12 loss: [25.077778816223145, 0.12862678617238998]\n",
      "  batch 14 loss: [27.505715370178223, 0.12101125717163086]\n",
      "  batch 16 loss: [36.11893272399902, 0.47819164395332336]\n",
      "  batch 18 loss: [30.857810974121094, 0.19570822268724442]\n",
      "  batch 20 loss: [30.356454849243164, 0.1825595311820507]\n",
      "  batch 22 loss: [29.161605834960938, 0.18805330991744995]\n",
      "  batch 24 loss: [29.368534088134766, 0.03647099249064922]\n",
      "  batch 26 loss: [35.14609718322754, 0.10347358137369156]\n",
      "  batch 28 loss: [29.29422092437744, 0.1154317818582058]\n",
      "  batch 30 loss: [34.83736991882324, 0.15892349183559418]\n",
      "  batch 32 loss: [34.44726371765137, 0.04956001881510019]\n",
      "  batch 34 loss: [38.842620849609375, 0.07853013649582863]\n",
      "  batch 36 loss: [31.96401596069336, 0.0885997973382473]\n",
      "  batch 38 loss: [32.10848808288574, 0.06502635776996613]\n",
      "  batch 40 loss: [29.698664665222168, 0.05551549233496189]\n",
      "  batch 42 loss: [35.16572380065918, 0.013330698944628239]\n",
      "  batch 44 loss: [34.13123321533203, 0.026941930875182152]\n",
      "  batch 46 loss: [33.85220146179199, 0.06313716247677803]\n",
      "  batch 48 loss: [41.08366775512695, 0.11895701475441456]\n",
      "  batch 50 loss: [31.5018892288208, 0.03234417364001274]\n",
      "  batch 52 loss: [28.508567810058594, 0.04567381739616394]\n",
      "  batch 54 loss: [36.44083023071289, 0.14750931039452553]\n",
      "LOSS generator 36.44083023071289 discriminator 0.14750931039452553\n",
      "EPOCH 111:\n",
      "  batch 0 loss: [35.0305061340332, 0.32989275455474854]\n",
      "  batch 2 loss: [31.515058517456055, 0.15051758289337158]\n",
      "  batch 4 loss: [33.500993728637695, 0.07251827046275139]\n",
      "  batch 6 loss: [34.495094299316406, 0.03751203045248985]\n",
      "  batch 8 loss: [30.72305965423584, 0.10914515145123005]\n",
      "  batch 10 loss: [33.42216682434082, 0.1374659240245819]\n",
      "  batch 12 loss: [31.720354080200195, 0.09839097410440445]\n",
      "  batch 14 loss: [33.793087005615234, 0.03315078839659691]\n",
      "  batch 16 loss: [36.96065330505371, 0.05273635871708393]\n",
      "  batch 18 loss: [31.833370208740234, 0.05714912246912718]\n",
      "  batch 20 loss: [34.71761894226074, 0.05032236874103546]\n",
      "  batch 22 loss: [37.574581146240234, 0.05335139390081167]\n",
      "  batch 24 loss: [36.7509822845459, 0.05063119903206825]\n",
      "  batch 26 loss: [34.97465896606445, 0.048629121854901314]\n",
      "  batch 28 loss: [34.80610466003418, 0.031077902764081955]\n",
      "  batch 30 loss: [25.105257987976074, 0.022056065499782562]\n",
      "  batch 32 loss: [31.11420249938965, 0.08376801013946533]\n",
      "  batch 34 loss: [31.74453067779541, 0.025515985675156116]\n",
      "  batch 36 loss: [31.462836265563965, 0.02456761710345745]\n",
      "  batch 38 loss: [35.27883720397949, 0.06534557323902845]\n",
      "  batch 40 loss: [28.412938117980957, 0.028332078829407692]\n",
      "  batch 42 loss: [33.74324607849121, 0.12002700939774513]\n",
      "  batch 44 loss: [31.8856258392334, 0.016436364967375994]\n",
      "  batch 46 loss: [31.611404418945312, 0.028874149546027184]\n",
      "  batch 48 loss: [34.462890625, 0.11825297772884369]\n",
      "  batch 50 loss: [31.368237495422363, 0.03573943115770817]\n",
      "  batch 52 loss: [32.194668769836426, 0.020292201079428196]\n",
      "  batch 54 loss: [36.31521797180176, 0.042750729247927666]\n",
      "LOSS generator 36.31521797180176 discriminator 0.042750729247927666\n",
      "EPOCH 112:\n",
      "  batch 0 loss: [38.99055099487305, 0.0815683975815773]\n",
      "  batch 2 loss: [35.58726119995117, 0.027955099008977413]\n",
      "  batch 4 loss: [33.48500442504883, 0.022315405309200287]\n",
      "  batch 6 loss: [30.971928596496582, 0.032926294952631]\n",
      "  batch 8 loss: [35.663373947143555, 0.03275682870298624]\n",
      "  batch 10 loss: [32.664167404174805, 0.028177360072731972]\n",
      "  batch 12 loss: [34.23694610595703, 0.03585191536694765]\n",
      "  batch 14 loss: [36.63488578796387, 0.04201555252075195]\n",
      "  batch 16 loss: [30.327649116516113, 0.10461713001132011]\n",
      "  batch 18 loss: [31.498220443725586, 0.01959757413715124]\n",
      "  batch 20 loss: [35.698171615600586, 0.029440531972795725]\n",
      "  batch 22 loss: [36.304033279418945, 0.025140440091490746]\n",
      "  batch 24 loss: [32.57099723815918, 0.01756238890811801]\n",
      "  batch 26 loss: [37.93313789367676, 0.02117783296853304]\n",
      "  batch 28 loss: [30.29662036895752, 0.035710349678993225]\n",
      "  batch 30 loss: [32.27620792388916, 0.006912402110174298]\n",
      "  batch 32 loss: [31.7239933013916, 0.061627164483070374]\n",
      "  batch 34 loss: [31.852152824401855, 0.01307252049446106]\n",
      "  batch 36 loss: [37.03056716918945, 0.07217103987932205]\n",
      "  batch 38 loss: [36.030006408691406, 0.010116375982761383]\n",
      "  batch 40 loss: [33.67385673522949, 0.021310172975063324]\n",
      "  batch 42 loss: [31.210289001464844, 0.08879612013697624]\n",
      "  batch 44 loss: [34.578067779541016, 0.03537624701857567]\n",
      "  batch 46 loss: [25.79232692718506, 0.10169733688235283]\n",
      "  batch 48 loss: [34.82001209259033, 0.04080650070682168]\n",
      "  batch 50 loss: [34.63288497924805, 0.11473584175109863]\n",
      "  batch 52 loss: [29.31515121459961, 0.19567039236426353]\n",
      "  batch 54 loss: [34.81676483154297, 0.04147920943796635]\n",
      "LOSS generator 34.81676483154297 discriminator 0.04147920943796635\n",
      "EPOCH 113:\n",
      "  batch 0 loss: [43.741851806640625, 0.04207798093557358]\n",
      "  batch 2 loss: [33.46847343444824, 0.03443687781691551]\n",
      "  batch 4 loss: [33.45015621185303, 0.06389740481972694]\n",
      "  batch 6 loss: [32.69824028015137, 0.03555646352469921]\n",
      "  batch 8 loss: [35.94660568237305, 0.023042344488203526]\n",
      "  batch 10 loss: [34.80196189880371, 0.01815785001963377]\n",
      "  batch 12 loss: [21.499202728271484, 0.13714973628520966]\n",
      "  batch 14 loss: [34.226945877075195, 0.02711613941937685]\n",
      "  batch 16 loss: [33.37888717651367, 0.041857701260596514]\n",
      "  batch 18 loss: [36.528846740722656, 0.05346567556262016]\n",
      "  batch 20 loss: [32.77512550354004, 0.02718868013471365]\n",
      "  batch 22 loss: [37.72174072265625, 0.015319227240979671]\n",
      "  batch 24 loss: [37.462087631225586, 0.05426277220249176]\n",
      "  batch 26 loss: [34.461031913757324, 0.10581357404589653]\n",
      "  batch 28 loss: [29.57224464416504, 0.10830947384238243]\n",
      "  batch 30 loss: [32.34000492095947, 0.05014517530798912]\n",
      "  batch 32 loss: [28.926359176635742, 0.041969820857048035]\n",
      "  batch 34 loss: [37.51223373413086, 0.04101070761680603]\n",
      "  batch 36 loss: [36.23539733886719, 0.040100445970892906]\n",
      "  batch 38 loss: [32.233482360839844, 0.042665536981076]\n",
      "  batch 40 loss: [32.84344005584717, 0.04511473700404167]\n",
      "  batch 42 loss: [34.03896522521973, 0.013083958998322487]\n",
      "  batch 44 loss: [35.73458290100098, 0.018046032171696424]\n",
      "  batch 46 loss: [31.78204345703125, 0.01579937944188714]\n",
      "  batch 48 loss: [32.85268688201904, 0.04545561410486698]\n",
      "  batch 50 loss: [29.209729194641113, 0.02744032721966505]\n",
      "  batch 52 loss: [31.053634643554688, 0.012229704996570945]\n",
      "  batch 54 loss: [32.103962898254395, 0.011275641154497862]\n",
      "LOSS generator 32.103962898254395 discriminator 0.011275641154497862\n",
      "EPOCH 114:\n",
      "  batch 0 loss: [40.347721099853516, 0.04273965209722519]\n",
      "  batch 2 loss: [36.776424407958984, 0.04668702185153961]\n",
      "  batch 4 loss: [33.162986755371094, 0.014945375267416239]\n",
      "  batch 6 loss: [32.728878021240234, 0.018578724935650826]\n",
      "  batch 8 loss: [38.202476501464844, 0.03641698136925697]\n",
      "  batch 10 loss: [35.39806938171387, 0.019362134858965874]\n",
      "  batch 12 loss: [31.453798294067383, 0.05027924105525017]\n",
      "  batch 14 loss: [30.966846466064453, 0.03460874408483505]\n",
      "  batch 16 loss: [27.146916389465332, 0.017775782849639654]\n",
      "  batch 18 loss: [30.977879524230957, 0.0239721592515707]\n",
      "  batch 20 loss: [37.37457084655762, 0.042335422709584236]\n",
      "  batch 22 loss: [36.30643653869629, 0.02255710493773222]\n",
      "  batch 24 loss: [34.09039878845215, 0.047512730583548546]\n",
      "  batch 26 loss: [33.58201026916504, 0.019874271005392075]\n",
      "  batch 28 loss: [31.83856201171875, 0.014808089938014746]\n",
      "  batch 30 loss: [30.70518398284912, 0.023209395818412304]\n",
      "  batch 32 loss: [38.59362030029297, 0.023178790928795934]\n",
      "  batch 34 loss: [34.489871978759766, 0.016739529091864824]\n",
      "  batch 36 loss: [36.84536933898926, 0.02676022844389081]\n",
      "  batch 38 loss: [31.793153762817383, 0.00868895323947072]\n",
      "  batch 40 loss: [28.705195426940918, 0.01003023935481906]\n",
      "  batch 42 loss: [33.83386039733887, 0.0065811146050691605]\n",
      "  batch 44 loss: [29.281229972839355, 0.11955269984900951]\n",
      "  batch 46 loss: [37.0423583984375, 0.04220316489227116]\n",
      "  batch 48 loss: [33.16440963745117, 0.05887508951127529]\n",
      "  batch 50 loss: [34.13819408416748, 0.05345140863209963]\n",
      "  batch 52 loss: [33.234060287475586, 0.05547273904085159]\n",
      "  batch 54 loss: [36.43786811828613, 0.02081499807536602]\n",
      "LOSS generator 36.43786811828613 discriminator 0.02081499807536602\n",
      "EPOCH 115:\n",
      "  batch 0 loss: [35.78028869628906, 0.013799288310110569]\n",
      "  batch 2 loss: [28.366991996765137, 0.0386428888887167]\n",
      "  batch 4 loss: [33.090457916259766, 0.019313519820570946]\n",
      "  batch 6 loss: [30.57937240600586, 0.042606149800121784]\n",
      "  batch 8 loss: [33.740264892578125, 0.03774135932326317]\n",
      "  batch 10 loss: [34.592079162597656, 0.019197133369743824]\n",
      "  batch 12 loss: [35.81024169921875, 0.058750761672854424]\n",
      "  batch 14 loss: [37.92608451843262, 0.03258853452280164]\n",
      "  batch 16 loss: [33.8533239364624, 0.0429108627140522]\n",
      "  batch 18 loss: [32.775699615478516, 0.01625361479818821]\n",
      "  batch 20 loss: [35.98859977722168, 0.03888947796076536]\n",
      "  batch 22 loss: [30.47964096069336, 0.027540620416402817]\n",
      "  batch 24 loss: [40.48312568664551, 0.048946890980005264]\n",
      "  batch 26 loss: [36.12677764892578, 0.023436390794813633]\n",
      "  batch 28 loss: [32.76871967315674, 0.03715732507407665]\n",
      "  batch 30 loss: [36.14413642883301, 0.061878751963377]\n",
      "  batch 32 loss: [27.47215747833252, 0.03199501056224108]\n",
      "  batch 34 loss: [27.92427635192871, 0.07519613159820437]\n",
      "  batch 36 loss: [30.306889533996582, 0.010379109997302294]\n",
      "  batch 38 loss: [38.277915954589844, 0.021844588220119476]\n",
      "  batch 40 loss: [36.10153579711914, 0.018921297043561935]\n",
      "  batch 42 loss: [35.76159191131592, 0.03225948102772236]\n",
      "  batch 44 loss: [30.1628999710083, 0.032886077649891376]\n",
      "  batch 46 loss: [32.73536777496338, 0.03694306127727032]\n",
      "  batch 48 loss: [32.75565147399902, 0.018482395680621266]\n",
      "  batch 50 loss: [38.919830322265625, 0.03477077092975378]\n",
      "  batch 52 loss: [36.364145278930664, 0.00806421332526952]\n",
      "  batch 54 loss: [31.116217613220215, 0.05924796313047409]\n",
      "LOSS generator 31.116217613220215 discriminator 0.05924796313047409\n",
      "EPOCH 116:\n",
      "  batch 0 loss: [49.02836990356445, 0.21291321516036987]\n",
      "  batch 2 loss: [34.45352745056152, 0.2254016101360321]\n",
      "  batch 4 loss: [31.559077262878418, 0.08748252503573895]\n",
      "  batch 6 loss: [33.10166263580322, 0.06566151604056358]\n",
      "  batch 8 loss: [31.299833297729492, 0.0520226638764143]\n",
      "  batch 10 loss: [30.269960403442383, 0.014885674230754375]\n",
      "  batch 12 loss: [33.90751075744629, 0.019387247040867805]\n",
      "  batch 14 loss: [29.373117446899414, 0.026611031033098698]\n",
      "  batch 16 loss: [34.93535232543945, 0.046237703412771225]\n",
      "  batch 18 loss: [32.44815921783447, 0.016389123164117336]\n",
      "  batch 20 loss: [33.23674392700195, 0.06177164241671562]\n",
      "  batch 22 loss: [35.38796615600586, 0.038586816750466824]\n",
      "  batch 24 loss: [29.838592529296875, 0.024526989087462425]\n",
      "  batch 26 loss: [37.32730674743652, 0.051489342004060745]\n",
      "  batch 28 loss: [33.35446643829346, 0.2627798765897751]\n",
      "  batch 30 loss: [30.179014205932617, 0.07488318905234337]\n",
      "  batch 32 loss: [35.064870834350586, 0.02427452988922596]\n",
      "  batch 34 loss: [31.2810640335083, 0.04424184001982212]\n",
      "  batch 36 loss: [35.18258857727051, 0.016765164211392403]\n",
      "  batch 38 loss: [35.76714515686035, 0.027927051298320293]\n",
      "  batch 40 loss: [29.644116401672363, 0.04689091723412275]\n",
      "  batch 42 loss: [35.490989685058594, 0.004576647421345115]\n",
      "  batch 44 loss: [33.819854736328125, 0.013546728529036045]\n",
      "  batch 46 loss: [41.246707916259766, 0.039125822484493256]\n",
      "  batch 48 loss: [31.654212951660156, 0.04020471312105656]\n",
      "  batch 50 loss: [34.60618019104004, 0.04567449167370796]\n",
      "  batch 52 loss: [33.52337646484375, 0.050028085708618164]\n",
      "  batch 54 loss: [31.54973602294922, 0.03466038964688778]\n",
      "LOSS generator 31.54973602294922 discriminator 0.03466038964688778\n",
      "EPOCH 117:\n",
      "  batch 0 loss: [35.99417495727539, 0.006098708137869835]\n",
      "  batch 2 loss: [36.25462627410889, 0.07552361115813255]\n",
      "  batch 4 loss: [33.15639877319336, 0.029181480407714844]\n",
      "  batch 6 loss: [30.750630378723145, 0.02514538448303938]\n",
      "  batch 8 loss: [36.1949987411499, 0.044190164655447006]\n",
      "  batch 10 loss: [38.15672302246094, 0.06280559673905373]\n",
      "  batch 12 loss: [28.98824119567871, 0.03521434962749481]\n",
      "  batch 14 loss: [34.07169723510742, 0.02632637624628842]\n",
      "  batch 16 loss: [33.06291484832764, 0.05128576047718525]\n",
      "  batch 18 loss: [34.70962715148926, 0.010303820949047804]\n",
      "  batch 20 loss: [33.81063461303711, 0.018514834810048342]\n",
      "  batch 22 loss: [35.81616973876953, 0.01597492303699255]\n",
      "  batch 24 loss: [34.3359317779541, 0.00896811205893755]\n",
      "  batch 26 loss: [33.68132019042969, 0.036473007407039404]\n",
      "  batch 28 loss: [32.39831352233887, 0.015486652962863445]\n",
      "  batch 30 loss: [33.856801986694336, 0.005007588770240545]\n",
      "  batch 32 loss: [35.13361740112305, 0.0153598478063941]\n",
      "  batch 34 loss: [33.041133880615234, 0.15377413667738438]\n",
      "  batch 36 loss: [36.62215805053711, 0.017899149446748197]\n",
      "  batch 38 loss: [29.562342643737793, 0.043212587013840675]\n",
      "  batch 40 loss: [32.9642276763916, 0.015646912157535553]\n",
      "  batch 42 loss: [40.36239433288574, 0.05061766132712364]\n",
      "  batch 44 loss: [33.205204010009766, 0.03562259487807751]\n",
      "  batch 46 loss: [37.89443397521973, 0.028482704423367977]\n",
      "  batch 48 loss: [28.407151222229004, 0.038887531496584415]\n",
      "  batch 50 loss: [33.21337890625, 0.00921982852742076]\n",
      "  batch 52 loss: [30.355676651000977, 0.014393392484635115]\n",
      "  batch 54 loss: [32.57419204711914, 0.03334364527836442]\n",
      "LOSS generator 32.57419204711914 discriminator 0.03334364527836442\n",
      "EPOCH 118:\n",
      "  batch 0 loss: [39.547306060791016, 0.005671138875186443]\n",
      "  batch 2 loss: [32.70852279663086, 0.030501587316393852]\n",
      "  batch 4 loss: [22.839452743530273, 0.03132583852857351]\n",
      "  batch 6 loss: [35.683889389038086, 0.04752547899261117]\n",
      "  batch 8 loss: [37.4704532623291, 0.01678995182737708]\n",
      "  batch 10 loss: [34.275529861450195, 0.02593941567465663]\n",
      "  batch 12 loss: [36.58087921142578, 0.012851936742663383]\n",
      "  batch 14 loss: [34.637332916259766, 0.03183015249669552]\n",
      "  batch 16 loss: [33.35045909881592, 0.0271928571164608]\n",
      "  batch 18 loss: [33.55257797241211, 0.04512028023600578]\n",
      "  batch 20 loss: [35.255062103271484, 0.011470664758235216]\n",
      "  batch 22 loss: [33.47077941894531, 0.02065658662468195]\n",
      "  batch 24 loss: [36.711313247680664, 0.012336826417595148]\n",
      "  batch 26 loss: [32.23869037628174, 0.017904689069837332]\n",
      "  batch 28 loss: [33.24977493286133, 0.01084091141819954]\n",
      "  batch 30 loss: [39.6363410949707, 0.017678328789770603]\n",
      "  batch 32 loss: [39.660491943359375, 0.042952029034495354]\n",
      "  batch 34 loss: [25.28308391571045, 0.07630125526338816]\n",
      "  batch 36 loss: [36.5169677734375, 0.013000932522118092]\n",
      "  batch 38 loss: [39.00356674194336, 0.04232853697612882]\n",
      "  batch 40 loss: [39.139949798583984, 0.04465715494006872]\n",
      "  batch 42 loss: [35.15545463562012, 0.014918024186044931]\n",
      "  batch 44 loss: [33.80329895019531, 0.01919932384043932]\n",
      "  batch 46 loss: [32.93360710144043, 0.013430536026135087]\n",
      "  batch 48 loss: [27.460139274597168, 0.03588837571442127]\n",
      "  batch 50 loss: [33.61436653137207, 0.017434728797525167]\n",
      "  batch 52 loss: [33.75126361846924, 0.012977471575140953]\n",
      "  batch 54 loss: [29.06117343902588, 0.056780227459967136]\n",
      "LOSS generator 29.06117343902588 discriminator 0.056780227459967136\n",
      "EPOCH 119:\n",
      "  batch 0 loss: [32.793113708496094, 0.015626821666955948]\n",
      "  batch 2 loss: [35.17169952392578, 0.0162891186773777]\n",
      "  batch 4 loss: [35.24766159057617, 0.02453092858195305]\n",
      "  batch 6 loss: [34.60196495056152, 0.02121011819690466]\n",
      "  batch 8 loss: [30.605554580688477, 0.024217180907726288]\n",
      "  batch 10 loss: [27.0713529586792, 0.08304943703114986]\n",
      "  batch 12 loss: [30.090429306030273, 0.03519390523433685]\n",
      "  batch 14 loss: [32.44454002380371, 0.03076392412185669]\n",
      "  batch 16 loss: [40.18494415283203, 0.013212652411311865]\n",
      "  batch 18 loss: [37.97355651855469, 0.0334939775057137]\n",
      "  batch 20 loss: [35.86640739440918, 0.040955579839646816]\n",
      "  batch 22 loss: [35.300933837890625, 0.02170239109545946]\n",
      "  batch 24 loss: [31.12234878540039, 0.014022769406437874]\n",
      "  batch 26 loss: [36.22686767578125, 0.04188824607990682]\n",
      "  batch 28 loss: [33.47660541534424, 0.023191383108496666]\n",
      "  batch 30 loss: [41.40361022949219, 0.04358803480863571]\n",
      "  batch 32 loss: [34.368391036987305, 0.021822411566972733]\n",
      "  batch 34 loss: [32.37748908996582, 0.981667498126626]\n",
      "  batch 36 loss: [46.45376968383789, 1.8294031620025635]\n",
      "  batch 38 loss: [32.49326419830322, 1.132058560848236]\n",
      "  batch 40 loss: [24.671399116516113, 0.8424826562404633]\n",
      "  batch 42 loss: [26.112804412841797, 0.3855820447206497]\n",
      "  batch 44 loss: [33.51752471923828, 0.6834618151187897]\n",
      "  batch 46 loss: [33.14151954650879, 0.2273734286427498]\n",
      "  batch 48 loss: [28.121469497680664, 0.42474839091300964]\n",
      "  batch 50 loss: [38.48123359680176, 0.3269025683403015]\n",
      "  batch 52 loss: [30.208698272705078, 0.22922220081090927]\n",
      "  batch 54 loss: [28.800601959228516, 0.10047296062111855]\n",
      "LOSS generator 28.800601959228516 discriminator 0.10047296062111855\n",
      "EPOCH 120:\n",
      "  batch 0 loss: [31.189538955688477, 0.07992212474346161]\n",
      "  batch 2 loss: [33.839590072631836, 0.11833923868834972]\n",
      "  batch 4 loss: [31.317100524902344, 0.21466630697250366]\n",
      "  batch 6 loss: [31.30482578277588, 0.14404046162962914]\n",
      "  batch 8 loss: [30.333314895629883, 0.1871165931224823]\n",
      "  batch 10 loss: [30.799612998962402, 0.1537586748600006]\n",
      "  batch 12 loss: [36.72319793701172, 0.22625114768743515]\n",
      "  batch 14 loss: [33.210235595703125, 0.09512880817055702]\n",
      "  batch 16 loss: [37.058387756347656, 0.036099229007959366]\n",
      "  batch 18 loss: [26.0827693939209, 0.2657780423760414]\n",
      "  batch 20 loss: [36.29084873199463, 0.4124399572610855]\n",
      "  batch 22 loss: [33.84481334686279, 0.4472216069698334]\n",
      "  batch 24 loss: [35.4692440032959, 0.2196817584335804]\n",
      "  batch 26 loss: [30.661224365234375, 0.2016036957502365]\n",
      "  batch 28 loss: [30.38895034790039, 0.3422187864780426]\n",
      "  batch 30 loss: [35.771629333496094, 0.23774991184473038]\n",
      "  batch 32 loss: [29.635181427001953, 0.1358724981546402]\n",
      "  batch 34 loss: [28.92538833618164, 0.08863145671784878]\n",
      "  batch 36 loss: [30.294886589050293, 0.13825485855340958]\n",
      "  batch 38 loss: [25.266958236694336, 0.10998188704252243]\n",
      "  batch 40 loss: [27.751065254211426, 0.10407553240656853]\n",
      "  batch 42 loss: [32.61674880981445, 0.04669288545846939]\n",
      "  batch 44 loss: [34.26215934753418, 0.04957219958305359]\n",
      "  batch 46 loss: [31.951223373413086, 0.02638864330947399]\n",
      "  batch 48 loss: [32.56753158569336, 0.05231700278818607]\n",
      "  batch 50 loss: [33.39593315124512, 0.06400706246495247]\n",
      "  batch 52 loss: [30.194911003112793, 0.07467540726065636]\n",
      "  batch 54 loss: [36.147592544555664, 0.009824729058891535]\n",
      "LOSS generator 36.147592544555664 discriminator 0.009824729058891535\n",
      "EPOCH 121:\n",
      "  batch 0 loss: [37.20515823364258, 0.06343136727809906]\n",
      "  batch 2 loss: [32.21109390258789, 0.06656905263662338]\n",
      "  batch 4 loss: [29.692021369934082, 0.06117636803537607]\n",
      "  batch 6 loss: [34.530378341674805, 0.06378377042710781]\n",
      "  batch 8 loss: [33.21352577209473, 0.04824951849877834]\n",
      "  batch 10 loss: [28.85146713256836, 0.02754933387041092]\n",
      "  batch 12 loss: [30.327848434448242, 0.04164333455264568]\n",
      "  batch 14 loss: [40.38799285888672, 0.038919908460229635]\n",
      "  batch 16 loss: [36.53682518005371, 0.012555105844512582]\n",
      "  batch 18 loss: [30.817320823669434, 0.021807136945426464]\n",
      "  batch 20 loss: [30.486595153808594, 0.032748183235526085]\n",
      "  batch 22 loss: [30.996856689453125, 0.018463831394910812]\n",
      "  batch 24 loss: [31.640904426574707, 0.03163367323577404]\n",
      "  batch 26 loss: [33.21099281311035, 0.05269403848797083]\n",
      "  batch 28 loss: [30.620732307434082, 0.06710901111364365]\n",
      "  batch 30 loss: [28.98807716369629, 0.01710696378722787]\n",
      "  batch 32 loss: [35.58425045013428, 0.06319721043109894]\n",
      "  batch 34 loss: [34.89011287689209, 0.11487878393381834]\n",
      "  batch 36 loss: [34.18698692321777, 0.01609016302973032]\n",
      "  batch 38 loss: [34.81886863708496, 0.03379944525659084]\n",
      "  batch 40 loss: [33.22295570373535, 0.01964695379137993]\n",
      "  batch 42 loss: [33.60006809234619, 0.10048572439700365]\n",
      "  batch 44 loss: [37.22640609741211, 0.06972096115350723]\n",
      "  batch 46 loss: [37.04378318786621, 0.0071782395243644714]\n",
      "  batch 48 loss: [32.9444522857666, 0.02567197848111391]\n",
      "  batch 50 loss: [28.689950942993164, 0.01763355266302824]\n",
      "  batch 52 loss: [39.108638763427734, 0.02925701066851616]\n",
      "  batch 54 loss: [34.54909420013428, 0.07017025351524353]\n",
      "LOSS generator 34.54909420013428 discriminator 0.07017025351524353\n",
      "EPOCH 122:\n",
      "  batch 0 loss: [35.24376678466797, 0.06957480311393738]\n",
      "  batch 2 loss: [36.61803436279297, 0.05101960524916649]\n",
      "  batch 4 loss: [28.328325271606445, 0.04325157217681408]\n",
      "  batch 6 loss: [29.672677040100098, 0.02162665780633688]\n",
      "  batch 8 loss: [32.68469047546387, 0.024924312718212605]\n",
      "  batch 10 loss: [32.990665435791016, 0.060319334268569946]\n",
      "  batch 12 loss: [28.089580535888672, 0.01750617753714323]\n",
      "  batch 14 loss: [32.70645332336426, 0.024240470491349697]\n",
      "  batch 16 loss: [34.11594009399414, 0.020862562581896782]\n",
      "  batch 18 loss: [34.11184501647949, 0.033219418255612254]\n",
      "  batch 20 loss: [37.75123405456543, 0.053061364218592644]\n",
      "  batch 22 loss: [36.90810585021973, 0.029927550349384546]\n",
      "  batch 24 loss: [37.30768585205078, 0.03508238913491368]\n",
      "  batch 26 loss: [33.54349136352539, 0.018649550154805183]\n",
      "  batch 28 loss: [35.313472747802734, 0.11890861205756664]\n",
      "  batch 30 loss: [33.43771743774414, 0.04216074291616678]\n",
      "  batch 32 loss: [37.33494281768799, 0.03667747601866722]\n",
      "  batch 34 loss: [31.21510601043701, 0.00987607054412365]\n",
      "  batch 36 loss: [37.32577896118164, 0.027879676781594753]\n",
      "  batch 38 loss: [33.745649337768555, 0.007666640216484666]\n",
      "  batch 40 loss: [33.520368576049805, 0.018708291463553905]\n",
      "  batch 42 loss: [38.27863883972168, 0.018182747066020966]\n",
      "  batch 44 loss: [29.40241050720215, 0.00671307323500514]\n",
      "  batch 46 loss: [37.458221435546875, 0.03991216793656349]\n",
      "  batch 48 loss: [35.61651039123535, 0.030465765856206417]\n",
      "  batch 50 loss: [30.2966365814209, 0.06137642543762922]\n",
      "  batch 52 loss: [29.45611572265625, 0.05949716828763485]\n",
      "  batch 54 loss: [30.744559288024902, 0.028041829355061054]\n",
      "LOSS generator 30.744559288024902 discriminator 0.028041829355061054\n",
      "EPOCH 123:\n",
      "  batch 0 loss: [42.94073486328125, 0.08008424937725067]\n",
      "  batch 2 loss: [30.52226734161377, 0.04782033525407314]\n",
      "  batch 4 loss: [37.22183418273926, 0.03728015720844269]\n",
      "  batch 6 loss: [37.76016426086426, 0.03187577426433563]\n",
      "  batch 8 loss: [32.139163970947266, 0.03678416134789586]\n",
      "  batch 10 loss: [36.56098556518555, 0.03281890042126179]\n",
      "  batch 12 loss: [31.934221267700195, 0.02169624948874116]\n",
      "  batch 14 loss: [28.28046989440918, 0.03852223791182041]\n",
      "  batch 16 loss: [32.94572162628174, 0.025858310982584953]\n",
      "  batch 18 loss: [28.047672271728516, 0.015116340480744839]\n",
      "  batch 20 loss: [39.940948486328125, 0.06930050067603588]\n",
      "  batch 22 loss: [34.56586265563965, 0.05498565919697285]\n",
      "  batch 24 loss: [29.750579833984375, 0.04631919413805008]\n",
      "  batch 26 loss: [27.589537620544434, 0.08278787508606911]\n",
      "  batch 28 loss: [33.34944152832031, 0.026219526305794716]\n",
      "  batch 30 loss: [34.88166427612305, 0.047602493315935135]\n",
      "  batch 32 loss: [34.57524108886719, 0.020176514517515898]\n",
      "  batch 34 loss: [35.59998893737793, 0.033690065145492554]\n",
      "  batch 36 loss: [32.59135341644287, 0.02749356534332037]\n",
      "  batch 38 loss: [33.9443473815918, 0.023542086593806744]\n",
      "  batch 40 loss: [38.75592803955078, 0.0029426926048472524]\n",
      "  batch 42 loss: [36.886322021484375, 0.019523884169757366]\n",
      "  batch 44 loss: [37.339351654052734, 0.02502385340631008]\n",
      "  batch 46 loss: [36.90843200683594, 0.03379209153354168]\n",
      "  batch 48 loss: [29.203763008117676, 0.031287568621337414]\n",
      "  batch 50 loss: [32.42033576965332, 0.02063477598130703]\n",
      "  batch 52 loss: [30.925710678100586, 0.01916198804974556]\n",
      "  batch 54 loss: [35.6987247467041, 0.02246937563177198]\n",
      "LOSS generator 35.6987247467041 discriminator 0.02246937563177198\n",
      "EPOCH 124:\n",
      "  batch 0 loss: [31.573986053466797, 0.017376048490405083]\n",
      "  batch 2 loss: [31.06975746154785, 0.02123650722205639]\n",
      "  batch 4 loss: [33.58388710021973, 0.012508861487731338]\n",
      "  batch 6 loss: [36.35148811340332, 0.043043770827353]\n",
      "  batch 8 loss: [29.25648784637451, 0.04696126189082861]\n",
      "  batch 10 loss: [29.01865005493164, 0.02030123583972454]\n",
      "  batch 12 loss: [33.83387756347656, 0.03289416804909706]\n",
      "  batch 14 loss: [35.37008476257324, 0.01622197311371565]\n",
      "  batch 16 loss: [31.477216720581055, 0.008528840378858149]\n",
      "  batch 18 loss: [34.12704944610596, 0.013610574416816235]\n",
      "  batch 20 loss: [33.59396743774414, 0.03272412531077862]\n",
      "  batch 22 loss: [35.163557052612305, 0.01767825521528721]\n",
      "  batch 24 loss: [34.72203063964844, 0.02083424525335431]\n",
      "  batch 26 loss: [32.859750747680664, 0.014120216015726328]\n",
      "  batch 28 loss: [30.164517402648926, 0.01067073317244649]\n",
      "  batch 30 loss: [34.85421943664551, 0.02751756552606821]\n",
      "  batch 32 loss: [31.14452075958252, 0.018357168417423964]\n",
      "  batch 34 loss: [37.76906967163086, 0.029607850359752774]\n",
      "  batch 36 loss: [34.8660888671875, 0.016085437033325434]\n",
      "  batch 38 loss: [36.14258003234863, 0.012615642976015806]\n",
      "  batch 40 loss: [34.89638328552246, 0.011640997370705009]\n",
      "  batch 42 loss: [36.56846046447754, 0.03055060375481844]\n",
      "  batch 44 loss: [37.41050338745117, 0.014797739684581757]\n",
      "  batch 46 loss: [33.73628616333008, 0.03718856628984213]\n",
      "  batch 48 loss: [31.98631000518799, 0.022488185670226812]\n",
      "  batch 50 loss: [36.663217544555664, 0.028406880795955658]\n",
      "  batch 52 loss: [30.958240509033203, 0.08545228745788336]\n",
      "  batch 54 loss: [35.42989921569824, 0.019834418781101704]\n",
      "LOSS generator 35.42989921569824 discriminator 0.019834418781101704\n",
      "EPOCH 125:\n",
      "  batch 0 loss: [44.36957550048828, 0.09782826900482178]\n",
      "  batch 2 loss: [36.32259559631348, 0.030337956734001637]\n",
      "  batch 4 loss: [37.79453468322754, 0.04423638433218002]\n",
      "  batch 6 loss: [31.104415893554688, 0.04781373217701912]\n",
      "  batch 8 loss: [32.38155746459961, 0.021782965399324894]\n",
      "  batch 10 loss: [39.1313362121582, 0.03295437525957823]\n",
      "  batch 12 loss: [33.9065055847168, 0.01692209392786026]\n",
      "  batch 14 loss: [36.83977127075195, 0.033064099960029125]\n",
      "  batch 16 loss: [36.357887268066406, 0.014672860503196716]\n",
      "  batch 18 loss: [30.193410873413086, 0.022609165403991938]\n",
      "  batch 20 loss: [29.46808624267578, 0.009526248322799802]\n",
      "  batch 22 loss: [28.489773750305176, 0.006545220734551549]\n",
      "  batch 24 loss: [28.62175178527832, 0.026117738336324692]\n",
      "  batch 26 loss: [34.557472229003906, 0.022986320313066244]\n",
      "  batch 28 loss: [33.97043991088867, 0.024003184866160154]\n",
      "  batch 30 loss: [31.548877716064453, 0.010906320996582508]\n",
      "  batch 32 loss: [35.35378646850586, 0.04540250450372696]\n",
      "  batch 34 loss: [38.675554275512695, 0.005236427765339613]\n",
      "  batch 36 loss: [37.621049880981445, 0.1170362588018179]\n",
      "  batch 38 loss: [33.624807357788086, 0.00793219287879765]\n",
      "  batch 40 loss: [34.33918762207031, 0.004958869190886617]\n",
      "  batch 42 loss: [35.003607749938965, 0.029852217063307762]\n",
      "  batch 44 loss: [33.43860054016113, 0.005431007593870163]\n",
      "  batch 46 loss: [34.83059024810791, 0.0051622476894408464]\n",
      "  batch 48 loss: [30.37489128112793, 0.02923735324293375]\n",
      "  batch 50 loss: [34.65200424194336, 0.003002001903951168]\n",
      "  batch 52 loss: [33.4615592956543, 0.004794985172338784]\n",
      "  batch 54 loss: [34.34759712219238, 0.002529981196857989]\n",
      "LOSS generator 34.34759712219238 discriminator 0.002529981196857989\n",
      "EPOCH 126:\n",
      "  batch 0 loss: [33.75001525878906, 0.05375940352678299]\n",
      "  batch 2 loss: [32.99506950378418, 0.005568809807300568]\n",
      "  batch 4 loss: [34.01276969909668, 0.010539238341152668]\n",
      "  batch 6 loss: [35.523019790649414, 0.020295931957662106]\n",
      "  batch 8 loss: [29.66934585571289, 0.0317661939188838]\n",
      "  batch 10 loss: [33.264732360839844, 0.011327419662848115]\n",
      "  batch 12 loss: [30.91956329345703, 0.02724641654640436]\n",
      "  batch 14 loss: [35.580382347106934, 0.010113998781889677]\n",
      "  batch 16 loss: [33.13335037231445, 0.005981589434668422]\n",
      "  batch 18 loss: [33.87936019897461, 0.006590705830603838]\n",
      "  batch 20 loss: [31.79949951171875, 0.02205165708437562]\n",
      "  batch 22 loss: [38.47078895568848, 0.01810538861900568]\n",
      "  batch 24 loss: [28.972392082214355, 0.02414405532181263]\n",
      "  batch 26 loss: [32.49064254760742, 0.029812663793563843]\n",
      "  batch 28 loss: [38.41389465332031, 0.017894386313855648]\n",
      "  batch 30 loss: [31.276644706726074, 0.08742297533899546]\n",
      "  batch 32 loss: [30.663049697875977, 0.011859112419188023]\n",
      "  batch 34 loss: [38.348981857299805, 0.033693292178213596]\n",
      "  batch 36 loss: [33.268455505371094, 0.015953858848661184]\n",
      "  batch 38 loss: [38.52812576293945, 0.018622370436787605]\n",
      "  batch 40 loss: [35.752389907836914, 0.025745904073119164]\n",
      "  batch 42 loss: [41.917537689208984, 0.03614388220012188]\n",
      "  batch 44 loss: [32.555898666381836, 0.007800744380801916]\n",
      "  batch 46 loss: [31.28226947784424, 0.011503070592880249]\n",
      "  batch 48 loss: [30.769261360168457, 0.0162410419434309]\n",
      "  batch 50 loss: [38.154531478881836, 0.06496118614450097]\n",
      "  batch 52 loss: [33.74133491516113, 0.010416867560707033]\n",
      "  batch 54 loss: [34.64842414855957, 0.054049485363066196]\n",
      "LOSS generator 34.64842414855957 discriminator 0.054049485363066196\n",
      "EPOCH 127:\n",
      "  batch 0 loss: [30.16850471496582, 0.012950439937412739]\n",
      "  batch 2 loss: [31.7971830368042, 0.0911535129416734]\n",
      "  batch 4 loss: [33.47694110870361, 0.1522707138210535]\n",
      "  batch 6 loss: [27.95464038848877, 0.05687971971929073]\n",
      "  batch 8 loss: [31.7705078125, 0.021470933686941862]\n",
      "  batch 10 loss: [36.07533645629883, 0.058593934401869774]\n",
      "  batch 12 loss: [35.599876403808594, 0.02940661832690239]\n",
      "  batch 14 loss: [40.95563507080078, 0.025364828296005726]\n",
      "  batch 16 loss: [34.39101219177246, 0.019058880861848593]\n",
      "  batch 18 loss: [31.905712127685547, 0.018357564928010106]\n",
      "  batch 20 loss: [34.71600532531738, 0.018620934803038836]\n",
      "  batch 22 loss: [34.96436309814453, 0.012213205453008413]\n",
      "  batch 24 loss: [40.02347373962402, 0.04613592475652695]\n",
      "  batch 26 loss: [37.81637954711914, 0.03199917823076248]\n",
      "  batch 28 loss: [29.731040954589844, 0.016716052778065205]\n",
      "  batch 30 loss: [35.30013084411621, 0.03660591971129179]\n",
      "  batch 32 loss: [30.907447814941406, 0.014119165483862162]\n",
      "  batch 34 loss: [30.48818588256836, 0.007442101836204529]\n",
      "  batch 36 loss: [36.64051628112793, 0.08185202442109585]\n",
      "  batch 38 loss: [36.416114807128906, 0.014911131234839559]\n",
      "  batch 40 loss: [33.87499237060547, 0.05112253502011299]\n",
      "  batch 42 loss: [32.80233287811279, 0.04940531775355339]\n",
      "  batch 44 loss: [36.42583465576172, 0.09423004649579525]\n",
      "  batch 46 loss: [35.058380126953125, 0.18569006025791168]\n",
      "  batch 48 loss: [30.247214317321777, 0.44433721899986267]\n",
      "  batch 50 loss: [34.00258541107178, 2.451327383518219]\n",
      "  batch 52 loss: [24.27511501312256, 2.5383331775665283]\n",
      "  batch 54 loss: [27.99841594696045, 0.9367891550064087]\n",
      "LOSS generator 27.99841594696045 discriminator 0.9367891550064087\n",
      "EPOCH 128:\n",
      "  batch 0 loss: [27.083818435668945, 1.3162932395935059]\n",
      "  batch 2 loss: [25.745670318603516, 0.7983447313308716]\n",
      "  batch 4 loss: [31.483108520507812, 1.1711453795433044]\n",
      "  batch 6 loss: [26.95718765258789, 0.8683541715145111]\n",
      "  batch 8 loss: [25.71780300140381, 0.9618679583072662]\n",
      "  batch 10 loss: [29.65024185180664, 1.0202680230140686]\n",
      "  batch 12 loss: [30.220582962036133, 0.7990462779998779]\n",
      "  batch 14 loss: [29.33657741546631, 0.7196776866912842]\n",
      "  batch 16 loss: [22.765504837036133, 0.743843674659729]\n",
      "  batch 18 loss: [26.171971321105957, 0.6457051038742065]\n",
      "  batch 20 loss: [25.876399993896484, 0.6645056009292603]\n",
      "  batch 22 loss: [33.11189556121826, 0.682552695274353]\n",
      "  batch 24 loss: [23.429489135742188, 0.6313087344169617]\n",
      "  batch 26 loss: [26.920655250549316, 0.6602849364280701]\n",
      "  batch 28 loss: [28.173893928527832, 0.5622693598270416]\n",
      "  batch 30 loss: [35.55871391296387, 0.4630406051874161]\n",
      "  batch 32 loss: [28.399621963500977, 0.5129103064537048]\n",
      "  batch 34 loss: [35.53087043762207, 0.41231469810009]\n",
      "  batch 36 loss: [28.102130889892578, 0.3909538686275482]\n",
      "  batch 38 loss: [30.02563190460205, 0.4394059330224991]\n",
      "  batch 40 loss: [24.95977783203125, 0.4843521863222122]\n",
      "  batch 42 loss: [30.52018451690674, 0.33011260628700256]\n",
      "  batch 44 loss: [32.93702793121338, 1.0592182278633118]\n",
      "  batch 46 loss: [27.101431846618652, 0.667226254940033]\n",
      "  batch 48 loss: [29.69729995727539, 1.0391819477081299]\n",
      "  batch 50 loss: [27.71670436859131, 0.6410384178161621]\n",
      "  batch 52 loss: [33.32483196258545, 0.5325368344783783]\n",
      "  batch 54 loss: [26.07167148590088, 0.4978829324245453]\n",
      "LOSS generator 26.07167148590088 discriminator 0.4978829324245453\n",
      "EPOCH 129:\n",
      "  batch 0 loss: [19.56072998046875, 0.7355719208717346]\n",
      "  batch 2 loss: [29.087337493896484, 0.5092159807682037]\n",
      "  batch 4 loss: [27.7686710357666, 0.3677152395248413]\n",
      "  batch 6 loss: [28.080634117126465, 0.38205239176750183]\n",
      "  batch 8 loss: [27.581128120422363, 0.3583661615848541]\n",
      "  batch 10 loss: [29.86942481994629, 0.2020583599805832]\n",
      "  batch 12 loss: [27.194841384887695, 0.3580833822488785]\n",
      "  batch 14 loss: [23.51859188079834, 0.3368518427014351]\n",
      "  batch 16 loss: [32.707173347473145, 0.19691656529903412]\n",
      "  batch 18 loss: [28.485877990722656, 0.19022417813539505]\n",
      "  batch 20 loss: [34.16222667694092, 0.24220852553844452]\n",
      "  batch 22 loss: [33.52928352355957, 0.15911006927490234]\n",
      "  batch 24 loss: [31.997432708740234, 0.2549659162759781]\n",
      "  batch 26 loss: [28.272014617919922, 0.13682404905557632]\n",
      "  batch 28 loss: [26.559367179870605, 0.38528937101364136]\n",
      "  batch 30 loss: [34.41429328918457, 0.43507109582424164]\n",
      "  batch 32 loss: [25.15634822845459, 0.40250009298324585]\n",
      "  batch 34 loss: [27.49251937866211, 0.28412187099456787]\n",
      "  batch 36 loss: [29.704647064208984, 0.1850343644618988]\n",
      "  batch 38 loss: [26.814924240112305, 0.14187273383140564]\n",
      "  batch 40 loss: [33.3056526184082, 0.13625550270080566]\n",
      "  batch 42 loss: [37.72432899475098, 0.16288850456476212]\n",
      "  batch 44 loss: [28.636079788208008, 0.12243109196424484]\n",
      "  batch 46 loss: [27.50771141052246, 0.12670546397566795]\n",
      "  batch 48 loss: [31.841476440429688, 0.04828314110636711]\n",
      "  batch 50 loss: [39.355783462524414, 0.17208580672740936]\n",
      "  batch 52 loss: [34.88179397583008, 0.1765400543808937]\n",
      "  batch 54 loss: [36.84202575683594, 0.1206592433154583]\n",
      "LOSS generator 36.84202575683594 discriminator 0.1206592433154583\n",
      "EPOCH 130:\n",
      "  batch 0 loss: [26.856401443481445, 0.18524169921875]\n",
      "  batch 2 loss: [27.36832618713379, 0.22127052396535873]\n",
      "  batch 4 loss: [28.824472427368164, 0.06313620880246162]\n",
      "  batch 6 loss: [34.434547424316406, 0.0732743926346302]\n",
      "  batch 8 loss: [26.769619941711426, 0.11952362209558487]\n",
      "  batch 10 loss: [34.10318183898926, 0.10280856862664223]\n",
      "  batch 12 loss: [32.08139896392822, 0.049302127212285995]\n",
      "  batch 14 loss: [36.797584533691406, 0.05482218414545059]\n",
      "  batch 16 loss: [29.788691520690918, 0.07899050414562225]\n",
      "  batch 18 loss: [31.798470497131348, 0.20908724330365658]\n",
      "  batch 20 loss: [33.482998847961426, 0.14654479920864105]\n",
      "  batch 22 loss: [30.49421215057373, 0.21192116290330887]\n",
      "  batch 24 loss: [29.95841407775879, 0.13931890577077866]\n",
      "  batch 26 loss: [40.607675552368164, 0.22399870306253433]\n",
      "  batch 28 loss: [31.897730827331543, 0.2064303234219551]\n",
      "  batch 30 loss: [28.52980136871338, 0.11355058290064335]\n",
      "  batch 32 loss: [36.1635684967041, 0.06878183595836163]\n",
      "  batch 34 loss: [28.256470680236816, 0.18732523918151855]\n",
      "  batch 36 loss: [35.97026824951172, 0.09161353297531605]\n",
      "  batch 38 loss: [27.755845069885254, 0.14588110893964767]\n",
      "  batch 40 loss: [36.26397132873535, 0.04479029029607773]\n",
      "  batch 42 loss: [30.20486545562744, 0.11652864888310432]\n",
      "  batch 44 loss: [32.54662799835205, 0.11854448355734348]\n",
      "  batch 46 loss: [30.696414947509766, 0.3012436032295227]\n",
      "  batch 48 loss: [26.796085357666016, 0.20019685477018356]\n",
      "  batch 50 loss: [33.485191345214844, 0.5805996805429459]\n",
      "  batch 52 loss: [25.955751419067383, 0.6396023333072662]\n",
      "  batch 54 loss: [30.58204746246338, 0.5412561893463135]\n",
      "LOSS generator 30.58204746246338 discriminator 0.5412561893463135\n",
      "EPOCH 131:\n",
      "  batch 0 loss: [31.862842559814453, 0.3761306703090668]\n",
      "  batch 2 loss: [25.211970329284668, 0.2886195480823517]\n",
      "  batch 4 loss: [31.72459602355957, 0.2202581912279129]\n",
      "  batch 6 loss: [30.443899154663086, 0.3630470484495163]\n",
      "  batch 8 loss: [30.234780311584473, 0.40999703109264374]\n",
      "  batch 10 loss: [27.292019844055176, 0.44775283336639404]\n",
      "  batch 12 loss: [30.605950355529785, 0.2282024249434471]\n",
      "  batch 14 loss: [28.045676231384277, 0.20964085310697556]\n",
      "  batch 16 loss: [27.641560554504395, 0.18322942405939102]\n",
      "  batch 18 loss: [29.37788200378418, 0.14675767719745636]\n",
      "  batch 20 loss: [31.673171043395996, 0.349753201007843]\n",
      "  batch 22 loss: [31.178884506225586, 0.21623069792985916]\n",
      "  batch 24 loss: [36.48805618286133, 0.0957033783197403]\n",
      "  batch 26 loss: [31.972015380859375, 0.13911599665880203]\n",
      "  batch 28 loss: [29.610641479492188, 0.13620765879750252]\n",
      "  batch 30 loss: [28.183459281921387, 0.1395254135131836]\n",
      "  batch 32 loss: [29.99413013458252, 0.15493033826351166]\n",
      "  batch 34 loss: [37.35418510437012, 0.1005726046860218]\n",
      "  batch 36 loss: [26.481403350830078, 0.39310164749622345]\n",
      "  batch 38 loss: [27.991459846496582, 0.15929611027240753]\n",
      "  batch 40 loss: [31.975759506225586, 0.1068306416273117]\n",
      "  batch 42 loss: [35.09706974029541, 0.08318190649151802]\n",
      "  batch 44 loss: [35.97430992126465, 0.06433894485235214]\n",
      "  batch 46 loss: [30.967195510864258, 0.08958664909005165]\n",
      "  batch 48 loss: [35.2136287689209, 0.06451684795320034]\n",
      "  batch 50 loss: [29.22256851196289, 0.11149448156356812]\n",
      "  batch 52 loss: [36.26773643493652, 0.14532636106014252]\n",
      "  batch 54 loss: [25.929851531982422, 0.11353657767176628]\n",
      "LOSS generator 25.929851531982422 discriminator 0.11353657767176628\n",
      "EPOCH 132:\n",
      "  batch 0 loss: [38.27292251586914, 0.07251378893852234]\n",
      "  batch 2 loss: [30.66952133178711, 0.136948611587286]\n",
      "  batch 4 loss: [31.657780647277832, 0.1869879588484764]\n",
      "  batch 6 loss: [37.01054000854492, 0.26982487738132477]\n",
      "  batch 8 loss: [29.968952178955078, 0.2719271555542946]\n",
      "  batch 10 loss: [30.808895111083984, 0.12103642523288727]\n",
      "  batch 12 loss: [40.708791732788086, 0.06581688672304153]\n",
      "  batch 14 loss: [26.50140380859375, 0.09426913782954216]\n",
      "  batch 16 loss: [27.540696144104004, 0.09879042208194733]\n",
      "  batch 18 loss: [26.806286811828613, 0.11171861737966537]\n",
      "  batch 20 loss: [31.90827751159668, 0.08597661182284355]\n",
      "  batch 22 loss: [34.93576431274414, 0.08887309394776821]\n",
      "  batch 24 loss: [31.723663330078125, 0.06825139373540878]\n",
      "  batch 26 loss: [33.48184776306152, 0.042207272723317146]\n",
      "  batch 28 loss: [33.0464391708374, 0.06357195414602757]\n",
      "  batch 30 loss: [30.925447463989258, 0.11613704264163971]\n",
      "  batch 32 loss: [32.79068183898926, 0.027425263077020645]\n",
      "  batch 34 loss: [27.39027976989746, 0.09887899830937386]\n",
      "  batch 36 loss: [33.467655181884766, 0.16940495371818542]\n",
      "  batch 38 loss: [27.692782402038574, 0.17531464993953705]\n",
      "  batch 40 loss: [29.81890106201172, 0.04316515289247036]\n",
      "  batch 42 loss: [30.01742172241211, 0.07533377595245838]\n",
      "  batch 44 loss: [31.592327117919922, 0.06493763998150826]\n",
      "  batch 46 loss: [34.702157974243164, 0.05394057370722294]\n",
      "  batch 48 loss: [37.60830116271973, 0.053477803245186806]\n",
      "  batch 50 loss: [29.682058334350586, 0.09148334339261055]\n",
      "  batch 52 loss: [37.95365333557129, 0.05674256011843681]\n",
      "  batch 54 loss: [33.083810806274414, 0.024094519205391407]\n",
      "LOSS generator 33.083810806274414 discriminator 0.024094519205391407\n",
      "EPOCH 133:\n",
      "  batch 0 loss: [33.94437789916992, 0.052702516317367554]\n",
      "  batch 2 loss: [38.759700775146484, 0.05236746557056904]\n",
      "  batch 4 loss: [36.39486026763916, 0.03423811495304108]\n",
      "  batch 6 loss: [30.37525177001953, 0.12800410762429237]\n",
      "  batch 8 loss: [27.092576026916504, 0.17653444036841393]\n",
      "  batch 10 loss: [32.989540100097656, 0.25275277346372604]\n",
      "  batch 12 loss: [31.627809524536133, 0.10605842247605324]\n",
      "  batch 14 loss: [34.87681007385254, 0.03759485110640526]\n",
      "  batch 16 loss: [32.96391677856445, 0.020379889756441116]\n",
      "  batch 18 loss: [31.25389003753662, 0.05504767782986164]\n",
      "  batch 20 loss: [34.58796691894531, 0.05682789720594883]\n",
      "  batch 22 loss: [34.87380599975586, 0.11244580894708633]\n",
      "  batch 24 loss: [26.590981483459473, 0.05528557300567627]\n",
      "  batch 26 loss: [33.08190727233887, 0.1389576531946659]\n",
      "  batch 28 loss: [29.448678970336914, 0.1330549530684948]\n",
      "  batch 30 loss: [30.036677360534668, 0.06557846069335938]\n",
      "  batch 32 loss: [35.537346839904785, 0.04919441603124142]\n",
      "  batch 34 loss: [35.21368980407715, 0.021762149408459663]\n",
      "  batch 36 loss: [30.671936988830566, 0.21442269533872604]\n",
      "  batch 38 loss: [29.852458000183105, 0.08573046326637268]\n",
      "  batch 40 loss: [32.972673416137695, 0.14623001404106617]\n",
      "  batch 42 loss: [35.2641716003418, 0.059896089136600494]\n",
      "  batch 44 loss: [28.04539680480957, 0.10041361954063177]\n",
      "  batch 46 loss: [37.91618728637695, 0.10396088287234306]\n",
      "  batch 48 loss: [32.12837791442871, 0.03485597297549248]\n",
      "  batch 50 loss: [32.06697750091553, 0.025749376974999905]\n",
      "  batch 52 loss: [33.680158615112305, 0.05807898007333279]\n",
      "  batch 54 loss: [29.623708724975586, 0.050183724611997604]\n",
      "LOSS generator 29.623708724975586 discriminator 0.050183724611997604\n",
      "EPOCH 134:\n",
      "  batch 0 loss: [36.193817138671875, 0.008053035475313663]\n",
      "  batch 2 loss: [33.02029037475586, 0.010502081830054522]\n",
      "  batch 4 loss: [32.90274906158447, 0.07114085555076599]\n",
      "  batch 6 loss: [27.211010932922363, 0.07328109443187714]\n",
      "  batch 8 loss: [30.600845336914062, 0.054694220423698425]\n",
      "  batch 10 loss: [29.410184860229492, 0.040805406868457794]\n",
      "  batch 12 loss: [34.54587364196777, 0.05731028225272894]\n",
      "  batch 14 loss: [31.776116371154785, 0.050420457031577826]\n",
      "  batch 16 loss: [40.56615447998047, 0.029719476820901036]\n",
      "  batch 18 loss: [34.90670394897461, 0.06337530165910721]\n",
      "  batch 20 loss: [33.78774833679199, 0.12324121408164501]\n",
      "  batch 22 loss: [29.72555923461914, 0.05351722612977028]\n",
      "  batch 24 loss: [31.449591636657715, 0.064511027187109]\n",
      "  batch 26 loss: [30.030707359313965, 0.05029786750674248]\n",
      "  batch 28 loss: [36.300506591796875, 0.05588621459901333]\n",
      "  batch 30 loss: [30.373828887939453, 0.09118440374732018]\n",
      "  batch 32 loss: [30.117201805114746, 0.0665268823504448]\n",
      "  batch 34 loss: [31.279537200927734, 0.030535075813531876]\n",
      "  batch 36 loss: [33.928627014160156, 0.05487672798335552]\n",
      "  batch 38 loss: [28.425479888916016, 0.03019273281097412]\n",
      "  batch 40 loss: [33.08220386505127, 0.14238111674785614]\n",
      "  batch 42 loss: [34.71733856201172, 0.0384162962436676]\n",
      "  batch 44 loss: [31.77500057220459, 0.04356242390349507]\n",
      "  batch 46 loss: [35.543718338012695, 0.04978947155177593]\n",
      "  batch 48 loss: [32.444332122802734, 0.08219201862812042]\n",
      "  batch 50 loss: [31.636310577392578, 0.020671697333455086]\n",
      "  batch 52 loss: [35.25096321105957, 0.133422389626503]\n",
      "  batch 54 loss: [39.133127212524414, 0.08438657224178314]\n",
      "LOSS generator 39.133127212524414 discriminator 0.08438657224178314\n",
      "EPOCH 135:\n",
      "  batch 0 loss: [31.208755493164062, 0.09444712102413177]\n",
      "  batch 2 loss: [34.03225517272949, 0.09930935874581337]\n",
      "  batch 4 loss: [30.954059600830078, 0.020967436023056507]\n",
      "  batch 6 loss: [30.859500885009766, 0.05976995639503002]\n",
      "  batch 8 loss: [36.1087589263916, 0.017316186800599098]\n",
      "  batch 10 loss: [32.064205169677734, 0.13370292261242867]\n",
      "  batch 12 loss: [30.730484008789062, 0.08531135320663452]\n",
      "  batch 14 loss: [39.06545066833496, 0.0875910334289074]\n",
      "  batch 16 loss: [30.79254722595215, 0.08446708973497152]\n",
      "  batch 18 loss: [30.484097480773926, 0.03649764321744442]\n",
      "  batch 20 loss: [34.75012016296387, 0.025328166782855988]\n",
      "  batch 22 loss: [33.82432556152344, 0.04746025521308184]\n",
      "  batch 24 loss: [26.478676795959473, 0.03368845861405134]\n",
      "  batch 26 loss: [35.5493049621582, 0.052119141444563866]\n",
      "  batch 28 loss: [38.11351776123047, 0.02399691380560398]\n",
      "  batch 30 loss: [29.1840181350708, 0.03449079114943743]\n",
      "  batch 32 loss: [27.22662353515625, 0.0428544906899333]\n",
      "  batch 34 loss: [37.678951263427734, 0.01042118645273149]\n",
      "  batch 36 loss: [34.6586799621582, 0.01610894361510873]\n",
      "  batch 38 loss: [30.013178825378418, 0.06427622400224209]\n",
      "  batch 40 loss: [37.54612159729004, 0.028318334370851517]\n",
      "  batch 42 loss: [30.87789821624756, 0.09190449118614197]\n",
      "  batch 44 loss: [33.47494316101074, 0.0221059899777174]\n",
      "  batch 46 loss: [33.71937084197998, 0.08741329610347748]\n",
      "  batch 48 loss: [29.378060340881348, 0.15237800776958466]\n",
      "  batch 50 loss: [34.63882827758789, 0.1389031484723091]\n",
      "  batch 52 loss: [35.69092559814453, 0.059967600740492344]\n",
      "  batch 54 loss: [33.936964988708496, 0.08237897977232933]\n",
      "LOSS generator 33.936964988708496 discriminator 0.08237897977232933\n",
      "EPOCH 136:\n",
      "  batch 0 loss: [32.512474060058594, 0.01746688038110733]\n",
      "  batch 2 loss: [37.38826370239258, 0.08841664344072342]\n",
      "  batch 4 loss: [31.572120666503906, 0.0609296765178442]\n",
      "  batch 6 loss: [30.795931816101074, 0.039690518751740456]\n",
      "  batch 8 loss: [31.55401039123535, 0.06721429154276848]\n",
      "  batch 10 loss: [34.6841402053833, 0.12368794530630112]\n",
      "  batch 12 loss: [29.794625282287598, 0.0750516802072525]\n",
      "  batch 14 loss: [33.34082317352295, 0.08580577746033669]\n",
      "  batch 16 loss: [34.27351951599121, 0.08844860084354877]\n",
      "  batch 18 loss: [31.96395492553711, 0.09955454617738724]\n",
      "  batch 20 loss: [38.98812484741211, 0.039025334641337395]\n",
      "  batch 22 loss: [40.173927307128906, 0.1370994672179222]\n",
      "  batch 24 loss: [30.604939460754395, 0.025911999866366386]\n",
      "  batch 26 loss: [31.177169799804688, 0.05213121511042118]\n",
      "  batch 28 loss: [36.6138801574707, 0.039678847417235374]\n",
      "  batch 30 loss: [35.9290714263916, 0.0764632411301136]\n",
      "  batch 32 loss: [28.882047653198242, 0.043766483664512634]\n",
      "  batch 34 loss: [25.88772487640381, 0.1115013137459755]\n",
      "  batch 36 loss: [34.5699520111084, 0.04065058287233114]\n",
      "  batch 38 loss: [31.54128074645996, 0.03968041576445103]\n",
      "  batch 40 loss: [31.920964241027832, 0.033809117041528225]\n",
      "  batch 42 loss: [31.961289405822754, 0.04666701517999172]\n",
      "  batch 44 loss: [33.391499519348145, 0.07622312381863594]\n",
      "  batch 46 loss: [28.585999488830566, 0.05245748721063137]\n",
      "  batch 48 loss: [30.8392915725708, 0.03083747997879982]\n",
      "  batch 50 loss: [36.9093074798584, 0.021538311149924994]\n",
      "  batch 52 loss: [25.883420944213867, 0.1451487336307764]\n",
      "  batch 54 loss: [37.452863693237305, 0.01777965296059847]\n",
      "LOSS generator 37.452863693237305 discriminator 0.01777965296059847\n",
      "EPOCH 137:\n",
      "  batch 0 loss: [35.9105224609375, 0.03631427139043808]\n",
      "  batch 2 loss: [26.41145610809326, 0.09434445202350616]\n",
      "  batch 4 loss: [32.10166549682617, 0.017501731868833303]\n",
      "  batch 6 loss: [31.627117156982422, 0.1166607178747654]\n",
      "  batch 8 loss: [31.021878242492676, 0.024237926118075848]\n",
      "  batch 10 loss: [29.336517333984375, 0.03744955640286207]\n",
      "  batch 12 loss: [35.41217231750488, 0.037161195650696754]\n",
      "  batch 14 loss: [29.699209213256836, 0.032279349863529205]\n",
      "  batch 16 loss: [28.074355125427246, 0.026666988618671894]\n",
      "  batch 18 loss: [29.813127517700195, 0.02430261392146349]\n",
      "  batch 20 loss: [35.80250930786133, 0.029120005201548338]\n",
      "  batch 22 loss: [35.693647384643555, 0.0730272475630045]\n",
      "  batch 24 loss: [30.05910873413086, 0.05184737779200077]\n",
      "  batch 26 loss: [33.10938358306885, 0.031331513077020645]\n",
      "  batch 28 loss: [31.032211303710938, 0.022346924990415573]\n",
      "  batch 30 loss: [40.32975196838379, 0.08101458568125963]\n",
      "  batch 32 loss: [31.150500297546387, 0.06655972078442574]\n",
      "  batch 34 loss: [31.150522232055664, 0.014355048071593046]\n",
      "  batch 36 loss: [32.76983070373535, 0.03816619981080294]\n",
      "  batch 38 loss: [41.99195098876953, 0.0821053427644074]\n",
      "  batch 40 loss: [28.64593505859375, 0.05290278419852257]\n",
      "  batch 42 loss: [36.496849060058594, 0.041487257927656174]\n",
      "  batch 44 loss: [34.39464282989502, 0.08337177708745003]\n",
      "  batch 46 loss: [33.139678955078125, 0.018814227543771267]\n",
      "  batch 48 loss: [33.998908042907715, 0.07270727213472128]\n",
      "  batch 50 loss: [35.74089813232422, 0.06883994117379189]\n",
      "  batch 52 loss: [36.20802307128906, 0.044443774968385696]\n",
      "  batch 54 loss: [39.787139892578125, 0.032618691213428974]\n",
      "LOSS generator 39.787139892578125 discriminator 0.032618691213428974\n",
      "EPOCH 138:\n",
      "  batch 0 loss: [32.61773681640625, 0.047908294945955276]\n",
      "  batch 2 loss: [36.5344123840332, 0.020777707919478416]\n",
      "  batch 4 loss: [27.231024742126465, 0.10339619964361191]\n",
      "  batch 6 loss: [28.64011287689209, 0.02277873083949089]\n",
      "  batch 8 loss: [34.30235481262207, 0.05794846452772617]\n",
      "  batch 10 loss: [39.802616119384766, 0.0841100849211216]\n",
      "  batch 12 loss: [35.95547103881836, 0.017821646761149168]\n",
      "  batch 14 loss: [36.27380180358887, 0.009845382533967495]\n",
      "  batch 16 loss: [32.78240966796875, 0.08511380478739738]\n",
      "  batch 18 loss: [27.686386108398438, 0.06396853551268578]\n",
      "  batch 20 loss: [32.70774555206299, 0.05927206762135029]\n",
      "  batch 22 loss: [38.41299057006836, 0.11139811668545008]\n",
      "  batch 24 loss: [31.881513595581055, 0.18137024622410536]\n",
      "  batch 26 loss: [34.09769058227539, 0.44464361667633057]\n",
      "  batch 28 loss: [29.567094802856445, 0.4379336088895798]\n",
      "  batch 30 loss: [31.250189781188965, 0.23760634660720825]\n",
      "  batch 32 loss: [27.55368709564209, 0.2350662499666214]\n",
      "  batch 34 loss: [30.106263160705566, 0.18893834948539734]\n",
      "  batch 36 loss: [34.45685958862305, 0.11106691882014275]\n",
      "  batch 38 loss: [29.14530086517334, 0.0745982751250267]\n",
      "  batch 40 loss: [37.17551040649414, 0.04782401164993644]\n",
      "  batch 42 loss: [33.16068649291992, 0.05975797772407532]\n",
      "  batch 44 loss: [32.41102886199951, 0.11072316020727158]\n",
      "  batch 46 loss: [29.73917007446289, 0.11203121207654476]\n",
      "  batch 48 loss: [33.594468116760254, 0.07820466719567776]\n",
      "  batch 50 loss: [28.166436195373535, 0.12169540673494339]\n",
      "  batch 52 loss: [33.34488868713379, 0.09963996522128582]\n",
      "  batch 54 loss: [33.165921211242676, 0.1157253049314022]\n",
      "LOSS generator 33.165921211242676 discriminator 0.1157253049314022\n",
      "EPOCH 139:\n",
      "  batch 0 loss: [26.8944091796875, 0.07137318700551987]\n",
      "  batch 2 loss: [34.31119155883789, 0.06318346783518791]\n",
      "  batch 4 loss: [35.10691833496094, 0.0585650447756052]\n",
      "  batch 6 loss: [27.006529808044434, 0.07016678899526596]\n",
      "  batch 8 loss: [30.367939949035645, 0.04964400269091129]\n",
      "  batch 10 loss: [32.42925834655762, 0.08865802362561226]\n",
      "  batch 12 loss: [36.92714309692383, 0.04952345695346594]\n",
      "  batch 14 loss: [36.96194076538086, 0.07162548787891865]\n",
      "  batch 16 loss: [30.009357452392578, 0.108765484765172]\n",
      "  batch 18 loss: [35.35640907287598, 0.5213589370250702]\n",
      "  batch 20 loss: [28.26475429534912, 0.2615911364555359]\n",
      "  batch 22 loss: [37.52145957946777, 0.03821654757484794]\n",
      "  batch 24 loss: [34.97030067443848, 0.07212914153933525]\n",
      "  batch 26 loss: [32.41460609436035, 0.04661812260746956]\n",
      "  batch 28 loss: [33.172372817993164, 0.03901645937003195]\n",
      "  batch 30 loss: [34.392364501953125, 0.045565588399767876]\n",
      "  batch 32 loss: [33.40814685821533, 0.07400194182991982]\n",
      "  batch 34 loss: [30.01828384399414, 0.20133477449417114]\n",
      "  batch 36 loss: [33.98990726470947, 0.18676680885255337]\n",
      "  batch 38 loss: [33.07513999938965, 0.21904979646205902]\n",
      "  batch 40 loss: [31.18077850341797, 0.2634543478488922]\n",
      "  batch 42 loss: [33.86051559448242, 0.07937469892203808]\n",
      "  batch 44 loss: [29.96427631378174, 0.045931629836559296]\n",
      "  batch 46 loss: [30.00539779663086, 0.12123550474643707]\n",
      "  batch 48 loss: [29.617432594299316, 0.12004942819476128]\n",
      "  batch 50 loss: [33.47812843322754, 0.027574345469474792]\n",
      "  batch 52 loss: [33.08802509307861, 0.05719892866909504]\n",
      "  batch 54 loss: [33.51492500305176, 0.04940508585423231]\n",
      "LOSS generator 33.51492500305176 discriminator 0.04940508585423231\n",
      "EPOCH 140:\n",
      "  batch 0 loss: [42.00012969970703, 0.032920680940151215]\n",
      "  batch 2 loss: [30.06482982635498, 0.044605997391045094]\n",
      "  batch 4 loss: [33.47154712677002, 0.10191966220736504]\n",
      "  batch 6 loss: [29.040337562561035, 0.08654312789440155]\n",
      "  batch 8 loss: [33.69317054748535, 0.9651764333248138]\n",
      "  batch 10 loss: [41.96417999267578, 1.5488719940185547]\n",
      "  batch 12 loss: [37.01016616821289, 1.334644079208374]\n",
      "  batch 14 loss: [37.819461822509766, 0.9885574281215668]\n",
      "  batch 16 loss: [35.62600040435791, 0.768098920583725]\n",
      "  batch 18 loss: [37.52972412109375, 0.7572484612464905]\n",
      "  batch 20 loss: [30.942750930786133, 0.7054088711738586]\n",
      "  batch 22 loss: [37.72731018066406, 0.7991894483566284]\n",
      "  batch 24 loss: [33.830848693847656, 0.8015622198581696]\n",
      "  batch 26 loss: [29.845229148864746, 0.5531272292137146]\n",
      "  batch 28 loss: [29.341200828552246, 0.24343178421258926]\n",
      "  batch 30 loss: [32.94591522216797, 0.17403510212898254]\n",
      "  batch 32 loss: [33.06291961669922, 0.20865383371710777]\n",
      "  batch 34 loss: [29.927794456481934, 0.10803333669900894]\n",
      "  batch 36 loss: [35.20991134643555, 0.359343558549881]\n",
      "  batch 38 loss: [32.53209209442139, 0.04243263229727745]\n",
      "  batch 40 loss: [26.312506675720215, 0.0761848222464323]\n",
      "  batch 42 loss: [36.99127769470215, 0.13986628875136375]\n",
      "  batch 44 loss: [27.883252143859863, 0.0811737161129713]\n",
      "  batch 46 loss: [34.68054008483887, 0.09663556516170502]\n",
      "  batch 48 loss: [35.821754455566406, 0.03924092464148998]\n",
      "  batch 50 loss: [32.161091804504395, 0.1879700142890215]\n",
      "  batch 52 loss: [29.018610954284668, 0.050436899065971375]\n",
      "  batch 54 loss: [32.60972595214844, 0.7489429097622633]\n",
      "LOSS generator 32.60972595214844 discriminator 0.7489429097622633\n",
      "EPOCH 141:\n",
      "  batch 0 loss: [32.322608947753906, 1.296737790107727]\n",
      "  batch 2 loss: [35.5325403213501, 0.6297683715820312]\n",
      "  batch 4 loss: [39.061004638671875, 0.7213649153709412]\n",
      "  batch 6 loss: [34.559309005737305, 0.5466149151325226]\n",
      "  batch 8 loss: [34.96156311035156, 0.6600196659564972]\n",
      "  batch 10 loss: [30.35906219482422, 0.5083622932434082]\n",
      "  batch 12 loss: [35.46695137023926, 0.5957405269145966]\n",
      "  batch 14 loss: [29.635751724243164, 0.4950651526451111]\n",
      "  batch 16 loss: [35.34945869445801, 0.49491462111473083]\n",
      "  batch 18 loss: [36.28178882598877, 0.6319145262241364]\n",
      "  batch 20 loss: [39.97205924987793, 0.24122828990221024]\n",
      "  batch 22 loss: [37.84916114807129, 0.7575385570526123]\n",
      "  batch 24 loss: [39.99492073059082, 0.4240666478872299]\n",
      "  batch 26 loss: [45.93790626525879, 0.8082112371921539]\n",
      "  batch 28 loss: [36.64509391784668, 0.6156038343906403]\n",
      "  batch 30 loss: [28.90864372253418, 0.39996080100536346]\n",
      "  batch 32 loss: [31.387073516845703, 0.32017065584659576]\n",
      "  batch 34 loss: [37.41062355041504, 0.3404734209179878]\n",
      "  batch 36 loss: [36.0967903137207, 0.3114117830991745]\n",
      "  batch 38 loss: [30.78902244567871, 0.15889793634414673]\n",
      "  batch 40 loss: [35.10008144378662, 0.3052959069609642]\n",
      "  batch 42 loss: [31.460941314697266, 0.1372167393565178]\n",
      "  batch 44 loss: [33.31104373931885, 0.09675974398851395]\n",
      "  batch 46 loss: [34.469133377075195, 0.14112448319792747]\n",
      "  batch 48 loss: [33.89010238647461, 0.26228567957878113]\n",
      "  batch 50 loss: [33.96776103973389, 0.31001944839954376]\n",
      "  batch 52 loss: [24.80395793914795, 0.3381515145301819]\n",
      "  batch 54 loss: [27.222086906433105, 0.1256333813071251]\n",
      "LOSS generator 27.222086906433105 discriminator 0.1256333813071251\n",
      "EPOCH 142:\n",
      "  batch 0 loss: [32.18214416503906, 0.2278706580400467]\n",
      "  batch 2 loss: [29.84002113342285, 0.1190500557422638]\n",
      "  batch 4 loss: [37.24251365661621, 0.14964449405670166]\n",
      "  batch 6 loss: [34.72115135192871, 0.10957200080156326]\n",
      "  batch 8 loss: [29.194008827209473, 0.04131883475929499]\n",
      "  batch 10 loss: [32.44316482543945, 0.10608512535691261]\n",
      "  batch 12 loss: [29.88182830810547, 0.058526381850242615]\n",
      "  batch 14 loss: [28.95820426940918, 0.06996006518602371]\n",
      "  batch 16 loss: [33.480512619018555, 0.06560079008340836]\n",
      "  batch 18 loss: [31.102476119995117, 0.13878007978200912]\n",
      "  batch 20 loss: [27.122407913208008, 0.12324651703238487]\n",
      "  batch 22 loss: [28.783113479614258, 0.05185282416641712]\n",
      "  batch 24 loss: [31.861339569091797, 0.062316929921507835]\n",
      "  batch 26 loss: [29.049434661865234, 0.05062239430844784]\n",
      "  batch 28 loss: [42.49447059631348, 0.05096250679343939]\n",
      "  batch 30 loss: [29.221074104309082, 0.09198714792728424]\n",
      "  batch 32 loss: [29.776556968688965, 0.22506517358124256]\n",
      "  batch 34 loss: [37.20283508300781, 0.08408741280436516]\n",
      "  batch 36 loss: [35.82038688659668, 0.041523223742842674]\n",
      "  batch 38 loss: [30.941325187683105, 0.0646518561989069]\n",
      "  batch 40 loss: [40.27909469604492, 0.15270688757300377]\n",
      "  batch 42 loss: [27.390649795532227, 0.09380440413951874]\n",
      "  batch 44 loss: [34.75120544433594, 0.10958308726549149]\n",
      "  batch 46 loss: [28.058476448059082, 0.19921798259019852]\n",
      "  batch 48 loss: [29.364994049072266, 0.19832082837820053]\n",
      "  batch 50 loss: [38.331674575805664, 0.1725998129695654]\n",
      "  batch 52 loss: [33.827866554260254, 0.18228156119585037]\n",
      "  batch 54 loss: [35.28743934631348, 0.06082645244896412]\n",
      "LOSS generator 35.28743934631348 discriminator 0.06082645244896412\n",
      "EPOCH 143:\n",
      "  batch 0 loss: [32.16486358642578, 0.015092847868800163]\n",
      "  batch 2 loss: [28.521778106689453, 0.06262899562716484]\n",
      "  batch 4 loss: [31.93587303161621, 0.0759856179356575]\n",
      "  batch 6 loss: [36.21142768859863, 0.04706604965031147]\n",
      "  batch 8 loss: [30.04468536376953, 0.02781898807734251]\n",
      "  batch 10 loss: [32.87138366699219, 0.04981243144720793]\n",
      "  batch 12 loss: [30.41182041168213, 0.03342120163142681]\n",
      "  batch 14 loss: [33.28309631347656, 0.02666356787085533]\n",
      "  batch 16 loss: [28.83196449279785, 0.043153515085577965]\n",
      "  batch 18 loss: [31.38729763031006, 0.018720602616667747]\n",
      "  batch 20 loss: [34.48802375793457, 0.030233163386583328]\n",
      "  batch 22 loss: [33.48698043823242, 0.0965077169239521]\n",
      "  batch 24 loss: [34.64237117767334, 0.03670277073979378]\n",
      "  batch 26 loss: [34.39177703857422, 0.03653979394584894]\n",
      "  batch 28 loss: [25.842501640319824, 0.1915852539241314]\n",
      "  batch 30 loss: [38.58578109741211, 0.09909678250551224]\n",
      "  batch 32 loss: [37.72422790527344, 0.07468801736831665]\n",
      "  batch 34 loss: [34.57668685913086, 0.014938130974769592]\n",
      "  batch 36 loss: [27.49626350402832, 0.05866331234574318]\n",
      "  batch 38 loss: [32.98733329772949, 0.0548304058611393]\n",
      "  batch 40 loss: [32.49096488952637, 0.04259204585105181]\n",
      "  batch 42 loss: [34.45160484313965, 0.04577633831650019]\n",
      "  batch 44 loss: [34.67001819610596, 0.03867091704159975]\n",
      "  batch 46 loss: [32.421576499938965, 0.026353011839091778]\n",
      "  batch 48 loss: [26.63365936279297, 0.08847747184336185]\n",
      "  batch 50 loss: [30.83408260345459, 0.11327331513166428]\n",
      "  batch 52 loss: [41.44998550415039, 0.1907433643937111]\n",
      "  batch 54 loss: [35.97253608703613, 0.06489866971969604]\n",
      "LOSS generator 35.97253608703613 discriminator 0.06489866971969604\n",
      "EPOCH 144:\n",
      "  batch 0 loss: [29.249561309814453, 0.016163473948836327]\n",
      "  batch 2 loss: [30.469985961914062, 0.019160518422722816]\n",
      "  batch 4 loss: [37.10824775695801, 0.23010504245758057]\n",
      "  batch 6 loss: [30.19393539428711, 0.06944723427295685]\n",
      "  batch 8 loss: [34.799522399902344, 0.037255750969052315]\n",
      "  batch 10 loss: [36.52691078186035, 0.010908529162406921]\n",
      "  batch 12 loss: [34.367340087890625, 0.027634819969534874]\n",
      "  batch 14 loss: [31.16691017150879, 0.13374802097678185]\n",
      "  batch 16 loss: [33.237914085388184, 0.02219257690012455]\n",
      "  batch 18 loss: [32.0514497756958, 0.07018976286053658]\n",
      "  batch 20 loss: [31.945290565490723, 0.09171462804079056]\n",
      "  batch 22 loss: [31.834625244140625, 0.05624624900519848]\n",
      "  batch 24 loss: [31.77065944671631, 0.03405024670064449]\n",
      "  batch 26 loss: [33.93587303161621, 0.012038390850648284]\n",
      "  batch 28 loss: [31.38856315612793, 0.06823155470192432]\n",
      "  batch 30 loss: [26.74243927001953, 0.08338452130556107]\n",
      "  batch 32 loss: [31.39023208618164, 0.03409566357731819]\n",
      "  batch 34 loss: [32.83437728881836, 0.05825228616595268]\n",
      "  batch 36 loss: [35.764018058776855, 0.049788747914135456]\n",
      "  batch 38 loss: [37.61168670654297, 0.0325689846649766]\n",
      "  batch 40 loss: [39.80223846435547, 0.032991696149110794]\n",
      "  batch 42 loss: [33.044039726257324, 0.01688409736379981]\n",
      "  batch 44 loss: [29.63424301147461, 0.021704790648072958]\n",
      "  batch 46 loss: [38.136037826538086, 0.03131624311208725]\n",
      "  batch 48 loss: [25.58167552947998, 0.0401105061173439]\n",
      "  batch 50 loss: [35.528910636901855, 0.042094022035598755]\n",
      "  batch 52 loss: [29.01385498046875, 0.06146339327096939]\n",
      "  batch 54 loss: [29.629942893981934, 0.040485506877303123]\n",
      "LOSS generator 29.629942893981934 discriminator 0.040485506877303123\n",
      "EPOCH 145:\n",
      "  batch 0 loss: [28.14910125732422, 0.026368746533989906]\n",
      "  batch 2 loss: [37.67571258544922, 0.05309450440108776]\n",
      "  batch 4 loss: [36.74247932434082, 0.031974729150533676]\n",
      "  batch 6 loss: [33.73009490966797, 0.06769061088562012]\n",
      "  batch 8 loss: [34.8872127532959, 0.014612152241170406]\n",
      "  batch 10 loss: [32.128432273864746, 0.014411387033760548]\n",
      "  batch 12 loss: [29.02125072479248, 0.06031382828950882]\n",
      "  batch 14 loss: [28.19203281402588, 0.06079443451017141]\n",
      "  batch 16 loss: [31.14474582672119, 0.015119766816496849]\n",
      "  batch 18 loss: [36.2116756439209, 0.08269082382321358]\n",
      "  batch 20 loss: [27.006019592285156, 0.16975213214755058]\n",
      "  batch 22 loss: [33.25309944152832, 0.05086361616849899]\n",
      "  batch 24 loss: [35.53289222717285, 0.04343510139733553]\n",
      "  batch 26 loss: [30.7182674407959, 0.029582031071186066]\n",
      "  batch 28 loss: [28.027670860290527, 0.08469616994261742]\n",
      "  batch 30 loss: [34.849754333496094, 0.0318844486027956]\n",
      "  batch 32 loss: [34.535767555236816, 0.035070909187197685]\n",
      "  batch 34 loss: [30.02943229675293, 0.03068060614168644]\n",
      "  batch 36 loss: [31.897994995117188, 0.032110122963786125]\n",
      "  batch 38 loss: [37.154184341430664, 0.034759996458888054]\n",
      "  batch 40 loss: [29.647639274597168, 0.03183784242719412]\n",
      "  batch 42 loss: [31.65874481201172, 0.011415787506848574]\n",
      "  batch 44 loss: [31.988630294799805, 0.022606855258345604]\n",
      "  batch 46 loss: [37.74912643432617, 0.022189761511981487]\n",
      "  batch 48 loss: [33.08199119567871, 0.012508746702224016]\n",
      "  batch 50 loss: [37.665395736694336, 0.017978192307054996]\n",
      "  batch 52 loss: [36.540470123291016, 0.018542291596531868]\n",
      "  batch 54 loss: [37.71000099182129, 0.05476948618888855]\n",
      "LOSS generator 37.71000099182129 discriminator 0.05476948618888855\n",
      "EPOCH 146:\n",
      "  batch 0 loss: [40.72367858886719, 0.10667498409748077]\n",
      "  batch 2 loss: [32.742835998535156, 0.03678210359066725]\n",
      "  batch 4 loss: [34.00348472595215, 0.022721475921571255]\n",
      "  batch 6 loss: [35.081336975097656, 0.02848877850919962]\n",
      "  batch 8 loss: [29.873260498046875, 0.022897089831531048]\n",
      "  batch 10 loss: [32.36533546447754, 0.014385870192199945]\n",
      "  batch 12 loss: [34.76275634765625, 0.00852833571843803]\n",
      "  batch 14 loss: [31.56411075592041, 0.014130317606031895]\n",
      "  batch 16 loss: [35.048458099365234, 0.030070053413510323]\n",
      "  batch 18 loss: [34.448225021362305, 0.05051032081246376]\n",
      "  batch 20 loss: [30.382527351379395, 0.027299383655190468]\n",
      "  batch 22 loss: [30.501559257507324, 0.08500956650823355]\n",
      "  batch 24 loss: [31.88721466064453, 0.14591187983751297]\n",
      "  batch 26 loss: [32.61254119873047, 0.07323729246854782]\n",
      "  batch 28 loss: [29.63429832458496, 0.051209503784775734]\n",
      "  batch 30 loss: [30.16314697265625, 0.05757487565279007]\n",
      "  batch 32 loss: [28.093077659606934, 0.038011182099580765]\n",
      "  batch 34 loss: [40.231754302978516, 0.04247058508917689]\n",
      "  batch 36 loss: [34.52990531921387, 0.009303649887442589]\n",
      "  batch 38 loss: [37.77097129821777, 0.024633592925965786]\n",
      "  batch 40 loss: [32.537535667419434, 0.058614758774638176]\n",
      "  batch 42 loss: [34.327314376831055, 0.02073701936751604]\n",
      "  batch 44 loss: [31.851442337036133, 0.06631756946444511]\n",
      "  batch 46 loss: [30.68434715270996, 0.03386123664677143]\n",
      "  batch 48 loss: [39.03396415710449, 0.024727854877710342]\n",
      "  batch 50 loss: [37.27435874938965, 0.012476996053010225]\n",
      "  batch 52 loss: [29.615983963012695, 0.023213724605739117]\n",
      "  batch 54 loss: [31.84921646118164, 0.038243926130235195]\n",
      "LOSS generator 31.84921646118164 discriminator 0.038243926130235195\n",
      "EPOCH 147:\n",
      "  batch 0 loss: [25.84322738647461, 0.021519504487514496]\n",
      "  batch 2 loss: [31.157516479492188, 0.03360510803759098]\n",
      "  batch 4 loss: [25.619888305664062, 0.1310253106057644]\n",
      "  batch 6 loss: [37.01841163635254, 0.02790466556325555]\n",
      "  batch 8 loss: [33.01963424682617, 0.023542216047644615]\n",
      "  batch 10 loss: [32.2408561706543, 0.014427025336772203]\n",
      "  batch 12 loss: [37.007253646850586, 0.010274661472067237]\n",
      "  batch 14 loss: [35.90631103515625, 0.020388631150126457]\n",
      "  batch 16 loss: [38.058536529541016, 0.01864217920228839]\n",
      "  batch 18 loss: [30.56300163269043, 0.02724437415599823]\n",
      "  batch 20 loss: [33.75675392150879, 0.03345336252823472]\n",
      "  batch 22 loss: [27.438871383666992, 0.018561342731118202]\n",
      "  batch 24 loss: [30.275047302246094, 0.027333722449839115]\n",
      "  batch 26 loss: [43.960365295410156, 0.06574165262281895]\n",
      "  batch 28 loss: [26.34907627105713, 0.03097340278327465]\n",
      "  batch 30 loss: [30.221863746643066, 0.021862471476197243]\n",
      "  batch 32 loss: [36.65302658081055, 0.009034722112119198]\n",
      "  batch 34 loss: [37.51861572265625, 0.03697141166776419]\n",
      "  batch 36 loss: [35.07427501678467, 0.02113366173580289]\n",
      "  batch 38 loss: [35.300838470458984, 0.04633586760610342]\n",
      "  batch 40 loss: [35.62495994567871, 0.45619674026966095]\n",
      "  batch 42 loss: [31.7732515335083, 0.6584823131561279]\n",
      "  batch 44 loss: [26.416553497314453, 0.5221812725067139]\n",
      "  batch 46 loss: [28.775936126708984, 0.318586528301239]\n",
      "  batch 48 loss: [33.909446716308594, 0.27920007705688477]\n",
      "  batch 50 loss: [33.07248783111572, 0.22425279021263123]\n",
      "  batch 52 loss: [31.526179313659668, 0.04876421391963959]\n",
      "  batch 54 loss: [32.344804763793945, 0.07229811139404774]\n",
      "LOSS generator 32.344804763793945 discriminator 0.07229811139404774\n",
      "EPOCH 148:\n",
      "  batch 0 loss: [28.01223373413086, 0.10193701833486557]\n",
      "  batch 2 loss: [36.60185623168945, 0.06619183346629143]\n",
      "  batch 4 loss: [31.865293502807617, 0.0851052338257432]\n",
      "  batch 6 loss: [27.70755672454834, 0.07521161809563637]\n",
      "  batch 8 loss: [32.69574737548828, 0.04053022153675556]\n",
      "  batch 10 loss: [30.59014129638672, 0.11790145933628082]\n",
      "  batch 12 loss: [28.695268630981445, 0.043895699083805084]\n",
      "  batch 14 loss: [35.05539894104004, 0.07819974422454834]\n",
      "  batch 16 loss: [34.345032691955566, 0.040540145710110664]\n",
      "  batch 18 loss: [33.504451751708984, 0.032238567247986794]\n",
      "  batch 20 loss: [31.912384033203125, 0.034932540729641914]\n",
      "  batch 22 loss: [31.656150817871094, 0.06837988644838333]\n",
      "  batch 24 loss: [28.492828369140625, 0.05463890731334686]\n",
      "  batch 26 loss: [32.53837871551514, 0.04163699224591255]\n",
      "  batch 28 loss: [32.013373374938965, 0.1724744802340865]\n",
      "  batch 30 loss: [31.05039691925049, 0.0947149433195591]\n",
      "  batch 32 loss: [34.4173002243042, 0.062129903584718704]\n",
      "  batch 34 loss: [29.56192398071289, 0.03847908601164818]\n",
      "  batch 36 loss: [33.60229682922363, 0.013680719770491123]\n",
      "  batch 38 loss: [40.146318435668945, 0.15870502591133118]\n",
      "  batch 40 loss: [25.7655668258667, 0.20264078676700592]\n",
      "  batch 42 loss: [33.500661849975586, 0.08951196074485779]\n",
      "  batch 44 loss: [34.374691009521484, 0.036632899194955826]\n",
      "  batch 46 loss: [34.14640426635742, 0.057952070608735085]\n",
      "  batch 48 loss: [31.9983549118042, 0.017617900855839252]\n",
      "  batch 50 loss: [32.26289176940918, 0.03533563483506441]\n",
      "  batch 52 loss: [35.41095542907715, 0.037253838032484055]\n",
      "  batch 54 loss: [34.39762210845947, 0.031078879721462727]\n",
      "LOSS generator 34.39762210845947 discriminator 0.031078879721462727\n",
      "EPOCH 149:\n",
      "  batch 0 loss: [33.977752685546875, 0.04360060393810272]\n",
      "  batch 2 loss: [34.85748767852783, 0.03605892322957516]\n",
      "  batch 4 loss: [32.19259262084961, 0.025084584951400757]\n",
      "  batch 6 loss: [30.21196174621582, 0.03308454528450966]\n",
      "  batch 8 loss: [36.844411849975586, 0.06992529425770044]\n",
      "  batch 10 loss: [31.894886016845703, 0.11307887639850378]\n",
      "  batch 12 loss: [33.05877876281738, 0.041181543841958046]\n",
      "  batch 14 loss: [35.20376396179199, 0.04662802070379257]\n",
      "  batch 16 loss: [31.330437660217285, 0.038352400064468384]\n",
      "  batch 18 loss: [37.22359657287598, 0.047769805416464806]\n",
      "  batch 20 loss: [34.37513732910156, 0.009518366307020187]\n",
      "  batch 22 loss: [34.00455188751221, 0.025016779080033302]\n",
      "  batch 24 loss: [28.890539169311523, 0.021438374184072018]\n",
      "  batch 26 loss: [31.320311546325684, 0.04591053258627653]\n",
      "  batch 28 loss: [33.31637477874756, 0.024861282669007778]\n",
      "  batch 30 loss: [30.231903076171875, 0.027158456621691585]\n",
      "  batch 32 loss: [40.64967155456543, 0.0498022073879838]\n",
      "  batch 34 loss: [33.54086875915527, 0.033391740173101425]\n",
      "  batch 36 loss: [34.08972358703613, 0.02195661049336195]\n",
      "  batch 38 loss: [29.44185447692871, 0.04408891825005412]\n",
      "  batch 40 loss: [31.835930824279785, 0.027005119249224663]\n",
      "  batch 42 loss: [40.08220863342285, 0.05278003215789795]\n",
      "  batch 44 loss: [26.24626922607422, 0.13937809690833092]\n",
      "  batch 46 loss: [30.13597583770752, 0.04175186436623335]\n",
      "  batch 48 loss: [29.660792350769043, 0.050061309710145]\n",
      "  batch 50 loss: [34.298505783081055, 0.03248107200488448]\n",
      "  batch 52 loss: [34.54287528991699, 0.0270672794431448]\n",
      "  batch 54 loss: [33.91191864013672, 0.09582797437906265]\n",
      "LOSS generator 33.91191864013672 discriminator 0.09582797437906265\n",
      "EPOCH 150:\n",
      "  batch 0 loss: [29.757659912109375, 0.03660188987851143]\n",
      "  batch 2 loss: [37.360456466674805, 0.04533322900533676]\n",
      "  batch 4 loss: [35.21393966674805, 0.06031462550163269]\n",
      "  batch 6 loss: [36.10878562927246, 0.038946207612752914]\n",
      "  batch 8 loss: [33.31866264343262, 0.04976554960012436]\n",
      "  batch 10 loss: [28.22950553894043, 0.0745061282068491]\n",
      "  batch 12 loss: [32.82114219665527, 0.02143122348934412]\n",
      "  batch 14 loss: [36.82949447631836, 0.020709614036604762]\n",
      "  batch 16 loss: [37.02448081970215, 0.024555308744311333]\n",
      "  batch 18 loss: [34.657010078430176, 0.047239392064511776]\n",
      "  batch 20 loss: [29.445369720458984, 0.024350130930542946]\n",
      "  batch 22 loss: [37.60254096984863, 0.03628231259062886]\n",
      "  batch 24 loss: [30.285330772399902, 0.023163605481386185]\n",
      "  batch 26 loss: [34.194393157958984, 0.059320771135389805]\n",
      "  batch 28 loss: [25.827826499938965, 0.03649917244911194]\n",
      "  batch 30 loss: [31.426313400268555, 0.14099418371915817]\n",
      "  batch 32 loss: [30.12788677215576, 0.10370408743619919]\n",
      "  batch 34 loss: [31.73088836669922, 0.04574105888605118]\n",
      "  batch 36 loss: [36.489484786987305, 0.04460701905190945]\n",
      "  batch 38 loss: [36.41282272338867, 0.049829257652163506]\n",
      "  batch 40 loss: [32.28779983520508, 0.13659958075731993]\n",
      "  batch 42 loss: [34.51859664916992, 0.022563650272786617]\n",
      "  batch 44 loss: [37.160701751708984, 0.0059214807115495205]\n",
      "  batch 46 loss: [34.37506294250488, 0.015626165084540844]\n",
      "  batch 48 loss: [34.42424201965332, 0.013691623695194721]\n",
      "  batch 50 loss: [31.155985832214355, 0.062065476551651955]\n",
      "  batch 52 loss: [31.64663314819336, 0.014540853444486856]\n",
      "  batch 54 loss: [29.60079288482666, 0.022111201658844948]\n",
      "LOSS generator 29.60079288482666 discriminator 0.022111201658844948\n",
      "EPOCH 151:\n",
      "  batch 0 loss: [33.77116394042969, 0.02607082575559616]\n",
      "  batch 2 loss: [31.66584873199463, 0.018559820018708706]\n",
      "  batch 4 loss: [34.01709842681885, 0.031171252951025963]\n",
      "  batch 6 loss: [36.589927673339844, 0.013618126511573792]\n",
      "  batch 8 loss: [40.80280113220215, 0.007060367846861482]\n",
      "  batch 10 loss: [31.795186042785645, 0.02279511373490095]\n",
      "  batch 12 loss: [29.94296646118164, 0.013788828626275063]\n",
      "  batch 14 loss: [31.791240692138672, 0.026979501359164715]\n",
      "  batch 16 loss: [29.187253952026367, 0.12070976430550218]\n",
      "  batch 18 loss: [36.542951583862305, 0.03734197840094566]\n",
      "  batch 20 loss: [34.60382652282715, 0.025294616352766752]\n",
      "  batch 22 loss: [36.7769889831543, 0.09393735975027084]\n",
      "  batch 24 loss: [32.24920845031738, 0.1523210108280182]\n",
      "  batch 26 loss: [34.19680404663086, 0.028585546649992466]\n",
      "  batch 28 loss: [29.4378719329834, 0.2023835927248001]\n",
      "  batch 30 loss: [34.154019355773926, 0.09658553078770638]\n",
      "  batch 32 loss: [36.51239013671875, 0.037312098778784275]\n",
      "  batch 34 loss: [30.709153175354004, 0.20271192491054535]\n",
      "  batch 36 loss: [33.14680004119873, 0.0683501735329628]\n",
      "  batch 38 loss: [27.681918144226074, 0.08455546200275421]\n",
      "  batch 40 loss: [34.34348678588867, 0.02666256669908762]\n",
      "  batch 42 loss: [33.36608695983887, 0.07251167157664895]\n",
      "  batch 44 loss: [38.094247817993164, 0.06739434227347374]\n",
      "  batch 46 loss: [35.364925384521484, 0.05182534642517567]\n",
      "  batch 48 loss: [29.905024528503418, 0.04688029736280441]\n",
      "  batch 50 loss: [28.167478561401367, 0.07012801989912987]\n",
      "  batch 52 loss: [33.27408981323242, 0.01627185381948948]\n",
      "  batch 54 loss: [34.62198066711426, 0.010764067061245441]\n",
      "LOSS generator 34.62198066711426 discriminator 0.010764067061245441\n",
      "EPOCH 152:\n",
      "  batch 0 loss: [28.105772018432617, 0.016794856637716293]\n",
      "  batch 2 loss: [32.07615852355957, 0.032751839607954025]\n",
      "  batch 4 loss: [28.598742485046387, 0.01829714421182871]\n",
      "  batch 6 loss: [39.26974678039551, 0.07303649187088013]\n",
      "  batch 8 loss: [37.91292953491211, 0.05237837880849838]\n",
      "  batch 10 loss: [31.50044536590576, 0.017656068317592144]\n",
      "  batch 12 loss: [31.594772338867188, 0.011181801557540894]\n",
      "  batch 14 loss: [30.62396812438965, 0.02514227107167244]\n",
      "  batch 16 loss: [35.393564224243164, 0.058335576206445694]\n",
      "  batch 18 loss: [37.79981231689453, 0.015403625089675188]\n",
      "  batch 20 loss: [33.51060676574707, 0.030206491239368916]\n",
      "  batch 22 loss: [30.30968475341797, 0.04866437055170536]\n",
      "  batch 24 loss: [26.873228073120117, 0.03859059885144234]\n",
      "  batch 26 loss: [32.005242347717285, 0.013904334045946598]\n",
      "  batch 28 loss: [37.921945571899414, 0.016607075929641724]\n",
      "  batch 30 loss: [40.27778434753418, 0.05520397983491421]\n",
      "  batch 32 loss: [34.91900825500488, 0.014866732060909271]\n",
      "  batch 34 loss: [30.754416465759277, 0.04493799991905689]\n",
      "  batch 36 loss: [33.14372253417969, 0.011111350730061531]\n",
      "  batch 38 loss: [35.52041149139404, 0.03152243746444583]\n",
      "  batch 40 loss: [38.31241226196289, 0.0423898184671998]\n",
      "  batch 42 loss: [28.77585792541504, 0.04380161687731743]\n",
      "  batch 44 loss: [33.30914497375488, 0.11678267270326614]\n",
      "  batch 46 loss: [33.27081775665283, 0.03564584441483021]\n",
      "  batch 48 loss: [35.184722900390625, 0.022925652097910643]\n",
      "  batch 50 loss: [33.370893478393555, 0.03543221112340689]\n",
      "  batch 52 loss: [29.803092002868652, 0.10688349232077599]\n",
      "  batch 54 loss: [33.66554641723633, 0.031006751349195838]\n",
      "LOSS generator 33.66554641723633 discriminator 0.031006751349195838\n",
      "EPOCH 153:\n",
      "  batch 0 loss: [37.080631256103516, 0.025579821318387985]\n",
      "  batch 2 loss: [32.845139503479004, 0.05193649046123028]\n",
      "  batch 4 loss: [30.02492904663086, 0.024460088461637497]\n",
      "  batch 6 loss: [36.08573532104492, 0.0694415532052517]\n",
      "  batch 8 loss: [30.318127632141113, 0.029765773564577103]\n",
      "  batch 10 loss: [35.36611557006836, 0.09393780305981636]\n",
      "  batch 12 loss: [29.46686363220215, 0.08584227319806814]\n",
      "  batch 14 loss: [35.22813701629639, 0.02347936574369669]\n",
      "  batch 16 loss: [30.976335525512695, 0.08522946620360017]\n",
      "  batch 18 loss: [34.95174789428711, 0.3791869878768921]\n",
      "  batch 20 loss: [34.16515350341797, 0.5729365199804306]\n",
      "  batch 22 loss: [36.27770805358887, 0.5107748806476593]\n",
      "  batch 24 loss: [40.11946678161621, 0.5863451510667801]\n",
      "  batch 26 loss: [33.64427089691162, 0.32151392102241516]\n",
      "  batch 28 loss: [39.868873596191406, 0.5266421064734459]\n",
      "  batch 30 loss: [40.34157180786133, 0.652477353811264]\n",
      "  batch 32 loss: [41.561960220336914, 0.3523748517036438]\n",
      "  batch 34 loss: [36.909854888916016, 0.3679806739091873]\n",
      "  batch 36 loss: [37.74659538269043, 0.11821922287344933]\n",
      "  batch 38 loss: [44.54292869567871, 0.18452715128660202]\n",
      "  batch 40 loss: [38.24795150756836, 0.16327040642499924]\n",
      "  batch 42 loss: [39.75813293457031, 0.2393142431974411]\n",
      "  batch 44 loss: [30.886106491088867, 0.07471428997814655]\n",
      "  batch 46 loss: [28.824875831604004, 0.07267947122454643]\n",
      "  batch 48 loss: [31.203282356262207, 0.11550146713852882]\n",
      "  batch 50 loss: [32.61672592163086, 0.03882952593266964]\n",
      "  batch 52 loss: [32.96041774749756, 0.15151401609182358]\n",
      "  batch 54 loss: [34.10093688964844, 0.10551079362630844]\n",
      "LOSS generator 34.10093688964844 discriminator 0.10551079362630844\n",
      "EPOCH 154:\n",
      "  batch 0 loss: [30.555261611938477, 0.043261345475912094]\n",
      "  batch 2 loss: [30.57667827606201, 0.04328886978328228]\n",
      "  batch 4 loss: [34.62644672393799, 0.08299113065004349]\n",
      "  batch 6 loss: [31.181255340576172, 0.2121474901214242]\n",
      "  batch 8 loss: [33.52899932861328, 0.035304232966154814]\n",
      "  batch 10 loss: [34.22878837585449, 0.06597818341106176]\n",
      "  batch 12 loss: [37.87937545776367, 0.11114256642758846]\n",
      "  batch 14 loss: [29.899497032165527, 0.06596046313643456]\n",
      "  batch 16 loss: [38.244211196899414, 0.037191903218626976]\n",
      "  batch 18 loss: [28.761301040649414, 0.028383824974298477]\n",
      "  batch 20 loss: [34.86451721191406, 0.06047507515177131]\n",
      "  batch 22 loss: [34.0251350402832, 0.03583459556102753]\n",
      "  batch 24 loss: [30.96808624267578, 0.037531761452555656]\n",
      "  batch 26 loss: [31.598092079162598, 0.015205918345600367]\n",
      "  batch 28 loss: [34.15486431121826, 0.020881003700196743]\n",
      "  batch 30 loss: [33.5230655670166, 0.02148227859288454]\n",
      "  batch 32 loss: [26.219566345214844, 0.06073882803320885]\n",
      "  batch 34 loss: [40.0671443939209, 0.027525050565600395]\n",
      "  batch 36 loss: [36.69430160522461, 0.022170487325638533]\n",
      "  batch 38 loss: [31.631439208984375, 0.009211218915879726]\n",
      "  batch 40 loss: [41.14560127258301, 0.08065846562385559]\n",
      "  batch 42 loss: [35.64984130859375, 0.06771388277411461]\n",
      "  batch 44 loss: [36.42243194580078, 0.049226195085793734]\n",
      "  batch 46 loss: [34.55298042297363, 0.021262321155518293]\n",
      "  batch 48 loss: [30.05237865447998, 0.025750577449798584]\n",
      "  batch 50 loss: [26.53573513031006, 0.02865188755095005]\n",
      "  batch 52 loss: [27.950608253479004, 0.019101159647107124]\n",
      "  batch 54 loss: [32.29536437988281, 0.04259451851248741]\n",
      "LOSS generator 32.29536437988281 discriminator 0.04259451851248741\n",
      "EPOCH 155:\n",
      "  batch 0 loss: [24.732908248901367, 0.04211820662021637]\n",
      "  batch 2 loss: [35.15960121154785, 0.03563168551772833]\n",
      "  batch 4 loss: [31.515634536743164, 0.029445595107972622]\n",
      "  batch 6 loss: [29.609500885009766, 0.014187249820679426]\n",
      "  batch 8 loss: [31.916826248168945, 0.013565690722316504]\n",
      "  batch 10 loss: [34.37568187713623, 0.03253423701971769]\n",
      "  batch 12 loss: [36.940330505371094, 0.14836375042796135]\n",
      "  batch 14 loss: [39.2562255859375, 0.061705938540399075]\n",
      "  batch 16 loss: [31.086155891418457, 0.06843645125627518]\n",
      "  batch 18 loss: [33.01473331451416, 0.05473531223833561]\n",
      "  batch 20 loss: [37.31131458282471, 0.03224222920835018]\n",
      "  batch 22 loss: [32.935495376586914, 0.09057505801320076]\n",
      "  batch 24 loss: [27.55223560333252, 0.04321787878870964]\n",
      "  batch 26 loss: [32.23161792755127, 0.031402007676661015]\n",
      "  batch 28 loss: [26.233261108398438, 0.04854466300457716]\n",
      "  batch 30 loss: [37.15376853942871, 0.023800287395715714]\n",
      "  batch 32 loss: [36.51892280578613, 0.2427748367190361]\n",
      "  batch 34 loss: [31.59019947052002, 0.03856630437076092]\n",
      "  batch 36 loss: [35.83272743225098, 0.053073836490511894]\n",
      "  batch 38 loss: [26.807584762573242, 0.03705250658094883]\n",
      "  batch 40 loss: [37.70719909667969, 0.015355582814663649]\n",
      "  batch 42 loss: [29.877690315246582, 0.05216502398252487]\n",
      "  batch 44 loss: [32.69205951690674, 0.01216644374653697]\n",
      "  batch 46 loss: [36.540672302246094, 0.00950104370713234]\n",
      "  batch 48 loss: [29.760398864746094, 0.026035744696855545]\n",
      "  batch 50 loss: [39.5015754699707, 0.03635130636394024]\n",
      "  batch 52 loss: [30.664690017700195, 0.02909456193447113]\n",
      "  batch 54 loss: [35.85289764404297, 0.015471796039491892]\n",
      "LOSS generator 35.85289764404297 discriminator 0.015471796039491892\n",
      "EPOCH 156:\n",
      "  batch 0 loss: [27.49131202697754, 0.018019208684563637]\n",
      "  batch 2 loss: [32.76162242889404, 0.020933592692017555]\n",
      "  batch 4 loss: [29.782706260681152, 0.011429426958784461]\n",
      "  batch 6 loss: [35.92471694946289, 0.029117751866579056]\n",
      "  batch 8 loss: [34.86943435668945, 0.011525763664394617]\n",
      "  batch 10 loss: [33.17989921569824, 0.013465081807225943]\n",
      "  batch 12 loss: [34.80529594421387, 0.019126519095152617]\n",
      "  batch 14 loss: [30.204465866088867, 0.02647844236344099]\n",
      "  batch 16 loss: [35.48597717285156, 0.03182460181415081]\n",
      "  batch 18 loss: [36.91322708129883, 0.01388209406286478]\n",
      "  batch 20 loss: [32.12173652648926, 0.025723137892782688]\n",
      "  batch 22 loss: [33.03815937042236, 0.04617759399116039]\n",
      "  batch 24 loss: [36.01759719848633, 0.02743938099592924]\n",
      "  batch 26 loss: [33.9046630859375, 0.15710796043276787]\n",
      "  batch 28 loss: [33.065229415893555, 0.01789430808275938]\n",
      "  batch 30 loss: [39.77460479736328, 0.036842710338532925]\n",
      "  batch 32 loss: [37.87952423095703, 0.036479013971984386]\n",
      "  batch 34 loss: [35.66824531555176, 0.012447214219719172]\n",
      "  batch 36 loss: [35.30197334289551, 0.013922147918492556]\n",
      "  batch 38 loss: [31.351600646972656, 0.03317020274698734]\n",
      "  batch 40 loss: [38.02605438232422, 0.01357340905815363]\n",
      "  batch 42 loss: [31.44942569732666, 0.016710549592971802]\n",
      "  batch 44 loss: [28.64420795440674, 0.016184281557798386]\n",
      "  batch 46 loss: [30.164122581481934, 0.044724298641085625]\n",
      "  batch 48 loss: [33.93020725250244, 0.0108922099461779]\n",
      "  batch 50 loss: [33.155890464782715, 0.008973727468401194]\n",
      "  batch 52 loss: [39.63612365722656, 0.03347651148214936]\n",
      "  batch 54 loss: [31.045337677001953, 0.042912453413009644]\n",
      "LOSS generator 31.045337677001953 discriminator 0.042912453413009644\n",
      "EPOCH 157:\n",
      "  batch 0 loss: [37.36515426635742, 0.03514789044857025]\n",
      "  batch 2 loss: [36.45261001586914, 0.03267461061477661]\n",
      "  batch 4 loss: [41.442604064941406, 0.020249188877642155]\n",
      "  batch 6 loss: [32.710968017578125, 0.029368558898568153]\n",
      "  batch 8 loss: [32.98555946350098, 0.08029484003782272]\n",
      "  batch 10 loss: [41.96144676208496, 0.041908091865479946]\n",
      "  batch 12 loss: [36.60297679901123, 0.043957619927823544]\n",
      "  batch 14 loss: [36.12611961364746, 0.013401011936366558]\n",
      "  batch 16 loss: [31.81178379058838, 0.052043721079826355]\n",
      "  batch 18 loss: [29.773499488830566, 0.015259401872754097]\n",
      "  batch 20 loss: [35.12736892700195, 0.04639236256480217]\n",
      "  batch 22 loss: [32.98050498962402, 0.052221594378352165]\n",
      "  batch 24 loss: [35.16684150695801, 0.016242964193224907]\n",
      "  batch 26 loss: [25.284099578857422, 0.22976074367761612]\n",
      "  batch 28 loss: [35.25798416137695, 0.12573346495628357]\n",
      "  batch 30 loss: [30.694652557373047, 0.16952010989189148]\n",
      "  batch 32 loss: [30.446524620056152, 0.13610868528485298]\n",
      "  batch 34 loss: [30.476365089416504, 0.10816456004977226]\n",
      "  batch 36 loss: [26.94474220275879, 0.06610614154487848]\n",
      "  batch 38 loss: [30.798297882080078, 0.009304215898737311]\n",
      "  batch 40 loss: [33.976518630981445, 0.04455200396478176]\n",
      "  batch 42 loss: [31.83726215362549, 0.02809504931792617]\n",
      "  batch 44 loss: [33.6171932220459, 0.02845963090658188]\n",
      "  batch 46 loss: [34.288554191589355, 0.036945453844964504]\n",
      "  batch 48 loss: [41.233924865722656, 0.026638253591954708]\n",
      "  batch 50 loss: [29.25192356109619, 0.023273451253771782]\n",
      "  batch 52 loss: [32.348347663879395, 0.03093742486089468]\n",
      "  batch 54 loss: [24.565529823303223, 0.13590474426746368]\n",
      "LOSS generator 24.565529823303223 discriminator 0.13590474426746368\n",
      "EPOCH 158:\n",
      "  batch 0 loss: [29.619543075561523, 0.014169923029839993]\n",
      "  batch 2 loss: [33.392717361450195, 0.012734773568809032]\n",
      "  batch 4 loss: [34.52479648590088, 0.03916124626994133]\n",
      "  batch 6 loss: [27.83060073852539, 0.107734190300107]\n",
      "  batch 8 loss: [40.129207611083984, 0.037076384760439396]\n",
      "  batch 10 loss: [34.55368614196777, 0.04279684764333069]\n",
      "  batch 12 loss: [32.21661376953125, 0.043146003037691116]\n",
      "  batch 14 loss: [36.0289306640625, 0.02443474717438221]\n",
      "  batch 16 loss: [34.650400161743164, 0.032626074738800526]\n",
      "  batch 18 loss: [33.26928520202637, 0.05033850111067295]\n",
      "  batch 20 loss: [41.85643196105957, 0.032807608135044575]\n",
      "  batch 22 loss: [32.627750396728516, 0.022866779239848256]\n",
      "  batch 24 loss: [30.5260009765625, 0.030707616358995438]\n",
      "  batch 26 loss: [31.589452743530273, 0.043470349162817]\n",
      "  batch 28 loss: [35.41659164428711, 0.04126212652772665]\n",
      "  batch 30 loss: [33.77421760559082, 0.01317497412674129]\n",
      "  batch 32 loss: [37.11937236785889, 0.03615339193493128]\n",
      "  batch 34 loss: [30.750405311584473, 0.05163460969924927]\n",
      "  batch 36 loss: [32.08529281616211, 0.046209901571273804]\n",
      "  batch 38 loss: [32.53086853027344, 0.026508266106247902]\n",
      "  batch 40 loss: [27.89043140411377, 0.024636919610202312]\n",
      "  batch 42 loss: [31.069019317626953, 0.02581130713224411]\n",
      "  batch 44 loss: [36.19333267211914, 0.04244604706764221]\n",
      "  batch 46 loss: [32.736971855163574, 0.008093419368378818]\n",
      "  batch 48 loss: [38.91459655761719, 0.04130532220005989]\n",
      "  batch 50 loss: [33.948402404785156, 0.01005203602835536]\n",
      "  batch 52 loss: [28.24575710296631, 0.061518143862485886]\n",
      "  batch 54 loss: [29.278687477111816, 0.052977005019783974]\n",
      "LOSS generator 29.278687477111816 discriminator 0.052977005019783974\n",
      "EPOCH 159:\n",
      "  batch 0 loss: [37.04594802856445, 0.02995310351252556]\n",
      "  batch 2 loss: [34.59164333343506, 0.025591189041733742]\n",
      "  batch 4 loss: [35.19350051879883, 0.013489946024492383]\n",
      "  batch 6 loss: [35.644240379333496, 0.01074231369420886]\n",
      "  batch 8 loss: [30.746496200561523, 0.030783310532569885]\n",
      "  batch 10 loss: [34.87888717651367, 0.042200030758976936]\n",
      "  batch 12 loss: [32.37977313995361, 0.07383724953979254]\n",
      "  batch 14 loss: [25.954944610595703, 0.02193240262567997]\n",
      "  batch 16 loss: [40.9260196685791, 0.02962284255772829]\n",
      "  batch 18 loss: [32.52522850036621, 0.07510607689619064]\n",
      "  batch 20 loss: [30.206174850463867, 0.017750557512044907]\n",
      "  batch 22 loss: [34.39434242248535, 0.011670258827507496]\n",
      "  batch 24 loss: [30.002877235412598, 0.010272706858813763]\n",
      "  batch 26 loss: [38.89285469055176, 0.04199084546416998]\n",
      "  batch 28 loss: [30.50399875640869, 0.05787596479058266]\n",
      "  batch 30 loss: [33.86384391784668, 0.04049511440098286]\n",
      "  batch 32 loss: [31.932865142822266, 0.022220622282475233]\n",
      "  batch 34 loss: [28.435461044311523, 0.02448979439213872]\n",
      "  batch 36 loss: [36.15728187561035, 0.00562597019597888]\n",
      "  batch 38 loss: [28.648401260375977, 0.017169572412967682]\n",
      "  batch 40 loss: [30.983253479003906, 0.033917369320988655]\n",
      "  batch 42 loss: [35.22721862792969, 0.037592790089547634]\n",
      "  batch 44 loss: [39.453989028930664, 0.030314579606056213]\n",
      "  batch 46 loss: [39.028682708740234, 0.009111219551414251]\n",
      "  batch 48 loss: [36.85761070251465, 0.013253683689981699]\n",
      "  batch 50 loss: [35.80449676513672, 0.02477352973073721]\n",
      "  batch 52 loss: [33.61844825744629, 0.010023876093327999]\n",
      "  batch 54 loss: [30.931276321411133, 0.07296626269817352]\n",
      "LOSS generator 30.931276321411133 discriminator 0.07296626269817352\n",
      "EPOCH 160:\n",
      "  batch 0 loss: [23.21692657470703, 0.07252053916454315]\n",
      "  batch 2 loss: [29.297566413879395, 0.03943931311368942]\n",
      "  batch 4 loss: [38.21325492858887, 0.05846845358610153]\n",
      "  batch 6 loss: [36.39780807495117, 0.042959848418831825]\n",
      "  batch 8 loss: [36.55291938781738, 0.02161729522049427]\n",
      "  batch 10 loss: [32.98978900909424, 0.023564444854855537]\n",
      "  batch 12 loss: [33.04831790924072, 0.013385334983468056]\n",
      "  batch 14 loss: [33.60119342803955, 0.028635242953896523]\n",
      "  batch 16 loss: [31.379481315612793, 0.012613689294084907]\n",
      "  batch 18 loss: [31.90068531036377, 0.013677943497896194]\n",
      "  batch 20 loss: [37.42057800292969, 0.03503016056492925]\n",
      "  batch 22 loss: [32.17488193511963, 0.03260063659399748]\n",
      "  batch 24 loss: [33.35304641723633, 0.01822811458259821]\n",
      "  batch 26 loss: [28.239904403686523, 0.06403547804802656]\n",
      "  batch 28 loss: [39.26003456115723, 0.10273600369691849]\n",
      "  batch 30 loss: [30.00154685974121, 0.10249314829707146]\n",
      "  batch 32 loss: [37.15719223022461, 0.04875782411545515]\n",
      "  batch 34 loss: [30.045734405517578, 0.03025957942008972]\n",
      "  batch 36 loss: [40.51887321472168, 0.07104416191577911]\n",
      "  batch 38 loss: [30.64070701599121, 0.022482915315777063]\n",
      "  batch 40 loss: [32.15886974334717, 0.011028888635337353]\n",
      "  batch 42 loss: [33.820247650146484, 0.01256835414096713]\n",
      "  batch 44 loss: [36.24943828582764, 0.2012202888727188]\n",
      "  batch 46 loss: [33.323163986206055, 0.10627007856965065]\n",
      "  batch 48 loss: [34.888590812683105, 0.1445813849568367]\n",
      "  batch 50 loss: [31.54909038543701, 0.0500789862126112]\n",
      "  batch 52 loss: [33.33575630187988, 0.012171822600066662]\n",
      "  batch 54 loss: [31.466480255126953, 0.03369371499866247]\n",
      "LOSS generator 31.466480255126953 discriminator 0.03369371499866247\n",
      "EPOCH 161:\n",
      "  batch 0 loss: [36.7011833190918, 0.007087952457368374]\n",
      "  batch 2 loss: [36.19506645202637, 0.06628129631280899]\n",
      "  batch 4 loss: [35.449073791503906, 0.02089689951390028]\n",
      "  batch 6 loss: [29.577795028686523, 0.014146980363875628]\n",
      "  batch 8 loss: [31.759410858154297, 0.010402601561509073]\n",
      "  batch 10 loss: [31.722177505493164, 0.052444785833358765]\n",
      "  batch 12 loss: [38.4434700012207, 0.0456617996096611]\n",
      "  batch 14 loss: [33.76939010620117, 0.019037164747714996]\n",
      "  batch 16 loss: [33.819915771484375, 0.00939938798546791]\n",
      "  batch 18 loss: [36.75333786010742, 0.01131065096706152]\n",
      "  batch 20 loss: [30.505332946777344, 0.030673394910991192]\n",
      "  batch 22 loss: [33.1120719909668, 0.02671765722334385]\n",
      "  batch 24 loss: [27.775083541870117, 0.021749633364379406]\n",
      "  batch 26 loss: [35.059515953063965, 0.012964771594852209]\n",
      "  batch 28 loss: [34.40226745605469, 0.016482233768329024]\n",
      "  batch 30 loss: [34.49632167816162, 0.01640098262578249]\n",
      "  batch 32 loss: [34.93007183074951, 0.048162274062633514]\n",
      "  batch 34 loss: [35.25954246520996, 0.018738859333097935]\n",
      "  batch 36 loss: [35.766408920288086, 0.037666480988264084]\n",
      "  batch 38 loss: [29.973508834838867, 0.013198038097470999]\n",
      "  batch 40 loss: [38.96344757080078, 0.018535046838223934]\n",
      "  batch 42 loss: [31.6469087600708, 0.006221588351763785]\n",
      "  batch 44 loss: [30.326778411865234, 0.015432822983711958]\n",
      "  batch 46 loss: [39.02088165283203, 0.012591529171913862]\n",
      "  batch 48 loss: [36.08978843688965, 0.006183141842484474]\n",
      "  batch 50 loss: [33.63526153564453, 0.13757577538490295]\n",
      "  batch 52 loss: [37.59648323059082, 0.010331196710467339]\n",
      "  batch 54 loss: [34.51035690307617, 0.014890172285959125]\n",
      "LOSS generator 34.51035690307617 discriminator 0.014890172285959125\n",
      "EPOCH 162:\n",
      "  batch 0 loss: [38.957393646240234, 0.0020180162973701954]\n",
      "  batch 2 loss: [31.81709098815918, 0.00568263279274106]\n",
      "  batch 4 loss: [37.25029182434082, 0.011779491323977709]\n",
      "  batch 6 loss: [33.13433361053467, 0.028216137550771236]\n",
      "  batch 8 loss: [36.1412239074707, 0.04049505339935422]\n",
      "  batch 10 loss: [34.71758842468262, 0.07758869975805283]\n",
      "  batch 12 loss: [28.906082153320312, 0.09536969661712646]\n",
      "  batch 14 loss: [33.816280364990234, 0.026474114507436752]\n",
      "  batch 16 loss: [35.494319915771484, 0.10082734376192093]\n",
      "  batch 18 loss: [36.14130401611328, 0.0437507564201951]\n",
      "  batch 20 loss: [31.94355869293213, 0.030017724260687828]\n",
      "  batch 22 loss: [29.81065082550049, 0.21609927713871002]\n",
      "  batch 24 loss: [36.3808650970459, 0.1270995233207941]\n",
      "  batch 26 loss: [31.996970176696777, 0.36830825358629227]\n",
      "  batch 28 loss: [30.706902503967285, 0.17506947182118893]\n",
      "  batch 30 loss: [37.54957580566406, 0.1291189007461071]\n",
      "  batch 32 loss: [33.168373107910156, 0.15858090575784445]\n",
      "  batch 34 loss: [31.038497924804688, 0.06297352537512779]\n",
      "  batch 36 loss: [31.988237380981445, 0.06485412735491991]\n",
      "  batch 38 loss: [33.464447021484375, 0.02699466422200203]\n",
      "  batch 40 loss: [36.65852165222168, 0.05184907279908657]\n",
      "  batch 42 loss: [36.48190689086914, 0.06654426269233227]\n",
      "  batch 44 loss: [33.26059818267822, 0.011543831089511514]\n",
      "  batch 46 loss: [37.133920669555664, 0.04912305809557438]\n",
      "  batch 48 loss: [31.273847579956055, 0.03516343608498573]\n",
      "  batch 50 loss: [26.102739334106445, 0.16838354617357254]\n",
      "  batch 52 loss: [34.55836582183838, 0.08129865489900112]\n",
      "  batch 54 loss: [34.16213607788086, 0.04877534881234169]\n",
      "LOSS generator 34.16213607788086 discriminator 0.04877534881234169\n",
      "EPOCH 163:\n",
      "  batch 0 loss: [35.55099868774414, 0.0678204894065857]\n",
      "  batch 2 loss: [29.421624183654785, 0.06447730213403702]\n",
      "  batch 4 loss: [31.943184852600098, 0.03496244363486767]\n",
      "  batch 6 loss: [33.10824203491211, 0.04928590729832649]\n",
      "  batch 8 loss: [31.893847465515137, 0.02990521676838398]\n",
      "  batch 10 loss: [36.273284912109375, 0.025690880604088306]\n",
      "  batch 12 loss: [32.44408988952637, 0.028608085587620735]\n",
      "  batch 14 loss: [29.547801971435547, 0.05694370158016682]\n",
      "  batch 16 loss: [29.45692539215088, 0.019997425377368927]\n",
      "  batch 18 loss: [30.2177677154541, 0.012668357696384192]\n",
      "  batch 20 loss: [37.21400833129883, 0.03638464747928083]\n",
      "  batch 22 loss: [28.78055763244629, 0.04745601862668991]\n",
      "  batch 24 loss: [32.309213638305664, 0.041988350450992584]\n",
      "  batch 26 loss: [42.39701461791992, 0.09889697842299938]\n",
      "  batch 28 loss: [34.00095558166504, 0.09122527483850718]\n",
      "  batch 30 loss: [29.354673385620117, 0.19637392461299896]\n",
      "  batch 32 loss: [36.648338317871094, 0.019036716781556606]\n",
      "  batch 34 loss: [30.76614761352539, 0.01742815738543868]\n",
      "  batch 36 loss: [40.14399719238281, 0.03820087015628815]\n",
      "  batch 38 loss: [32.510050773620605, 0.025616643019020557]\n",
      "  batch 40 loss: [30.422962188720703, 0.025431813206523657]\n",
      "  batch 42 loss: [30.746621131896973, 0.02878275141119957]\n",
      "  batch 44 loss: [39.31063270568848, 0.02770242583937943]\n",
      "  batch 46 loss: [30.771711349487305, 0.02863061986863613]\n",
      "  batch 48 loss: [35.13733100891113, 0.018303672317415476]\n",
      "  batch 50 loss: [39.31954383850098, 0.03802528232336044]\n",
      "  batch 52 loss: [31.435725212097168, 0.02070941962301731]\n",
      "  batch 54 loss: [33.91475486755371, 0.020470793824642897]\n",
      "LOSS generator 33.91475486755371 discriminator 0.020470793824642897\n",
      "EPOCH 164:\n",
      "  batch 0 loss: [27.776647567749023, 0.050494514405727386]\n",
      "  batch 2 loss: [37.648643493652344, 0.015718808863312006]\n",
      "  batch 4 loss: [32.96011734008789, 0.006010757759213448]\n",
      "  batch 6 loss: [30.469709396362305, 0.014004795346409082]\n",
      "  batch 8 loss: [31.82244873046875, 0.014654969796538353]\n",
      "  batch 10 loss: [35.3974609375, 0.005958724766969681]\n",
      "  batch 12 loss: [36.17340660095215, 0.03869357891380787]\n",
      "  batch 14 loss: [38.469648361206055, 0.023593824356794357]\n",
      "  batch 16 loss: [29.55335521697998, 0.12278036028146744]\n",
      "  batch 18 loss: [37.550621032714844, 0.033940842375159264]\n",
      "  batch 20 loss: [37.53493309020996, 0.013170183170586824]\n",
      "  batch 22 loss: [37.04034423828125, 0.011627040803432465]\n",
      "  batch 24 loss: [39.52500534057617, 0.03249791357666254]\n",
      "  batch 26 loss: [36.8934383392334, 0.011745175812393427]\n",
      "  batch 28 loss: [36.387184143066406, 0.015021477825939655]\n",
      "  batch 30 loss: [35.73007869720459, 0.010105269961059093]\n",
      "  batch 32 loss: [36.49334144592285, 0.005816710996441543]\n",
      "  batch 34 loss: [29.94983196258545, 0.02339746244251728]\n",
      "  batch 36 loss: [28.04851722717285, 0.040385933592915535]\n",
      "  batch 38 loss: [36.20011329650879, 0.028283752501010895]\n",
      "  batch 40 loss: [31.133079528808594, 0.01237645954824984]\n",
      "  batch 42 loss: [33.18356227874756, 0.01614849455654621]\n",
      "  batch 44 loss: [28.456851959228516, 0.02277726912871003]\n",
      "  batch 46 loss: [30.394960403442383, 0.009155960753560066]\n",
      "  batch 48 loss: [31.21039867401123, 0.01368754799477756]\n",
      "  batch 50 loss: [39.85731506347656, 0.04453857394400984]\n",
      "  batch 52 loss: [32.16964626312256, 0.014790695626288652]\n",
      "  batch 54 loss: [34.45051956176758, 0.01735827326774597]\n",
      "LOSS generator 34.45051956176758 discriminator 0.01735827326774597\n",
      "EPOCH 165:\n",
      "  batch 0 loss: [30.296689987182617, 0.020168330520391464]\n",
      "  batch 2 loss: [36.063979148864746, 0.06566681899130344]\n",
      "  batch 4 loss: [31.842479705810547, 0.0224154032766819]\n",
      "  batch 6 loss: [33.57590866088867, 0.013599804136902094]\n",
      "  batch 8 loss: [32.34766101837158, 0.006630764110013843]\n",
      "  batch 10 loss: [33.223106384277344, 0.01161807682365179]\n",
      "  batch 12 loss: [36.64092254638672, 0.01719203102402389]\n",
      "  batch 14 loss: [31.351733207702637, 0.01218574121594429]\n",
      "  batch 16 loss: [40.324575424194336, 0.022025348851457238]\n",
      "  batch 18 loss: [39.8979606628418, 0.08575859293341637]\n",
      "  batch 20 loss: [35.18861389160156, 0.015136010246351361]\n",
      "  batch 22 loss: [34.75164985656738, 0.08777360338717699]\n",
      "  batch 24 loss: [29.085208892822266, 0.08881843090057373]\n",
      "  batch 26 loss: [35.0880184173584, 0.013239593710750341]\n",
      "  batch 28 loss: [31.37606430053711, 0.01418851176276803]\n",
      "  batch 30 loss: [31.877708435058594, 0.02407183055765927]\n",
      "  batch 32 loss: [29.208402633666992, 0.022405690513551235]\n",
      "  batch 34 loss: [30.31831645965576, 0.03323987778276205]\n",
      "  batch 36 loss: [38.53868865966797, 0.0133334887214005]\n",
      "  batch 38 loss: [35.05289077758789, 0.011406306410208344]\n",
      "  batch 40 loss: [30.50123691558838, 0.013551313430070877]\n",
      "  batch 42 loss: [34.621825218200684, 0.06007693288847804]\n",
      "  batch 44 loss: [34.353586196899414, 0.06359287537634373]\n",
      "  batch 46 loss: [32.828914642333984, 0.04871991463005543]\n",
      "  batch 48 loss: [40.674659729003906, 0.040397968143224716]\n",
      "  batch 50 loss: [35.112892150878906, 0.04901452176272869]\n",
      "  batch 52 loss: [35.62607765197754, 0.02359151840209961]\n",
      "  batch 54 loss: [32.56115245819092, 0.035216087475419044]\n",
      "LOSS generator 32.56115245819092 discriminator 0.035216087475419044\n",
      "EPOCH 166:\n",
      "  batch 0 loss: [34.88592529296875, 0.022161874920129776]\n",
      "  batch 2 loss: [28.49840259552002, 0.017825850285589695]\n",
      "  batch 4 loss: [40.534658432006836, 0.03514127340167761]\n",
      "  batch 6 loss: [33.63550567626953, 0.022718118503689766]\n",
      "  batch 8 loss: [35.417975425720215, 0.02757081249728799]\n",
      "  batch 10 loss: [27.6813907623291, 0.020698598120361567]\n",
      "  batch 12 loss: [37.32670021057129, 0.03812737902626395]\n",
      "  batch 14 loss: [31.660640716552734, 0.013556435704231262]\n",
      "  batch 16 loss: [33.237770080566406, 0.010859851259738207]\n",
      "  batch 18 loss: [35.201377868652344, 0.008275436237454414]\n",
      "  batch 20 loss: [34.28280830383301, 0.004567866213619709]\n",
      "  batch 22 loss: [32.52159118652344, 0.010573097504675388]\n",
      "  batch 24 loss: [34.324875831604004, 0.017908950801938772]\n",
      "  batch 26 loss: [35.53170204162598, 0.03271539229899645]\n",
      "  batch 28 loss: [35.685532569885254, 0.014535302761942148]\n",
      "  batch 30 loss: [37.450828552246094, 0.02462570881471038]\n",
      "  batch 32 loss: [35.12954330444336, 0.007731197401881218]\n",
      "  batch 34 loss: [36.16400718688965, 0.020033642649650574]\n",
      "  batch 36 loss: [33.34274864196777, 0.02201383002102375]\n",
      "  batch 38 loss: [31.733917236328125, 0.03610282391309738]\n",
      "  batch 40 loss: [34.27202224731445, 0.0087472687009722]\n",
      "  batch 42 loss: [28.208325386047363, 0.015077793970704079]\n",
      "  batch 44 loss: [39.2656364440918, 0.030925733037292957]\n",
      "  batch 46 loss: [36.81340217590332, 0.009086887817829847]\n",
      "  batch 48 loss: [31.988930702209473, 0.016605690587311983]\n",
      "  batch 50 loss: [34.331851959228516, 0.021088808309286833]\n",
      "  batch 52 loss: [36.65366554260254, 0.12130110710859299]\n",
      "  batch 54 loss: [29.02361488342285, 0.015965281752869487]\n",
      "LOSS generator 29.02361488342285 discriminator 0.015965281752869487\n",
      "EPOCH 167:\n",
      "  batch 0 loss: [37.464542388916016, 0.03112945891916752]\n",
      "  batch 2 loss: [38.34523582458496, 0.10303495824337006]\n",
      "  batch 4 loss: [32.125404357910156, 0.04728792514652014]\n",
      "  batch 6 loss: [34.58327674865723, 0.07482289522886276]\n",
      "  batch 8 loss: [38.38043212890625, 0.04234637226909399]\n",
      "  batch 10 loss: [37.56547927856445, 0.05069417133927345]\n",
      "  batch 12 loss: [31.091044425964355, 0.017374827526509762]\n",
      "  batch 14 loss: [32.21074199676514, 0.024363736156374216]\n",
      "  batch 16 loss: [28.5350980758667, 0.041871149092912674]\n",
      "  batch 18 loss: [29.319021224975586, 0.09946008725091815]\n",
      "  batch 20 loss: [36.34036636352539, 0.007905730046331882]\n",
      "  batch 22 loss: [33.101168632507324, 0.011267423164099455]\n",
      "  batch 24 loss: [34.947505950927734, 0.00914075318723917]\n",
      "  batch 26 loss: [40.21894645690918, 0.007306302664801478]\n",
      "  batch 28 loss: [35.73657417297363, 0.014477834571152925]\n",
      "  batch 30 loss: [30.311772346496582, 0.011638677679002285]\n",
      "  batch 32 loss: [34.06698417663574, 0.011084805242717266]\n",
      "  batch 34 loss: [37.62934112548828, 0.010126108769327402]\n",
      "  batch 36 loss: [28.314560890197754, 0.006432159570977092]\n",
      "  batch 38 loss: [33.223772048950195, 0.037284075282514095]\n",
      "  batch 40 loss: [35.14189147949219, 0.010390264680609107]\n",
      "  batch 42 loss: [33.2184419631958, 0.004094430711120367]\n",
      "  batch 44 loss: [36.51887321472168, 0.027739263139665127]\n",
      "  batch 46 loss: [37.94528007507324, 0.021604971028864384]\n",
      "  batch 48 loss: [30.927045822143555, 0.004592298995703459]\n",
      "  batch 50 loss: [36.37740135192871, 0.04328409768640995]\n",
      "  batch 52 loss: [31.732617378234863, 0.010010433616116643]\n",
      "  batch 54 loss: [32.903120040893555, 0.017229754477739334]\n",
      "LOSS generator 32.903120040893555 discriminator 0.017229754477739334\n",
      "EPOCH 168:\n",
      "  batch 0 loss: [33.788082122802734, 0.022838423028588295]\n",
      "  batch 2 loss: [36.369354248046875, 0.021397676318883896]\n",
      "  batch 4 loss: [40.9499397277832, 0.010259879985824227]\n",
      "  batch 6 loss: [31.44857120513916, 0.04245406482368708]\n",
      "  batch 8 loss: [33.34433364868164, 0.043433548882603645]\n",
      "  batch 10 loss: [32.41009712219238, 0.02413713652640581]\n",
      "  batch 12 loss: [31.535459518432617, 0.015829501673579216]\n",
      "  batch 14 loss: [35.316115379333496, 0.026489362120628357]\n",
      "  batch 16 loss: [37.02910232543945, 0.01763682020828128]\n",
      "  batch 18 loss: [32.79202365875244, 0.011128622107207775]\n",
      "  batch 20 loss: [32.656771659851074, 0.006224373355507851]\n",
      "  batch 22 loss: [41.438066482543945, 0.01315567473648116]\n",
      "  batch 24 loss: [31.610501289367676, 0.06563699804246426]\n",
      "  batch 26 loss: [32.53071975708008, 0.024887994397431612]\n",
      "  batch 28 loss: [34.92461681365967, 0.031581077724695206]\n",
      "  batch 30 loss: [34.7259464263916, 0.008342017186805606]\n",
      "  batch 32 loss: [32.46581268310547, 0.007179003558121622]\n",
      "  batch 34 loss: [30.302995681762695, 0.016918667126446962]\n",
      "  batch 36 loss: [29.310861587524414, 0.02996309334412217]\n",
      "  batch 38 loss: [33.001792907714844, 0.03510106634348631]\n",
      "  batch 40 loss: [35.84601402282715, 0.021152500063180923]\n",
      "  batch 42 loss: [32.78296089172363, 0.0065549639984965324]\n",
      "  batch 44 loss: [36.97603988647461, 0.03337078541517258]\n",
      "  batch 46 loss: [29.264283180236816, 0.010798859177157283]\n",
      "  batch 48 loss: [31.608776092529297, 0.010864297393709421]\n",
      "  batch 50 loss: [37.01361274719238, 0.024515063036233187]\n",
      "  batch 52 loss: [41.99652671813965, 0.006941755884326994]\n",
      "  batch 54 loss: [31.844910621643066, 0.003482213942334056]\n",
      "LOSS generator 31.844910621643066 discriminator 0.003482213942334056\n",
      "EPOCH 169:\n",
      "  batch 0 loss: [34.96672058105469, 0.007172822952270508]\n",
      "  batch 2 loss: [36.024295806884766, 0.020062786992639303]\n",
      "  batch 4 loss: [36.221351623535156, 0.0351522583514452]\n",
      "  batch 6 loss: [33.354251861572266, 0.013211274053901434]\n",
      "  batch 8 loss: [37.56772422790527, 0.008292755694128573]\n",
      "  batch 10 loss: [30.038833618164062, 0.014701563632115722]\n",
      "  batch 12 loss: [33.71059799194336, 0.006711377762258053]\n",
      "  batch 14 loss: [28.912583351135254, 0.007547788321971893]\n",
      "  batch 16 loss: [37.461992263793945, 0.006781872129067779]\n",
      "  batch 18 loss: [30.04043960571289, 0.017995077185332775]\n",
      "  batch 20 loss: [33.85706329345703, 0.03502481058239937]\n",
      "  batch 22 loss: [35.66147994995117, 0.013144699216354638]\n",
      "  batch 24 loss: [33.55692958831787, 0.013690784573554993]\n",
      "  batch 26 loss: [42.32546424865723, 0.015314784366637468]\n",
      "  batch 28 loss: [34.6217098236084, 0.002853955957107246]\n",
      "  batch 30 loss: [31.775541305541992, 0.04885558085516095]\n",
      "  batch 32 loss: [35.45657444000244, 0.012664880603551865]\n",
      "  batch 34 loss: [37.606258392333984, 0.005224536173045635]\n",
      "  batch 36 loss: [31.894533157348633, 0.0054888008162379265]\n",
      "  batch 38 loss: [33.4350700378418, 0.005152540688868612]\n",
      "  batch 40 loss: [30.410405158996582, 0.027339379768818617]\n",
      "  batch 42 loss: [34.022708892822266, 0.009054875001311302]\n",
      "  batch 44 loss: [34.51482963562012, 0.003138615400530398]\n",
      "  batch 46 loss: [32.434783935546875, 0.01785705192014575]\n",
      "  batch 48 loss: [34.945234298706055, 0.004282184410840273]\n",
      "  batch 50 loss: [41.01310157775879, 0.037460627034306526]\n",
      "  batch 52 loss: [29.023391723632812, 0.01036813110113144]\n",
      "  batch 54 loss: [37.30316734313965, 0.010562462033703923]\n",
      "LOSS generator 37.30316734313965 discriminator 0.010562462033703923\n",
      "EPOCH 170:\n",
      "  batch 0 loss: [31.477495193481445, 0.008112551644444466]\n",
      "  batch 2 loss: [31.111120223999023, 0.0059632426127791405]\n",
      "  batch 4 loss: [34.54098701477051, 0.045883854385465384]\n",
      "  batch 6 loss: [32.96980094909668, 0.014347461052238941]\n",
      "  batch 8 loss: [30.366058349609375, 0.06425656634382904]\n",
      "  batch 10 loss: [32.022043228149414, 0.012665679212659597]\n",
      "  batch 12 loss: [36.81602668762207, 0.0026823037769645452]\n",
      "  batch 14 loss: [36.77861022949219, 0.009137640707194805]\n",
      "  batch 16 loss: [35.50862121582031, 0.007598866242915392]\n",
      "  batch 18 loss: [31.942357063293457, 0.002140434953616932]\n",
      "  batch 20 loss: [37.149667739868164, 0.012637907639145851]\n",
      "  batch 22 loss: [33.288339614868164, 0.005380447022616863]\n",
      "  batch 24 loss: [34.43505859375, 0.005245032953098416]\n",
      "  batch 26 loss: [33.10969352722168, 0.014347933698445559]\n",
      "  batch 28 loss: [34.74827766418457, 0.017493401188403368]\n",
      "  batch 30 loss: [36.00297546386719, 0.012826906982809305]\n",
      "  batch 32 loss: [31.397186279296875, 0.014229866210371256]\n",
      "  batch 34 loss: [38.05646514892578, 0.04106499161571264]\n",
      "  batch 36 loss: [36.34745216369629, 0.019825628492981195]\n",
      "  batch 38 loss: [33.380680084228516, 0.02356988564133644]\n",
      "  batch 40 loss: [40.09403419494629, 0.019195183645933867]\n",
      "  batch 42 loss: [32.52199935913086, 0.006242444971576333]\n",
      "  batch 44 loss: [35.13483238220215, 0.015513349906541407]\n",
      "  batch 46 loss: [29.94410800933838, 0.012771492823958397]\n",
      "  batch 48 loss: [32.17712116241455, 0.01332439249381423]\n",
      "  batch 50 loss: [39.95087814331055, 0.022570259869098663]\n",
      "  batch 52 loss: [35.67841720581055, 0.018280201591551304]\n",
      "  batch 54 loss: [32.199480056762695, 0.005847563501447439]\n",
      "LOSS generator 32.199480056762695 discriminator 0.005847563501447439\n",
      "EPOCH 171:\n",
      "  batch 0 loss: [35.63861083984375, 0.01162036880850792]\n",
      "  batch 2 loss: [32.86044883728027, 0.06898568756878376]\n",
      "  batch 4 loss: [29.263944625854492, 0.011274714954197407]\n",
      "  batch 6 loss: [36.720176696777344, 0.06176865799352527]\n",
      "  batch 8 loss: [34.848565101623535, 0.01430787262506783]\n",
      "  batch 10 loss: [33.21825695037842, 0.011946751270443201]\n",
      "  batch 12 loss: [36.52192306518555, 0.016872630454599857]\n",
      "  batch 14 loss: [34.85271072387695, 0.028563075116835535]\n",
      "  batch 16 loss: [38.44677734375, 0.07850479707121849]\n",
      "  batch 18 loss: [35.39161682128906, 0.03629972459748387]\n",
      "  batch 20 loss: [35.58884811401367, 0.018573790788650513]\n",
      "  batch 22 loss: [37.452510833740234, 0.035099683329463005]\n",
      "  batch 24 loss: [29.730731964111328, 0.02026965282857418]\n",
      "  batch 26 loss: [30.674158096313477, 0.012933960184454918]\n",
      "  batch 28 loss: [31.303735733032227, 0.024762161076068878]\n",
      "  batch 30 loss: [33.835256576538086, 0.009474809281527996]\n",
      "  batch 32 loss: [40.01622772216797, 0.008379906183108687]\n",
      "  batch 34 loss: [33.13383388519287, 0.011695896741002798]\n",
      "  batch 36 loss: [37.065011978149414, 0.0024152655387297273]\n",
      "  batch 38 loss: [35.57208442687988, 0.007325061364099383]\n",
      "  batch 40 loss: [32.76796531677246, 0.007567722117528319]\n",
      "  batch 42 loss: [37.52499198913574, 0.007548606721684337]\n",
      "  batch 44 loss: [32.227230072021484, 0.0055404684972018]\n",
      "  batch 46 loss: [32.25383949279785, 0.0022107434342615306]\n",
      "  batch 48 loss: [33.710336685180664, 0.015617987141013145]\n",
      "  batch 50 loss: [32.71523380279541, 0.03666965663433075]\n",
      "  batch 52 loss: [37.95598030090332, 0.011993646156042814]\n",
      "  batch 54 loss: [37.127817153930664, 0.0212781373411417]\n",
      "LOSS generator 37.127817153930664 discriminator 0.0212781373411417\n",
      "EPOCH 172:\n",
      "  batch 0 loss: [30.807889938354492, 0.008791460655629635]\n",
      "  batch 2 loss: [35.37930870056152, 0.011210028314962983]\n",
      "  batch 4 loss: [36.20576095581055, 0.004353418247774243]\n",
      "  batch 6 loss: [32.01008987426758, 0.006746225990355015]\n",
      "  batch 8 loss: [30.89484691619873, 0.02322246041148901]\n",
      "  batch 10 loss: [28.209750175476074, 0.015605122782289982]\n",
      "  batch 12 loss: [36.04986000061035, 0.006254040170460939]\n",
      "  batch 14 loss: [36.5007209777832, 0.006706608692184091]\n",
      "  batch 16 loss: [34.46304512023926, 0.007479849737137556]\n",
      "  batch 18 loss: [33.341651916503906, 0.00505050178617239]\n",
      "  batch 20 loss: [31.462517738342285, 0.006381410174071789]\n",
      "  batch 22 loss: [38.75434494018555, 0.028605276253074408]\n",
      "  batch 24 loss: [30.503860473632812, 0.02791787590831518]\n",
      "  batch 26 loss: [31.12643337249756, 0.017574836499989033]\n",
      "  batch 28 loss: [32.03304958343506, 0.08874068083241582]\n",
      "  batch 30 loss: [35.23196601867676, 0.43966132402420044]\n",
      "  batch 32 loss: [35.67330741882324, 0.4600883573293686]\n",
      "  batch 34 loss: [38.70553970336914, 0.3194229155778885]\n",
      "  batch 36 loss: [37.01452445983887, 0.3668823093175888]\n",
      "  batch 38 loss: [31.554049491882324, 0.05402125604450703]\n",
      "  batch 40 loss: [34.795162200927734, 0.04531351337209344]\n",
      "  batch 42 loss: [32.76191520690918, 0.028647041879594326]\n",
      "  batch 44 loss: [30.675711631774902, 0.19844885915517807]\n",
      "  batch 46 loss: [36.63373947143555, 0.044482662342488766]\n",
      "  batch 48 loss: [36.36534309387207, 0.01215427927672863]\n",
      "  batch 50 loss: [42.358680725097656, 0.1800658218562603]\n",
      "  batch 52 loss: [33.47895431518555, 0.07737132627516985]\n",
      "  batch 54 loss: [30.54852867126465, 0.19070386700332165]\n",
      "LOSS generator 30.54852867126465 discriminator 0.19070386700332165\n",
      "EPOCH 173:\n",
      "  batch 0 loss: [30.96422576904297, 0.022614596411585808]\n",
      "  batch 2 loss: [30.416854858398438, 0.3759617507457733]\n",
      "  batch 4 loss: [24.914671897888184, 0.2229730635881424]\n",
      "  batch 6 loss: [33.88667678833008, 0.3201674669981003]\n",
      "  batch 8 loss: [34.17187690734863, 0.07864303514361382]\n",
      "  batch 10 loss: [40.092023849487305, 0.048099953681230545]\n",
      "  batch 12 loss: [30.68367862701416, 0.0147398104891181]\n",
      "  batch 14 loss: [35.51450157165527, 0.018916375003755093]\n",
      "  batch 16 loss: [34.108619689941406, 0.04855780117213726]\n",
      "  batch 18 loss: [30.82490348815918, 0.007369838654994965]\n",
      "  batch 20 loss: [32.39247131347656, 0.04934103600680828]\n",
      "  batch 22 loss: [33.74942970275879, 0.11627212539315224]\n",
      "  batch 24 loss: [36.60613250732422, 0.03543508728034794]\n",
      "  batch 26 loss: [34.10722827911377, 0.015068669337779284]\n",
      "  batch 28 loss: [38.216142654418945, 0.03452379209920764]\n",
      "  batch 30 loss: [43.286184310913086, 0.026444326620548964]\n",
      "  batch 32 loss: [29.973456382751465, 0.18659479171037674]\n",
      "  batch 34 loss: [33.56071186065674, 0.10553538519889116]\n",
      "  batch 36 loss: [29.242633819580078, 0.035399192944169044]\n",
      "  batch 38 loss: [36.867719650268555, 0.04255468025803566]\n",
      "  batch 40 loss: [36.21138381958008, 0.02975997980684042]\n",
      "  batch 42 loss: [31.991758346557617, 0.05457126721739769]\n",
      "  batch 44 loss: [33.10930061340332, 0.027311953715980053]\n",
      "  batch 46 loss: [34.8126106262207, 0.0061564508359879255]\n",
      "  batch 48 loss: [35.48563003540039, 0.01216750533785671]\n",
      "  batch 50 loss: [34.8150577545166, 0.014584778342396021]\n",
      "  batch 52 loss: [31.967077255249023, 0.01217831508256495]\n",
      "  batch 54 loss: [29.492892265319824, 0.04522022418677807]\n",
      "LOSS generator 29.492892265319824 discriminator 0.04522022418677807\n",
      "EPOCH 174:\n",
      "  batch 0 loss: [25.69446563720703, 0.09444335848093033]\n",
      "  batch 2 loss: [41.3823184967041, 0.07529761269688606]\n",
      "  batch 4 loss: [34.18560600280762, 0.02743999194353819]\n",
      "  batch 6 loss: [28.110774993896484, 0.09451170824468136]\n",
      "  batch 8 loss: [30.81135654449463, 0.026164797134697437]\n",
      "  batch 10 loss: [34.380706787109375, 0.014890930615365505]\n",
      "  batch 12 loss: [34.67268180847168, 0.008798829512670636]\n",
      "  batch 14 loss: [37.46661949157715, 0.03625860624015331]\n",
      "  batch 16 loss: [29.289612770080566, 0.0234317141585052]\n",
      "  batch 18 loss: [32.409027099609375, 0.017995834350585938]\n",
      "  batch 20 loss: [33.69414520263672, 0.05298088118433952]\n",
      "  batch 22 loss: [34.993465423583984, 0.04978965222835541]\n",
      "  batch 24 loss: [41.093698501586914, 0.029870130121707916]\n",
      "  batch 26 loss: [35.56060981750488, 0.03533288277685642]\n",
      "  batch 28 loss: [39.845781326293945, 0.018563195131719112]\n",
      "  batch 30 loss: [32.23729133605957, 0.029912693426012993]\n",
      "  batch 32 loss: [35.91157913208008, 0.0031887050718069077]\n",
      "  batch 34 loss: [34.000370025634766, 0.013703177450224757]\n",
      "  batch 36 loss: [31.890785217285156, 0.012146302964538336]\n",
      "  batch 38 loss: [32.05082607269287, 0.005741585046052933]\n",
      "  batch 40 loss: [36.336639404296875, 0.01658323686569929]\n",
      "  batch 42 loss: [30.3537015914917, 0.06647537788376212]\n",
      "  batch 44 loss: [40.1492919921875, 0.0350502273067832]\n",
      "  batch 46 loss: [31.009929656982422, 0.01609867112711072]\n",
      "  batch 48 loss: [32.14085388183594, 0.014761075843125582]\n",
      "  batch 50 loss: [41.95345687866211, 0.024053744971752167]\n",
      "  batch 52 loss: [34.889760971069336, 0.020469563081860542]\n",
      "  batch 54 loss: [33.35393714904785, 0.010753174778074026]\n",
      "LOSS generator 33.35393714904785 discriminator 0.010753174778074026\n",
      "EPOCH 175:\n",
      "  batch 0 loss: [35.31630325317383, 0.015117952600121498]\n",
      "  batch 2 loss: [32.20652484893799, 0.010361144319176674]\n",
      "  batch 4 loss: [31.51989459991455, 0.016727366019040346]\n",
      "  batch 6 loss: [36.9205207824707, 0.02107181935571134]\n",
      "  batch 8 loss: [34.207014083862305, 0.010396308731287718]\n",
      "  batch 10 loss: [36.982248306274414, 0.02025796379894018]\n",
      "  batch 12 loss: [38.68625068664551, 0.014342824928462505]\n",
      "  batch 14 loss: [40.49148368835449, 0.02432099636644125]\n",
      "  batch 16 loss: [32.398983001708984, 0.027261356823146343]\n",
      "  batch 18 loss: [38.387495040893555, 0.018049252219498158]\n",
      "  batch 20 loss: [31.513545036315918, 0.01517441589385271]\n",
      "  batch 22 loss: [33.12703323364258, 0.10638728365302086]\n",
      "  batch 24 loss: [35.96279525756836, 0.022944508586078882]\n",
      "  batch 26 loss: [34.52488708496094, 0.027508815750479698]\n",
      "  batch 28 loss: [33.15199375152588, 0.011858079815283418]\n",
      "  batch 30 loss: [35.62290096282959, 0.030558381229639053]\n",
      "  batch 32 loss: [35.24381446838379, 0.017347369343042374]\n",
      "  batch 34 loss: [34.11833477020264, 0.01633814023807645]\n",
      "  batch 36 loss: [34.2014102935791, 0.01684637274593115]\n",
      "  batch 38 loss: [37.11933135986328, 0.02392501663416624]\n",
      "  batch 40 loss: [32.42686462402344, 0.007471654564142227]\n",
      "  batch 42 loss: [33.233412742614746, 0.009546954650431871]\n",
      "  batch 44 loss: [32.90205001831055, 0.004161088494583964]\n",
      "  batch 46 loss: [30.643829345703125, 0.005406094249337912]\n",
      "  batch 48 loss: [34.02220344543457, 0.004784353310242295]\n",
      "  batch 50 loss: [36.13907814025879, 0.015347741078585386]\n",
      "  batch 52 loss: [31.608826637268066, 0.00668464507907629]\n",
      "  batch 54 loss: [34.19443130493164, 0.009091111831367016]\n",
      "LOSS generator 34.19443130493164 discriminator 0.009091111831367016\n",
      "EPOCH 176:\n",
      "  batch 0 loss: [34.131431579589844, 0.00886034406721592]\n",
      "  batch 2 loss: [30.91206169128418, 0.004088223213329911]\n",
      "  batch 4 loss: [40.10183334350586, 0.017922769766300917]\n",
      "  batch 6 loss: [33.55128288269043, 0.0069764889776706696]\n",
      "  batch 8 loss: [33.25135803222656, 0.011802057269960642]\n",
      "  batch 10 loss: [39.64494705200195, 0.005620364099740982]\n",
      "  batch 12 loss: [26.211984634399414, 0.060058566741645336]\n",
      "  batch 14 loss: [32.708791732788086, 0.003142892848700285]\n",
      "  batch 16 loss: [38.908355712890625, 0.015076206531375647]\n",
      "  batch 18 loss: [37.48803901672363, 0.011918121483176947]\n",
      "  batch 20 loss: [36.20443153381348, 0.023039253195747733]\n",
      "  batch 22 loss: [42.70715141296387, 0.04031076841056347]\n",
      "  batch 24 loss: [33.761186599731445, 0.0043648864375427365]\n",
      "  batch 26 loss: [34.0221586227417, 0.022336607333272696]\n",
      "  batch 28 loss: [34.50180625915527, 0.009118810063228011]\n",
      "  batch 30 loss: [30.588862419128418, 0.015389281790703535]\n",
      "  batch 32 loss: [35.39303016662598, 0.005751451710239053]\n",
      "  batch 34 loss: [33.257646560668945, 0.03060303069651127]\n",
      "  batch 36 loss: [30.653228759765625, 0.03480093274265528]\n",
      "  batch 38 loss: [33.18699264526367, 0.03907896112650633]\n",
      "  batch 40 loss: [28.466639518737793, 0.029955817386507988]\n",
      "  batch 42 loss: [32.21305274963379, 0.010989932110533118]\n",
      "  batch 44 loss: [30.668729782104492, 0.011990804690867662]\n",
      "  batch 46 loss: [37.14058494567871, 0.026148606091737747]\n",
      "  batch 48 loss: [41.77940559387207, 0.01999342313501984]\n",
      "  batch 50 loss: [37.83140563964844, 0.01541117113083601]\n",
      "  batch 52 loss: [39.11484336853027, 0.004794097214471549]\n",
      "  batch 54 loss: [34.03537082672119, 0.034431359730660915]\n",
      "LOSS generator 34.03537082672119 discriminator 0.034431359730660915\n",
      "EPOCH 177:\n",
      "  batch 0 loss: [24.464881896972656, 0.014679573476314545]\n",
      "  batch 2 loss: [28.91381072998047, 0.024225558154284954]\n",
      "  batch 4 loss: [33.379220962524414, 0.01521702902391553]\n",
      "  batch 6 loss: [30.223167419433594, 0.02042417787015438]\n",
      "  batch 8 loss: [30.079769134521484, 0.013408014550805092]\n",
      "  batch 10 loss: [37.13237762451172, 0.011137847555801272]\n",
      "  batch 12 loss: [35.57372283935547, 0.005484642460942268]\n",
      "  batch 14 loss: [38.49592399597168, 0.03431445173919201]\n",
      "  batch 16 loss: [32.6486291885376, 0.09421508945524693]\n",
      "  batch 18 loss: [34.37138843536377, 0.010964148328639567]\n",
      "  batch 20 loss: [32.52411651611328, 0.011634939815849066]\n",
      "  batch 22 loss: [39.16881561279297, 0.011991429841145873]\n",
      "  batch 24 loss: [38.063377380371094, 0.013862333842553198]\n",
      "  batch 26 loss: [37.93196678161621, 0.03324514999985695]\n",
      "  batch 28 loss: [29.894302368164062, 0.008690034504979849]\n",
      "  batch 30 loss: [33.955495834350586, 0.014692914905026555]\n",
      "  batch 32 loss: [37.26073455810547, 0.025614946149289608]\n",
      "  batch 34 loss: [31.649446487426758, 0.019676812924444675]\n",
      "  batch 36 loss: [37.04380226135254, 0.009122705552726984]\n",
      "  batch 38 loss: [37.23242378234863, 0.020513487979769707]\n",
      "  batch 40 loss: [35.26319694519043, 0.006158069882076234]\n",
      "  batch 42 loss: [38.55606269836426, 0.007801451720297337]\n",
      "  batch 44 loss: [36.50301170349121, 0.013689110055565834]\n",
      "  batch 46 loss: [35.25080108642578, 0.005016843089833856]\n",
      "  batch 48 loss: [29.771581649780273, 0.008843776537105441]\n",
      "  batch 50 loss: [37.66746711730957, 0.012443307088688016]\n",
      "  batch 52 loss: [37.04305076599121, 0.009009738452732563]\n",
      "  batch 54 loss: [37.63799285888672, 0.007469123229384422]\n",
      "LOSS generator 37.63799285888672 discriminator 0.007469123229384422\n",
      "EPOCH 178:\n",
      "  batch 0 loss: [32.2884407043457, 0.0034937760792672634]\n",
      "  batch 2 loss: [35.355756759643555, 0.007747295487206429]\n",
      "  batch 4 loss: [35.86100769042969, 0.005831445101648569]\n",
      "  batch 6 loss: [32.25352478027344, 0.005136447551194578]\n",
      "  batch 8 loss: [32.82738399505615, 0.010499531868845224]\n",
      "  batch 10 loss: [40.72167205810547, 0.0062271455535665154]\n",
      "  batch 12 loss: [38.8409538269043, 0.003818148863501847]\n",
      "  batch 14 loss: [38.50197219848633, 0.021937786135822535]\n",
      "  batch 16 loss: [35.21094512939453, 0.010193901602178812]\n",
      "  batch 18 loss: [32.25487422943115, 0.028123111464083195]\n",
      "  batch 20 loss: [32.01790142059326, 0.009701376780867577]\n",
      "  batch 22 loss: [35.74301528930664, 0.019826553063467145]\n",
      "  batch 24 loss: [37.91994094848633, 0.007449371856637299]\n",
      "  batch 26 loss: [35.871076583862305, 0.017848556861281395]\n",
      "  batch 28 loss: [38.04484748840332, 0.024779497180134058]\n",
      "  batch 30 loss: [31.285597801208496, 0.00686315237544477]\n",
      "  batch 32 loss: [38.00702476501465, 0.003002555458806455]\n",
      "  batch 34 loss: [36.71732139587402, 0.047404234297573566]\n",
      "  batch 36 loss: [35.50173759460449, 0.006434611510485411]\n",
      "  batch 38 loss: [36.190019607543945, 0.05817862041294575]\n",
      "  batch 40 loss: [26.555916786193848, 2.1325474977493286]\n",
      "  batch 42 loss: [35.932878494262695, 1.7225449085235596]\n",
      "  batch 44 loss: [33.296226501464844, 1.2020045220851898]\n",
      "  batch 46 loss: [26.487587928771973, 1.058866024017334]\n",
      "  batch 48 loss: [29.586338996887207, 1.03885155916214]\n",
      "  batch 50 loss: [33.39919376373291, 0.9581000208854675]\n",
      "  batch 52 loss: [36.359317779541016, 0.7176079750061035]\n",
      "  batch 54 loss: [44.89023780822754, 1.2981082201004028]\n",
      "LOSS generator 44.89023780822754 discriminator 1.2981082201004028\n",
      "EPOCH 179:\n",
      "  batch 0 loss: [33.148075103759766, 0.7506370544433594]\n",
      "  batch 2 loss: [28.56276512145996, 0.6607210040092468]\n",
      "  batch 4 loss: [41.90300750732422, 0.6137387156486511]\n",
      "  batch 6 loss: [37.54410362243652, 0.37440428137779236]\n",
      "  batch 8 loss: [28.103861808776855, 0.73908331990242]\n",
      "  batch 10 loss: [47.13142013549805, 0.8507808744907379]\n",
      "  batch 12 loss: [35.44114112854004, 0.5641658306121826]\n",
      "  batch 14 loss: [34.10996723175049, 0.4974878430366516]\n",
      "  batch 16 loss: [42.29693794250488, 0.6275300681591034]\n",
      "  batch 18 loss: [31.100343704223633, 0.8602085709571838]\n",
      "  batch 20 loss: [33.845038414001465, 0.6829791069030762]\n",
      "  batch 22 loss: [29.3837308883667, 0.5999606251716614]\n",
      "  batch 24 loss: [36.29884719848633, 0.5847976505756378]\n",
      "  batch 26 loss: [34.69613456726074, 0.48102226853370667]\n",
      "  batch 28 loss: [41.09177589416504, 0.48238204419612885]\n",
      "  batch 30 loss: [43.131765365600586, 0.7784991562366486]\n",
      "  batch 32 loss: [36.26800727844238, 0.5059915035963058]\n",
      "  batch 34 loss: [41.25624465942383, 0.4873962998390198]\n",
      "  batch 36 loss: [33.284162521362305, 0.5517784357070923]\n",
      "  batch 38 loss: [41.35736083984375, 0.5776688754558563]\n",
      "  batch 40 loss: [32.53367328643799, 0.30345629155635834]\n",
      "  batch 42 loss: [35.399091720581055, 0.32930053770542145]\n",
      "  batch 44 loss: [32.444862365722656, 0.2061784267425537]\n",
      "  batch 46 loss: [37.060001373291016, 0.1459013633430004]\n",
      "  batch 48 loss: [37.89064598083496, 0.06143640726804733]\n",
      "  batch 50 loss: [42.334585189819336, 0.13190597668290138]\n",
      "  batch 52 loss: [35.978105545043945, 0.10429000854492188]\n",
      "  batch 54 loss: [42.2675666809082, 0.06066324561834335]\n",
      "LOSS generator 42.2675666809082 discriminator 0.06066324561834335\n",
      "EPOCH 180:\n",
      "  batch 0 loss: [35.50694274902344, 0.14371322095394135]\n",
      "  batch 2 loss: [35.43375587463379, 0.1015569157898426]\n",
      "  batch 4 loss: [38.42971420288086, 0.17565114796161652]\n",
      "  batch 6 loss: [34.04333686828613, 0.1547020748257637]\n",
      "  batch 8 loss: [40.314558029174805, 0.10530189797282219]\n",
      "  batch 10 loss: [37.872392654418945, 0.04831292852759361]\n",
      "  batch 12 loss: [33.78057098388672, 0.050607385113835335]\n",
      "  batch 14 loss: [42.41716766357422, 0.13352564722299576]\n",
      "  batch 16 loss: [40.007904052734375, 0.041550335474312305]\n",
      "  batch 18 loss: [32.67409801483154, 0.13793877139687538]\n",
      "  batch 20 loss: [33.653221130371094, 0.11961043626070023]\n",
      "  batch 22 loss: [36.8543701171875, 0.055147238075733185]\n",
      "  batch 24 loss: [42.44379425048828, 0.057906223461031914]\n",
      "  batch 26 loss: [37.39731311798096, 0.26507800817489624]\n",
      "  batch 28 loss: [39.974355697631836, 0.22254253551363945]\n",
      "  batch 30 loss: [33.9722785949707, 0.16413965076208115]\n",
      "  batch 32 loss: [41.008644104003906, 0.10091526806354523]\n",
      "  batch 34 loss: [44.62933540344238, 0.17792915925383568]\n",
      "  batch 36 loss: [42.51963233947754, 0.11062407679855824]\n",
      "  batch 38 loss: [38.910133361816406, 0.0844685360789299]\n",
      "  batch 40 loss: [38.597585678100586, 0.04567950963973999]\n",
      "  batch 42 loss: [41.381975173950195, 0.024831151589751244]\n",
      "  batch 44 loss: [33.911742210388184, 0.23262321949005127]\n",
      "  batch 46 loss: [45.49054527282715, 0.06122023053467274]\n",
      "  batch 48 loss: [38.753746032714844, 0.07149702683091164]\n",
      "  batch 50 loss: [39.661563873291016, 0.0498011561576277]\n",
      "  batch 52 loss: [37.01489067077637, 0.08174698892980814]\n",
      "  batch 54 loss: [32.865217208862305, 1.5232593417167664]\n",
      "LOSS generator 32.865217208862305 discriminator 1.5232593417167664\n",
      "EPOCH 181:\n",
      "  batch 0 loss: [38.12730407714844, 1.7642335891723633]\n",
      "  batch 2 loss: [33.46150779724121, 0.6738392859697342]\n",
      "  batch 4 loss: [28.4104061126709, 0.3102346211671829]\n",
      "  batch 6 loss: [27.351258277893066, 0.4555522948503494]\n",
      "  batch 8 loss: [31.06334686279297, 0.18366900458931923]\n",
      "  batch 10 loss: [31.391929626464844, 0.056853216141462326]\n",
      "  batch 12 loss: [35.13774871826172, 0.07898390106856823]\n",
      "  batch 14 loss: [31.854483604431152, 0.09370268136262894]\n",
      "  batch 16 loss: [34.009337425231934, 0.08329019695520401]\n",
      "  batch 18 loss: [30.045891761779785, 0.04647214524447918]\n",
      "  batch 20 loss: [35.09576416015625, 0.07581313140690327]\n",
      "  batch 22 loss: [30.664315223693848, 0.05094424448907375]\n",
      "  batch 24 loss: [36.37938117980957, 0.08974234014749527]\n",
      "  batch 26 loss: [33.04473400115967, 0.10562913492321968]\n",
      "  batch 28 loss: [31.61160373687744, 0.15357572957873344]\n",
      "  batch 30 loss: [32.67457866668701, 0.2076583206653595]\n",
      "  batch 32 loss: [33.06344032287598, 0.09055974893271923]\n",
      "  batch 34 loss: [31.254006385803223, 0.05855503864586353]\n",
      "  batch 36 loss: [32.64496898651123, 0.04671552591025829]\n",
      "  batch 38 loss: [28.650728225708008, 0.02015482261776924]\n",
      "  batch 40 loss: [29.54751205444336, 0.0210101124830544]\n",
      "  batch 42 loss: [32.74952697753906, 0.045492496341466904]\n",
      "  batch 44 loss: [35.412275314331055, 0.07288199104368687]\n",
      "  batch 46 loss: [30.041552543640137, 0.0511931162327528]\n",
      "  batch 48 loss: [30.020524978637695, 0.14069764874875546]\n",
      "  batch 50 loss: [35.294071197509766, 0.03669582214206457]\n",
      "  batch 52 loss: [35.451581954956055, 0.030145021621137857]\n",
      "  batch 54 loss: [30.113242149353027, 0.03222459740936756]\n",
      "LOSS generator 30.113242149353027 discriminator 0.03222459740936756\n",
      "EPOCH 182:\n",
      "  batch 0 loss: [27.687602996826172, 0.359191358089447]\n",
      "  batch 2 loss: [29.11924934387207, 0.0851509110070765]\n",
      "  batch 4 loss: [32.7163143157959, 0.025716282427310944]\n",
      "  batch 6 loss: [28.60887336730957, 0.15336063504219055]\n",
      "  batch 8 loss: [34.32075881958008, 0.030800293665379286]\n",
      "  batch 10 loss: [31.803685188293457, 0.021946871653199196]\n",
      "  batch 12 loss: [33.000614166259766, 0.05707992892712355]\n",
      "  batch 14 loss: [39.26716232299805, 0.07287765294313431]\n",
      "  batch 16 loss: [38.8514518737793, 0.01145436242222786]\n",
      "  batch 18 loss: [32.76283359527588, 0.12260004365816712]\n",
      "  batch 20 loss: [37.40134811401367, 0.09262088686227798]\n",
      "  batch 22 loss: [39.2904109954834, 0.24872665852308273]\n",
      "  batch 24 loss: [32.003923416137695, 0.08737171813845634]\n",
      "  batch 26 loss: [35.57681846618652, 0.08171709068119526]\n",
      "  batch 28 loss: [31.01932144165039, 0.08493921346962452]\n",
      "  batch 30 loss: [30.846006393432617, 0.06387804262340069]\n",
      "  batch 32 loss: [30.350650787353516, 0.08376006409525871]\n",
      "  batch 34 loss: [29.535115242004395, 0.06128848157823086]\n",
      "  batch 36 loss: [34.1637020111084, 0.08426174521446228]\n",
      "  batch 38 loss: [34.94854164123535, 0.0224948120303452]\n",
      "  batch 40 loss: [35.45722579956055, 0.07192803919315338]\n",
      "  batch 42 loss: [29.98842716217041, 0.03289726376533508]\n",
      "  batch 44 loss: [33.57386779785156, 0.035920072346925735]\n",
      "  batch 46 loss: [31.059195518493652, 0.02708242181688547]\n",
      "  batch 48 loss: [27.80564022064209, 0.01999580394476652]\n",
      "  batch 50 loss: [30.558361053466797, 0.044049753807485104]\n",
      "  batch 52 loss: [32.978506088256836, 0.015058301854878664]\n",
      "  batch 54 loss: [36.932193756103516, 0.020356981083750725]\n",
      "LOSS generator 36.932193756103516 discriminator 0.020356981083750725\n",
      "EPOCH 183:\n",
      "  batch 0 loss: [31.088167190551758, 0.015409589745104313]\n",
      "  batch 2 loss: [35.229196548461914, 0.04732199851423502]\n",
      "  batch 4 loss: [32.568565368652344, 0.023870724719017744]\n",
      "  batch 6 loss: [30.932329177856445, 0.02917927550151944]\n",
      "  batch 8 loss: [37.18471145629883, 0.018910979852080345]\n",
      "  batch 10 loss: [37.51608657836914, 0.025263141840696335]\n",
      "  batch 12 loss: [37.731740951538086, 0.03752289852127433]\n",
      "  batch 14 loss: [30.063650131225586, 0.018445913214236498]\n",
      "  batch 16 loss: [30.136738777160645, 0.18250589072704315]\n",
      "  batch 18 loss: [30.53346538543701, 0.12472930550575256]\n",
      "  batch 20 loss: [31.133094787597656, 0.09461363963782787]\n",
      "  batch 22 loss: [33.94013500213623, 0.03823705017566681]\n",
      "  batch 24 loss: [35.220027923583984, 0.05599895678460598]\n",
      "  batch 26 loss: [38.35883808135986, 0.043329646810889244]\n",
      "  batch 28 loss: [31.071173667907715, 0.013877655379474163]\n",
      "  batch 30 loss: [39.68034744262695, 0.03807692136615515]\n",
      "  batch 32 loss: [33.894996643066406, 0.020743546076118946]\n",
      "  batch 34 loss: [32.564887046813965, 0.018928383709862828]\n",
      "  batch 36 loss: [42.51944351196289, 0.05055674724280834]\n",
      "  batch 38 loss: [31.134124755859375, 0.0397772341966629]\n",
      "  batch 40 loss: [34.6239538192749, 0.028586496599018574]\n",
      "  batch 42 loss: [32.88564205169678, 0.007298719836398959]\n",
      "  batch 44 loss: [35.36301612854004, 0.013490593060851097]\n",
      "  batch 46 loss: [31.601183891296387, 0.022475217003375292]\n",
      "  batch 48 loss: [30.92298412322998, 0.030104797333478928]\n",
      "  batch 50 loss: [31.142590522766113, 0.016033231047913432]\n",
      "  batch 52 loss: [33.738144874572754, 0.01959242671728134]\n",
      "  batch 54 loss: [31.874096870422363, 0.005768470698967576]\n",
      "LOSS generator 31.874096870422363 discriminator 0.005768470698967576\n",
      "EPOCH 184:\n",
      "  batch 0 loss: [38.934085845947266, 0.006486972328275442]\n",
      "  batch 2 loss: [31.348485946655273, 0.008411805611103773]\n",
      "  batch 4 loss: [31.933584213256836, 0.029196822084486485]\n",
      "  batch 6 loss: [34.973297119140625, 0.011471497709862888]\n",
      "  batch 8 loss: [35.97257995605469, 0.030896039679646492]\n",
      "  batch 10 loss: [33.39060592651367, 0.02975924510974437]\n",
      "  batch 12 loss: [36.52849769592285, 0.051975004374980927]\n",
      "  batch 14 loss: [36.871376037597656, 0.014398124534636736]\n",
      "  batch 16 loss: [42.234981536865234, 0.016192812006920576]\n",
      "  batch 18 loss: [35.18208312988281, 0.04088611155748367]\n",
      "  batch 20 loss: [32.46071815490723, 0.15411964058876038]\n",
      "  batch 22 loss: [33.93096733093262, 0.0933835543692112]\n",
      "  batch 24 loss: [32.475229263305664, 0.0678686834871769]\n",
      "  batch 26 loss: [40.18436622619629, 0.07143717166036367]\n",
      "  batch 28 loss: [26.03374195098877, 0.04086456447839737]\n",
      "  batch 30 loss: [32.035094261169434, 0.025401802733540535]\n",
      "  batch 32 loss: [35.95746612548828, 0.07991576287895441]\n",
      "  batch 34 loss: [31.830737113952637, 0.11236929474398494]\n",
      "  batch 36 loss: [33.16393280029297, 0.027514793910086155]\n",
      "  batch 38 loss: [31.34449291229248, 0.01397569989785552]\n",
      "  batch 40 loss: [34.26866912841797, 0.028339597396552563]\n",
      "  batch 42 loss: [35.56702995300293, 0.021369553171098232]\n",
      "  batch 44 loss: [35.56696701049805, 0.0028713055653497577]\n",
      "  batch 46 loss: [29.514344215393066, 0.03244728408753872]\n",
      "  batch 48 loss: [33.181480407714844, 0.006383225554600358]\n",
      "  batch 50 loss: [31.304051399230957, 0.042320357635617256]\n",
      "  batch 52 loss: [33.1940803527832, 0.03297153487801552]\n",
      "  batch 54 loss: [29.148198127746582, 0.014408756047487259]\n",
      "LOSS generator 29.148198127746582 discriminator 0.014408756047487259\n",
      "EPOCH 185:\n",
      "  batch 0 loss: [31.257545471191406, 0.008761152625083923]\n",
      "  batch 2 loss: [39.960493087768555, 0.009385469136759639]\n",
      "  batch 4 loss: [34.84419059753418, 0.018050378654152155]\n",
      "  batch 6 loss: [34.73594856262207, 0.02327287755906582]\n",
      "  batch 8 loss: [37.27410888671875, 0.020997455343604088]\n",
      "  batch 10 loss: [39.22235679626465, 0.012417508289217949]\n",
      "  batch 12 loss: [32.26738929748535, 0.008764020167291164]\n",
      "  batch 14 loss: [36.42007064819336, 0.009569879504851997]\n",
      "  batch 16 loss: [31.432275772094727, 0.01441448915284127]\n",
      "  batch 18 loss: [28.98157024383545, 0.03719482012093067]\n",
      "  batch 20 loss: [35.28352165222168, 0.006073973956517875]\n",
      "  batch 22 loss: [30.158705711364746, 0.008352480363100767]\n",
      "  batch 24 loss: [32.76979637145996, 0.012553266249597073]\n",
      "  batch 26 loss: [26.286483764648438, 0.021102719008922577]\n",
      "  batch 28 loss: [31.905776977539062, 0.007713492610491812]\n",
      "  batch 30 loss: [37.390281677246094, 0.05714485980570316]\n",
      "  batch 32 loss: [28.641053199768066, 0.03863911097869277]\n",
      "  batch 34 loss: [35.669233322143555, 0.015479384921491146]\n",
      "  batch 36 loss: [40.3875617980957, 0.013197856023907661]\n",
      "  batch 38 loss: [41.854087829589844, 0.01676000701263547]\n",
      "  batch 40 loss: [35.657864570617676, 0.006354504497721791]\n",
      "  batch 42 loss: [32.3013391494751, 0.005222185282036662]\n",
      "  batch 44 loss: [37.45523452758789, 0.02208817156497389]\n",
      "  batch 46 loss: [32.714253425598145, 0.008132221177220345]\n",
      "  batch 48 loss: [38.38530921936035, 0.013579056598246098]\n",
      "  batch 50 loss: [35.338314056396484, 0.0033869610633701086]\n",
      "  batch 52 loss: [29.98348331451416, 0.07548025902360678]\n",
      "  batch 54 loss: [36.142836570739746, 0.0514637203887105]\n",
      "LOSS generator 36.142836570739746 discriminator 0.0514637203887105\n",
      "EPOCH 186:\n",
      "  batch 0 loss: [44.97928237915039, 0.039454273879528046]\n",
      "  batch 2 loss: [29.559815406799316, 0.0669306293129921]\n",
      "  batch 4 loss: [29.67372703552246, 0.028651068918406963]\n",
      "  batch 6 loss: [33.953535079956055, 0.019196294248104095]\n",
      "  batch 8 loss: [37.01107215881348, 0.019716843031346798]\n",
      "  batch 10 loss: [28.57450008392334, 0.025595691986382008]\n",
      "  batch 12 loss: [35.54119873046875, 0.017024856060743332]\n",
      "  batch 14 loss: [33.15554618835449, 0.016384247224777937]\n",
      "  batch 16 loss: [31.62429904937744, 0.027934234589338303]\n",
      "  batch 18 loss: [37.587581634521484, 0.03231109073385596]\n",
      "  batch 20 loss: [31.71784019470215, 0.08977035945281386]\n",
      "  batch 22 loss: [34.662899017333984, 0.017751000355929136]\n",
      "  batch 24 loss: [36.37446403503418, 0.09043615311384201]\n",
      "  batch 26 loss: [32.45570087432861, 0.03628728352487087]\n",
      "  batch 28 loss: [27.654191970825195, 0.15222366340458393]\n",
      "  batch 30 loss: [30.620141983032227, 0.1108202375471592]\n",
      "  batch 32 loss: [32.3791561126709, 0.046562775038182735]\n",
      "  batch 34 loss: [31.910888671875, 0.07690883427858353]\n",
      "  batch 36 loss: [36.5985050201416, 0.05861896462738514]\n",
      "  batch 38 loss: [29.840153694152832, 0.07842478156089783]\n",
      "  batch 40 loss: [36.74982452392578, 0.0488977562636137]\n",
      "  batch 42 loss: [35.139848709106445, 0.027273006737232208]\n",
      "  batch 44 loss: [34.41518306732178, 0.011450068792328238]\n",
      "  batch 46 loss: [37.97258186340332, 0.022407423704862595]\n",
      "  batch 48 loss: [31.09517765045166, 0.025517876259982586]\n",
      "  batch 50 loss: [30.4326114654541, 0.033894999884068966]\n",
      "  batch 52 loss: [34.950599670410156, 0.02013013605028391]\n",
      "  batch 54 loss: [33.498891830444336, 0.022723677568137646]\n",
      "LOSS generator 33.498891830444336 discriminator 0.022723677568137646\n",
      "EPOCH 187:\n",
      "  batch 0 loss: [34.6392936706543, 0.006627152673900127]\n",
      "  batch 2 loss: [39.185556411743164, 0.050837256014347076]\n",
      "  batch 4 loss: [33.856794357299805, 0.042669229209423065]\n",
      "  batch 6 loss: [31.410874366760254, 0.038481004536151886]\n",
      "  batch 8 loss: [31.052244186401367, 0.03277108445763588]\n",
      "  batch 10 loss: [29.772823333740234, 0.015365950763225555]\n",
      "  batch 12 loss: [28.899314880371094, 0.017665172927081585]\n",
      "  batch 14 loss: [37.721628189086914, 0.02386616077274084]\n",
      "  batch 16 loss: [38.81863212585449, 0.010660805739462376]\n",
      "  batch 18 loss: [29.29166030883789, 0.015486159361898899]\n",
      "  batch 20 loss: [40.89399528503418, 0.008712731767445803]\n",
      "  batch 22 loss: [36.21451282501221, 0.015032537281513214]\n",
      "  batch 24 loss: [31.60568904876709, 0.010936222737655044]\n",
      "  batch 26 loss: [38.17393684387207, 0.025621427223086357]\n",
      "  batch 28 loss: [34.864158630371094, 0.06177198328077793]\n",
      "  batch 30 loss: [33.53110313415527, 0.02331824228167534]\n",
      "  batch 32 loss: [32.5736026763916, 0.031042580027133226]\n",
      "  batch 34 loss: [30.01634407043457, 0.07963848067447543]\n",
      "  batch 36 loss: [27.11603355407715, 0.012700367253273726]\n",
      "  batch 38 loss: [37.39852333068848, 0.002598151913844049]\n",
      "  batch 40 loss: [35.04369068145752, 0.04522247985005379]\n",
      "  batch 42 loss: [31.53643035888672, 0.03241977281868458]\n",
      "  batch 44 loss: [38.1678466796875, 0.008146384730935097]\n",
      "  batch 46 loss: [36.415751457214355, 0.018559475429356098]\n",
      "  batch 48 loss: [31.502954483032227, 0.011304852087050676]\n",
      "  batch 50 loss: [32.62780952453613, 0.03513019345700741]\n",
      "  batch 52 loss: [31.045947074890137, 0.03193340077996254]\n",
      "  batch 54 loss: [35.99030590057373, 0.020337454974651337]\n",
      "LOSS generator 35.99030590057373 discriminator 0.020337454974651337\n",
      "EPOCH 188:\n",
      "  batch 0 loss: [28.415664672851562, 0.015574116259813309]\n",
      "  batch 2 loss: [34.725637435913086, 0.03292636992409825]\n",
      "  batch 4 loss: [34.44529724121094, 0.008430888410657644]\n",
      "  batch 6 loss: [32.6190710067749, 0.010132159106433392]\n",
      "  batch 8 loss: [33.56767463684082, 0.01399423461407423]\n",
      "  batch 10 loss: [38.81105995178223, 0.006418449338525534]\n",
      "  batch 12 loss: [39.579288482666016, 0.03216007392620668]\n",
      "  batch 14 loss: [33.977481842041016, 0.018763387110084295]\n",
      "  batch 16 loss: [31.79856014251709, 0.010407714173197746]\n",
      "  batch 18 loss: [35.33502388000488, 0.046041715890169144]\n",
      "  batch 20 loss: [39.54380798339844, 0.05204332899302244]\n",
      "  batch 22 loss: [32.003557205200195, 0.03274131868965924]\n",
      "  batch 24 loss: [36.01109504699707, 0.03392932144924998]\n",
      "  batch 26 loss: [37.64077568054199, 0.009003219194710255]\n",
      "  batch 28 loss: [29.278963088989258, 0.019933141767978668]\n",
      "  batch 30 loss: [32.99611473083496, 0.015295928344130516]\n",
      "  batch 32 loss: [31.875670433044434, 0.06652072723954916]\n",
      "  batch 34 loss: [32.76894760131836, 0.0318914819508791]\n",
      "  batch 36 loss: [34.3016414642334, 0.010885326191782951]\n",
      "  batch 38 loss: [38.66859817504883, 0.022199755534529686]\n",
      "  batch 40 loss: [28.84566020965576, 0.03847395442426205]\n",
      "  batch 42 loss: [30.85106658935547, 0.01005122670903802]\n",
      "  batch 44 loss: [39.19282913208008, 0.01683455624151975]\n",
      "  batch 46 loss: [33.26726150512695, 0.01914133643731475]\n",
      "  batch 48 loss: [33.160136222839355, 0.013392883352935314]\n",
      "  batch 50 loss: [37.1533317565918, 0.00782326515763998]\n",
      "  batch 52 loss: [34.978078842163086, 0.034635483752936125]\n",
      "  batch 54 loss: [31.76297378540039, 0.05731797404587269]\n",
      "LOSS generator 31.76297378540039 discriminator 0.05731797404587269\n",
      "EPOCH 189:\n",
      "  batch 0 loss: [35.85496520996094, 0.015539880841970444]\n",
      "  batch 2 loss: [36.948341369628906, 0.016728525632061064]\n",
      "  batch 4 loss: [36.6234188079834, 0.014249363448470831]\n",
      "  batch 6 loss: [31.792710304260254, 0.021626342087984085]\n",
      "  batch 8 loss: [34.69882869720459, 0.04489654675126076]\n",
      "  batch 10 loss: [34.13690948486328, 0.02052079141139984]\n",
      "  batch 12 loss: [33.470741271972656, 0.017204929143190384]\n",
      "  batch 14 loss: [35.41566467285156, 0.007126679876819253]\n",
      "  batch 16 loss: [34.71517562866211, 0.02002504374831915]\n",
      "  batch 18 loss: [34.69475173950195, 0.02841711789369583]\n",
      "  batch 20 loss: [33.451847076416016, 0.0285616684705019]\n",
      "  batch 22 loss: [39.491859436035156, 0.05223488621413708]\n",
      "  batch 24 loss: [34.24276351928711, 0.061315834522247314]\n",
      "  batch 26 loss: [36.03415870666504, 0.034831780940294266]\n",
      "  batch 28 loss: [35.0300874710083, 0.015958920819684863]\n",
      "  batch 30 loss: [35.02339553833008, 0.019440933130681515]\n",
      "  batch 32 loss: [34.27888870239258, 0.01222943002358079]\n",
      "  batch 34 loss: [32.43541717529297, 0.025465323124080896]\n",
      "  batch 36 loss: [34.428911209106445, 0.018277634866535664]\n",
      "  batch 38 loss: [36.28409004211426, 0.018850713968276978]\n",
      "  batch 40 loss: [36.3960075378418, 0.009202934335917234]\n",
      "  batch 42 loss: [31.37410831451416, 0.02907564863562584]\n",
      "  batch 44 loss: [29.776214599609375, 0.036518532782793045]\n",
      "  batch 46 loss: [29.2554931640625, 0.029046785086393356]\n",
      "  batch 48 loss: [36.69597148895264, 0.017175129847601056]\n",
      "  batch 50 loss: [29.77381992340088, 0.015545024536550045]\n",
      "  batch 52 loss: [32.71292495727539, 0.009303742088377476]\n",
      "  batch 54 loss: [30.717906951904297, 0.09378622472286224]\n",
      "LOSS generator 30.717906951904297 discriminator 0.09378622472286224\n",
      "EPOCH 190:\n",
      "  batch 0 loss: [36.86637878417969, 0.06408446282148361]\n",
      "  batch 2 loss: [36.25331497192383, 0.042417784221470356]\n",
      "  batch 4 loss: [33.631561279296875, 0.005653585074469447]\n",
      "  batch 6 loss: [35.31435012817383, 0.05741268955171108]\n",
      "  batch 8 loss: [34.26596260070801, 0.009749285294674337]\n",
      "  batch 10 loss: [36.712225914001465, 0.021818336099386215]\n",
      "  batch 12 loss: [38.6519718170166, 0.014193229842931032]\n",
      "  batch 14 loss: [41.03801345825195, 0.011305246967822313]\n",
      "  batch 16 loss: [32.20140552520752, 0.01395415049046278]\n",
      "  batch 18 loss: [38.64699172973633, 0.015454236418008804]\n",
      "  batch 20 loss: [35.03285217285156, 0.006482102908194065]\n",
      "  batch 22 loss: [30.30824565887451, 0.019151528365910053]\n",
      "  batch 24 loss: [28.881319046020508, 0.028396816458553076]\n",
      "  batch 26 loss: [31.204012870788574, 0.04153209179639816]\n",
      "  batch 28 loss: [31.063087463378906, 0.017968829721212387]\n",
      "  batch 30 loss: [31.807100296020508, 0.030479006469249725]\n",
      "  batch 32 loss: [33.43327522277832, 0.052933919709175825]\n",
      "  batch 34 loss: [33.011802673339844, 0.023376050405204296]\n",
      "  batch 36 loss: [31.97349739074707, 0.1878795027732849]\n",
      "  batch 38 loss: [32.01295280456543, 0.00957465311512351]\n",
      "  batch 40 loss: [35.31451606750488, 0.02606647787615657]\n",
      "  batch 42 loss: [37.0534782409668, 0.03403576463460922]\n",
      "  batch 44 loss: [39.9503059387207, 0.02085274364799261]\n",
      "  batch 46 loss: [28.857563018798828, 0.019175443798303604]\n",
      "  batch 48 loss: [33.625450134277344, 0.043951574712991714]\n",
      "  batch 50 loss: [32.494534492492676, 0.011993046384304762]\n",
      "  batch 52 loss: [37.522369384765625, 0.01791790220886469]\n",
      "  batch 54 loss: [29.922606468200684, 0.011351719498634338]\n",
      "LOSS generator 29.922606468200684 discriminator 0.011351719498634338\n",
      "EPOCH 191:\n",
      "  batch 0 loss: [25.958126068115234, 0.009214171208441257]\n",
      "  batch 2 loss: [37.154229164123535, 0.03825017623603344]\n",
      "  batch 4 loss: [40.08344650268555, 0.009671308565884829]\n",
      "  batch 6 loss: [32.216952323913574, 0.09696358442306519]\n",
      "  batch 8 loss: [33.610761642456055, 0.05709833651781082]\n",
      "  batch 10 loss: [28.57544231414795, 0.02922090282663703]\n",
      "  batch 12 loss: [37.71105766296387, 0.02724952669814229]\n",
      "  batch 14 loss: [35.97268867492676, 0.015547809191048145]\n",
      "  batch 16 loss: [34.623735427856445, 0.016497117932885885]\n",
      "  batch 18 loss: [42.02475929260254, 0.09740446135401726]\n",
      "  batch 20 loss: [31.325451850891113, 0.026381722651422024]\n",
      "  batch 22 loss: [28.4461612701416, 0.08897871896624565]\n",
      "  batch 24 loss: [31.833434104919434, 0.06822473928332329]\n",
      "  batch 26 loss: [28.576340675354004, 0.0328862143214792]\n",
      "  batch 28 loss: [34.71907424926758, 0.018680325709283352]\n",
      "  batch 30 loss: [32.90957546234131, 0.008161303121596575]\n",
      "  batch 32 loss: [29.08307456970215, 0.048020441085100174]\n",
      "  batch 34 loss: [31.60860824584961, 0.035041261464357376]\n",
      "  batch 36 loss: [32.38981246948242, 0.14714594930410385]\n",
      "  batch 38 loss: [29.858736038208008, 0.30069927126169205]\n",
      "  batch 40 loss: [32.704023361206055, 0.46493008732795715]\n",
      "  batch 42 loss: [38.65696144104004, 0.5918089598417282]\n",
      "  batch 44 loss: [30.103835105895996, 1.2219099402427673]\n",
      "  batch 46 loss: [40.32521057128906, 2.345010221004486]\n",
      "  batch 48 loss: [38.699079513549805, 1.1930257678031921]\n",
      "  batch 50 loss: [34.017476081848145, 0.8226204216480255]\n",
      "  batch 52 loss: [29.729117393493652, 0.8786442875862122]\n",
      "  batch 54 loss: [38.4513053894043, 0.8578656017780304]\n",
      "LOSS generator 38.4513053894043 discriminator 0.8578656017780304\n",
      "EPOCH 192:\n",
      "  batch 0 loss: [30.869680404663086, 0.7294049263000488]\n",
      "  batch 2 loss: [25.65602970123291, 0.7552618086338043]\n",
      "  batch 4 loss: [35.43860626220703, 0.8524345755577087]\n",
      "  batch 6 loss: [39.0563850402832, 0.8310903608798981]\n",
      "  batch 8 loss: [33.60970592498779, 0.8493949174880981]\n",
      "  batch 10 loss: [28.952905654907227, 0.6318952739238739]\n",
      "  batch 12 loss: [29.57526683807373, 0.5271446704864502]\n",
      "  batch 14 loss: [27.764738082885742, 0.38504132628440857]\n",
      "  batch 16 loss: [32.15725326538086, 0.23999929428100586]\n",
      "  batch 18 loss: [33.14138412475586, 0.20161307603120804]\n",
      "  batch 20 loss: [28.30344009399414, 0.12289770320057869]\n",
      "  batch 22 loss: [27.38637065887451, 0.09639822691679001]\n",
      "  batch 24 loss: [33.201284408569336, 0.07523345574736595]\n",
      "  batch 26 loss: [24.571117401123047, 0.10701688006520271]\n",
      "  batch 28 loss: [30.00309467315674, 0.23218278586864471]\n",
      "  batch 30 loss: [29.40971088409424, 0.17595990002155304]\n",
      "  batch 32 loss: [32.08272075653076, 0.2800997346639633]\n",
      "  batch 34 loss: [32.98807144165039, 0.38128283619880676]\n",
      "  batch 36 loss: [34.54823875427246, 0.873757004737854]\n",
      "  batch 38 loss: [30.271353721618652, 0.26908327639102936]\n",
      "  batch 40 loss: [28.192424774169922, 0.1774599701166153]\n",
      "  batch 42 loss: [37.5496940612793, 0.06988945789635181]\n",
      "  batch 44 loss: [32.99061584472656, 0.04500936530530453]\n",
      "  batch 46 loss: [31.387348175048828, 0.06291524693369865]\n",
      "  batch 48 loss: [36.637481689453125, 0.06709412299096584]\n",
      "  batch 50 loss: [35.19495391845703, 0.06353461742401123]\n",
      "  batch 52 loss: [32.37887954711914, 0.0443155225366354]\n",
      "  batch 54 loss: [38.32478713989258, 0.05854947678744793]\n",
      "LOSS generator 38.32478713989258 discriminator 0.05854947678744793\n",
      "EPOCH 193:\n",
      "  batch 0 loss: [31.08851432800293, 0.026806512847542763]\n",
      "  batch 2 loss: [30.877559661865234, 0.03750709630548954]\n",
      "  batch 4 loss: [36.77186965942383, 0.028836744837462902]\n",
      "  batch 6 loss: [33.63850021362305, 0.04109448008239269]\n",
      "  batch 8 loss: [34.43056869506836, 0.03928456176072359]\n",
      "  batch 10 loss: [32.16833019256592, 0.013878898695111275]\n",
      "  batch 12 loss: [27.296985626220703, 0.0599488690495491]\n",
      "  batch 14 loss: [35.38021278381348, 0.034283063374459743]\n",
      "  batch 16 loss: [30.8341646194458, 0.08775479346513748]\n",
      "  batch 18 loss: [31.712190628051758, 0.04616076126694679]\n",
      "  batch 20 loss: [30.4017915725708, 0.4476918876171112]\n",
      "  batch 22 loss: [34.11484146118164, 0.5732776820659637]\n",
      "  batch 24 loss: [32.46489238739014, 0.42518095672130585]\n",
      "  batch 26 loss: [29.73463249206543, 0.6843520700931549]\n",
      "  batch 28 loss: [41.33694839477539, 0.15379244834184647]\n",
      "  batch 30 loss: [46.275535583496094, 0.28970613330602646]\n",
      "  batch 32 loss: [44.75998878479004, 0.3965778946876526]\n",
      "  batch 34 loss: [46.45851135253906, 0.34603293240070343]\n",
      "  batch 36 loss: [38.028656005859375, 0.2370825856924057]\n",
      "  batch 38 loss: [35.233924865722656, 0.08297175168991089]\n",
      "  batch 40 loss: [45.3734245300293, 0.11743367463350296]\n",
      "  batch 42 loss: [41.24009132385254, 0.11721703037619591]\n",
      "  batch 44 loss: [31.371529579162598, 0.09838921017944813]\n",
      "  batch 46 loss: [42.812910079956055, 0.05871943570673466]\n",
      "  batch 48 loss: [38.44008827209473, 0.03413735330104828]\n",
      "  batch 50 loss: [34.68146800994873, 0.08151490613818169]\n",
      "  batch 52 loss: [44.176557540893555, 0.15072891116142273]\n",
      "  batch 54 loss: [40.62174034118652, 0.010536151938140392]\n",
      "LOSS generator 40.62174034118652 discriminator 0.010536151938140392\n",
      "EPOCH 194:\n",
      "  batch 0 loss: [50.26239776611328, 0.10438872873783112]\n",
      "  batch 2 loss: [37.73518943786621, 0.05385410785675049]\n",
      "  batch 4 loss: [33.10716438293457, 0.10358989611268044]\n",
      "  batch 6 loss: [40.6124382019043, 0.15197293367236853]\n",
      "  batch 8 loss: [51.27514839172363, 0.10136558674275875]\n",
      "  batch 10 loss: [38.57147789001465, 0.047649089246988297]\n",
      "  batch 12 loss: [45.263465881347656, 0.012878084555268288]\n",
      "  batch 14 loss: [37.49497413635254, 0.020655542612075806]\n",
      "  batch 16 loss: [37.809024810791016, 0.017837786115705967]\n",
      "  batch 18 loss: [39.13972854614258, 0.052184016443789005]\n",
      "  batch 20 loss: [43.13543510437012, 0.006470831576734781]\n",
      "  batch 22 loss: [36.15846633911133, 0.02264585066586733]\n",
      "  batch 24 loss: [43.09611511230469, 0.02059343084692955]\n",
      "  batch 26 loss: [32.7224645614624, 0.021320882253348827]\n",
      "  batch 28 loss: [41.48243522644043, 0.028837280347943306]\n",
      "  batch 30 loss: [40.87154960632324, 0.026994864456355572]\n",
      "  batch 32 loss: [33.508124351501465, 0.03450603969395161]\n",
      "  batch 34 loss: [45.22012710571289, 0.02880239672958851]\n",
      "  batch 36 loss: [39.30281448364258, 0.04917966527864337]\n",
      "  batch 38 loss: [34.73691272735596, 1.1799886524677277]\n",
      "  batch 40 loss: [35.311241149902344, 2.432977795600891]\n",
      "  batch 42 loss: [32.43841552734375, 0.9547567963600159]\n",
      "  batch 44 loss: [28.16557025909424, 1.0171692371368408]\n",
      "  batch 46 loss: [39.30254554748535, 0.7226095199584961]\n",
      "  batch 48 loss: [45.59495735168457, 1.0302035808563232]\n",
      "  batch 50 loss: [35.19559669494629, 0.6009817123413086]\n",
      "  batch 52 loss: [33.494049072265625, 0.3171631842851639]\n",
      "  batch 54 loss: [37.97831153869629, 0.33840450644493103]\n",
      "LOSS generator 37.97831153869629 discriminator 0.33840450644493103\n",
      "EPOCH 195:\n",
      "  batch 0 loss: [25.447397232055664, 0.50958251953125]\n",
      "  batch 2 loss: [26.467097282409668, 0.4210372418165207]\n",
      "  batch 4 loss: [29.828742027282715, 0.44951173663139343]\n",
      "  batch 6 loss: [21.531551361083984, 0.4245418310165405]\n",
      "  batch 8 loss: [33.83670234680176, 0.374140202999115]\n",
      "  batch 10 loss: [36.12359809875488, 0.23600949347019196]\n",
      "  batch 12 loss: [26.79907989501953, 0.3139764666557312]\n",
      "  batch 14 loss: [32.902156829833984, 0.19548427313566208]\n",
      "  batch 16 loss: [29.00043773651123, 0.25529951602220535]\n",
      "  batch 18 loss: [28.468608856201172, 0.3002794086933136]\n",
      "  batch 20 loss: [31.996660232543945, 0.09921850264072418]\n",
      "  batch 22 loss: [30.42959213256836, 0.2809460610151291]\n",
      "  batch 24 loss: [32.07331085205078, 0.16868669912219048]\n",
      "  batch 26 loss: [35.481611251831055, 0.3293142765760422]\n",
      "  batch 28 loss: [27.996073722839355, 0.22108285129070282]\n",
      "  batch 30 loss: [35.76373100280762, 0.38084182143211365]\n",
      "  batch 32 loss: [36.15939140319824, 0.4517187476158142]\n",
      "  batch 34 loss: [30.071971893310547, 0.38469603657722473]\n",
      "  batch 36 loss: [29.1086368560791, 0.4257894456386566]\n",
      "  batch 38 loss: [29.849224090576172, 0.6539538204669952]\n",
      "  batch 40 loss: [33.668089866638184, 0.4040287435054779]\n",
      "  batch 42 loss: [34.524314880371094, 0.3026804029941559]\n",
      "  batch 44 loss: [28.622051239013672, 0.43425223231315613]\n",
      "  batch 46 loss: [32.03803539276123, 0.40817467868328094]\n",
      "  batch 48 loss: [25.88737392425537, 0.5177627056837082]\n",
      "  batch 50 loss: [37.16545867919922, 0.3665558099746704]\n",
      "  batch 52 loss: [31.385228157043457, 0.7478897571563721]\n",
      "  batch 54 loss: [35.76633644104004, 0.5251494944095612]\n",
      "LOSS generator 35.76633644104004 discriminator 0.5251494944095612\n",
      "EPOCH 196:\n",
      "  batch 0 loss: [30.336387634277344, 0.4679492712020874]\n",
      "  batch 2 loss: [33.27903747558594, 0.564467042684555]\n",
      "  batch 4 loss: [37.582733154296875, 0.32285889983177185]\n",
      "  batch 6 loss: [28.004334449768066, 0.5514953285455704]\n",
      "  batch 8 loss: [27.916558265686035, 0.37419289350509644]\n",
      "  batch 10 loss: [36.68088722229004, 0.3625127375125885]\n",
      "  batch 12 loss: [28.127291679382324, 0.4224335700273514]\n",
      "  batch 14 loss: [32.36971378326416, 0.4394165873527527]\n",
      "  batch 16 loss: [26.048333168029785, 0.3127867877483368]\n",
      "  batch 18 loss: [25.434353828430176, 0.26846107840538025]\n",
      "  batch 20 loss: [30.29935359954834, 0.16305869072675705]\n",
      "  batch 22 loss: [29.395724296569824, 0.14596614986658096]\n",
      "  batch 24 loss: [36.51319599151611, 0.14331256970763206]\n",
      "  batch 26 loss: [33.964487075805664, 0.22351907193660736]\n",
      "  batch 28 loss: [32.362260818481445, 0.10696335881948471]\n",
      "  batch 30 loss: [33.49904155731201, 0.11859881691634655]\n",
      "  batch 32 loss: [33.0147705078125, 0.03209036774933338]\n",
      "  batch 34 loss: [30.245609283447266, 0.0629741195589304]\n",
      "  batch 36 loss: [30.072002410888672, 0.09005957841873169]\n",
      "  batch 38 loss: [31.4384765625, 0.04810623824596405]\n",
      "  batch 40 loss: [33.79524898529053, 0.02031028689816594]\n",
      "  batch 42 loss: [38.348716735839844, 0.06884372420608997]\n",
      "  batch 44 loss: [38.4964714050293, 0.027701979968696833]\n",
      "  batch 46 loss: [31.37164878845215, 0.028568169102072716]\n",
      "  batch 48 loss: [30.47358512878418, 0.03822833625599742]\n",
      "  batch 50 loss: [40.00149154663086, 0.01435120776295662]\n",
      "  batch 52 loss: [32.970736503601074, 0.04694874957203865]\n",
      "  batch 54 loss: [31.76314353942871, 0.062037430703639984]\n",
      "LOSS generator 31.76314353942871 discriminator 0.062037430703639984\n",
      "EPOCH 197:\n",
      "  batch 0 loss: [28.687000274658203, 0.027710705995559692]\n",
      "  batch 2 loss: [32.51077079772949, 0.039403933100402355]\n",
      "  batch 4 loss: [31.725082397460938, 0.06793438456952572]\n",
      "  batch 6 loss: [34.77792549133301, 0.029413559474051]\n",
      "  batch 8 loss: [33.76028823852539, 0.016433708369731903]\n",
      "  batch 10 loss: [29.515673637390137, 0.15437225624918938]\n",
      "  batch 12 loss: [37.24689865112305, 0.02186405658721924]\n",
      "  batch 14 loss: [34.1837158203125, 0.039384638890624046]\n",
      "  batch 16 loss: [29.468666076660156, 0.07502663135528564]\n",
      "  batch 18 loss: [27.411945343017578, 0.03338771220296621]\n",
      "  batch 20 loss: [36.80111122131348, 0.05669250898063183]\n",
      "  batch 22 loss: [42.23750305175781, 0.05539490096271038]\n",
      "  batch 24 loss: [38.20293426513672, 0.01487133838236332]\n",
      "  batch 26 loss: [29.231677055358887, 0.08173634670674801]\n",
      "  batch 28 loss: [33.9066219329834, 0.03897383622825146]\n",
      "  batch 30 loss: [33.8914794921875, 0.03036981518380344]\n",
      "  batch 32 loss: [32.59824752807617, 0.057379967998713255]\n",
      "  batch 34 loss: [32.906386375427246, 0.08121902495622635]\n",
      "  batch 36 loss: [32.21065616607666, 0.05881059169769287]\n",
      "  batch 38 loss: [36.93697929382324, 0.03324207291007042]\n",
      "  batch 40 loss: [36.347042083740234, 0.05050228722393513]\n",
      "  batch 42 loss: [31.66551113128662, 0.014980637817643583]\n",
      "  batch 44 loss: [39.2828426361084, 0.03512972453609109]\n",
      "  batch 46 loss: [31.096205711364746, 0.04766846727579832]\n",
      "  batch 48 loss: [32.91337203979492, 0.007665951270610094]\n",
      "  batch 50 loss: [39.345733642578125, 0.033813754096627235]\n",
      "  batch 52 loss: [35.53364181518555, 0.010551222832873464]\n",
      "  batch 54 loss: [29.571489334106445, 0.04034939967095852]\n",
      "LOSS generator 29.571489334106445 discriminator 0.04034939967095852\n",
      "EPOCH 198:\n",
      "  batch 0 loss: [41.74412536621094, 0.02427208609879017]\n",
      "  batch 2 loss: [34.521968841552734, 0.035381180234253407]\n",
      "  batch 4 loss: [31.076701164245605, 0.037901658564805984]\n",
      "  batch 6 loss: [33.00350475311279, 0.062443952076137066]\n",
      "  batch 8 loss: [28.859902381896973, 0.036565447226166725]\n",
      "  batch 10 loss: [35.39491844177246, 0.017399088479578495]\n",
      "  batch 12 loss: [35.11615562438965, 0.023637471254915]\n",
      "  batch 14 loss: [33.81066703796387, 0.0178686436265707]\n",
      "  batch 16 loss: [33.856539726257324, 0.011156810447573662]\n",
      "  batch 18 loss: [36.93721008300781, 0.03202194720506668]\n",
      "  batch 20 loss: [33.907827377319336, 0.019052259624004364]\n",
      "  batch 22 loss: [34.051496505737305, 0.05111074820160866]\n",
      "  batch 24 loss: [32.97016525268555, 0.10934766754508018]\n",
      "  batch 26 loss: [32.85053062438965, 0.02992654126137495]\n",
      "  batch 28 loss: [37.121877670288086, 0.07221332937479019]\n",
      "  batch 30 loss: [31.050881385803223, 0.031270106323063374]\n",
      "  batch 32 loss: [34.698039054870605, 0.04275856167078018]\n",
      "  batch 34 loss: [29.97490119934082, 0.18267328292131424]\n",
      "  batch 36 loss: [31.09203338623047, 0.2154037281870842]\n",
      "  batch 38 loss: [32.04715347290039, 0.07952754385769367]\n",
      "  batch 40 loss: [37.99616050720215, 0.07899845764040947]\n",
      "  batch 42 loss: [33.4318208694458, 0.2221866026520729]\n",
      "  batch 44 loss: [34.751304626464844, 0.03320304024964571]\n",
      "  batch 46 loss: [32.18540573120117, 0.031146650202572346]\n",
      "  batch 48 loss: [28.27210807800293, 0.10659798234701157]\n",
      "  batch 50 loss: [28.839787483215332, 0.30168473720550537]\n",
      "  batch 52 loss: [33.80183410644531, 0.1383170336484909]\n",
      "  batch 54 loss: [37.276323318481445, 0.0945449098944664]\n",
      "LOSS generator 37.276323318481445 discriminator 0.0945449098944664\n",
      "EPOCH 199:\n",
      "  batch 0 loss: [39.62274169921875, 0.12090214341878891]\n",
      "  batch 2 loss: [28.635534286499023, 0.46433350443840027]\n",
      "  batch 4 loss: [34.444580078125, 0.35736072808504105]\n",
      "  batch 6 loss: [30.162035942077637, 0.31352104246616364]\n",
      "  batch 8 loss: [26.713263511657715, 0.08560550957918167]\n",
      "  batch 10 loss: [29.855329513549805, 0.13782649114727974]\n",
      "  batch 12 loss: [34.046152114868164, 0.1017422191798687]\n",
      "  batch 14 loss: [36.20339393615723, 0.05268273875117302]\n",
      "  batch 16 loss: [30.86600399017334, 0.055085303261876106]\n",
      "  batch 18 loss: [28.37514877319336, 0.03373540751636028]\n",
      "  batch 20 loss: [34.086809158325195, 0.009933258406817913]\n",
      "  batch 22 loss: [34.095590591430664, 0.04896686226129532]\n",
      "  batch 24 loss: [34.89326858520508, 0.010847561294212937]\n",
      "  batch 26 loss: [36.6979398727417, 0.03621634840965271]\n",
      "  batch 28 loss: [32.67367649078369, 0.039068521931767464]\n",
      "  batch 30 loss: [30.524078369140625, 0.014745599590241909]\n",
      "  batch 32 loss: [28.897390365600586, 0.013643458485603333]\n",
      "  batch 34 loss: [43.868289947509766, 0.04526808485388756]\n",
      "  batch 36 loss: [31.849404335021973, 0.10167282819747925]\n",
      "  batch 38 loss: [33.71855926513672, 0.05585962883196771]\n",
      "  batch 40 loss: [29.361751556396484, 0.10066382214426994]\n",
      "  batch 42 loss: [32.087852478027344, 0.08189185708761215]\n",
      "  batch 44 loss: [32.70611763000488, 0.07949963584542274]\n",
      "  batch 46 loss: [36.775306701660156, 0.05811711214482784]\n",
      "  batch 48 loss: [34.87503528594971, 0.019760065712034702]\n",
      "  batch 50 loss: [35.758527755737305, 0.008797328220680356]\n",
      "  batch 52 loss: [35.96837043762207, 0.021803682669997215]\n",
      "  batch 54 loss: [33.034836769104004, 0.06101940758526325]\n",
      "LOSS generator 33.034836769104004 discriminator 0.06101940758526325\n",
      "EPOCH 200:\n",
      "  batch 0 loss: [33.021358489990234, 0.05544590204954147]\n",
      "  batch 2 loss: [34.133201599121094, 0.014158807694911957]\n",
      "  batch 4 loss: [31.316871643066406, 0.052143458276987076]\n",
      "  batch 6 loss: [32.014899253845215, 0.017193425446748734]\n",
      "  batch 8 loss: [36.83689498901367, 0.008714881259948015]\n",
      "  batch 10 loss: [33.17520618438721, 0.019678425043821335]\n",
      "  batch 12 loss: [37.05343818664551, 0.04405749402940273]\n",
      "  batch 14 loss: [35.381399154663086, 0.01350894826464355]\n",
      "  batch 16 loss: [37.30908012390137, 0.019414781825616956]\n",
      "  batch 18 loss: [31.080299377441406, 0.03271368332207203]\n",
      "  batch 20 loss: [32.71111869812012, 0.007165750488638878]\n",
      "  batch 22 loss: [38.68083381652832, 0.035160398576408625]\n",
      "  batch 24 loss: [32.51453971862793, 0.02479153499007225]\n",
      "  batch 26 loss: [32.81211853027344, 0.01841654535382986]\n",
      "  batch 28 loss: [37.56561851501465, 0.07055831328034401]\n",
      "  batch 30 loss: [35.480186462402344, 0.05615989863872528]\n",
      "  batch 32 loss: [34.94362258911133, 0.02557182777673006]\n",
      "  batch 34 loss: [34.166744232177734, 0.03280833177268505]\n",
      "  batch 36 loss: [30.715667724609375, 0.1873662257567048]\n",
      "  batch 38 loss: [37.42200469970703, 0.13106746971607208]\n",
      "  batch 40 loss: [31.35458755493164, 0.11565625295042992]\n",
      "  batch 42 loss: [32.27570724487305, 0.03261033911257982]\n",
      "  batch 44 loss: [33.026939392089844, 0.01723544020205736]\n",
      "  batch 46 loss: [28.18090534210205, 0.07220831234008074]\n",
      "  batch 48 loss: [36.136714935302734, 0.03322542365640402]\n",
      "  batch 50 loss: [28.944636344909668, 0.07024853676557541]\n",
      "  batch 52 loss: [29.992294311523438, 0.026569390669465065]\n",
      "  batch 54 loss: [31.906862258911133, 0.028995437547564507]\n",
      "LOSS generator 31.906862258911133 discriminator 0.028995437547564507\n",
      "EPOCH 201:\n",
      "  batch 0 loss: [30.095298767089844, 0.019111385568976402]\n",
      "  batch 2 loss: [36.1024284362793, 0.022785373032093048]\n",
      "  batch 4 loss: [33.04465866088867, 0.008285741088911891]\n",
      "  batch 6 loss: [35.88575553894043, 0.015786664094775915]\n",
      "  batch 8 loss: [33.172040939331055, 0.027387991547584534]\n",
      "  batch 10 loss: [33.95022964477539, 0.04141273186542094]\n",
      "  batch 12 loss: [39.8918342590332, 0.032908289693295956]\n",
      "  batch 14 loss: [39.36452865600586, 0.01063994923606515]\n",
      "  batch 16 loss: [32.09699058532715, 0.14419412426650524]\n",
      "  batch 18 loss: [39.240888595581055, 0.01280434732325375]\n",
      "  batch 20 loss: [40.48183822631836, 0.035085088573396206]\n",
      "  batch 22 loss: [32.55476760864258, 0.03561285464093089]\n",
      "  batch 24 loss: [30.39670753479004, 0.014058342203497887]\n",
      "  batch 26 loss: [39.58913612365723, 0.00933176081161946]\n",
      "  batch 28 loss: [36.82936477661133, 0.018300330266356468]\n",
      "  batch 30 loss: [31.335732460021973, 0.05254577845335007]\n",
      "  batch 32 loss: [33.97310256958008, 0.015871006064116955]\n",
      "  batch 34 loss: [32.66927433013916, 0.01653648354113102]\n",
      "  batch 36 loss: [30.844972610473633, 0.01332542346790433]\n",
      "  batch 38 loss: [28.204195022583008, 0.045640695840120316]\n",
      "  batch 40 loss: [37.22165107727051, 0.032616524025797844]\n",
      "  batch 42 loss: [34.042545318603516, 0.01807030662894249]\n",
      "  batch 44 loss: [34.71091842651367, 0.01648623589426279]\n",
      "  batch 46 loss: [29.0521183013916, 0.04503234289586544]\n",
      "  batch 48 loss: [32.752187728881836, 0.012987796682864428]\n",
      "  batch 50 loss: [28.572710037231445, 0.020993859972804785]\n",
      "  batch 52 loss: [31.892505645751953, 0.042471641674637794]\n",
      "  batch 54 loss: [29.82378387451172, 0.014441588195040822]\n",
      "LOSS generator 29.82378387451172 discriminator 0.014441588195040822\n",
      "EPOCH 202:\n",
      "  batch 0 loss: [25.565242767333984, 0.02185111679136753]\n",
      "  batch 2 loss: [29.368130683898926, 0.14535291260108352]\n",
      "  batch 4 loss: [31.696526527404785, 0.032554470002651215]\n",
      "  batch 6 loss: [42.36460304260254, 0.037879422307014465]\n",
      "  batch 8 loss: [44.91021919250488, 0.02657630667090416]\n",
      "  batch 10 loss: [35.127004623413086, 0.035178378224372864]\n",
      "  batch 12 loss: [36.61519813537598, 0.04661411605775356]\n",
      "  batch 14 loss: [31.543251037597656, 0.017526011914014816]\n",
      "  batch 16 loss: [33.92487144470215, 0.010306157637387514]\n",
      "  batch 18 loss: [33.334848403930664, 0.012563740834593773]\n",
      "  batch 20 loss: [36.67197608947754, 0.04768041428178549]\n",
      "  batch 22 loss: [34.03041458129883, 0.014299454167485237]\n",
      "  batch 24 loss: [34.25500679016113, 0.005706120748072863]\n",
      "  batch 26 loss: [31.834260940551758, 0.018392042256891727]\n",
      "  batch 28 loss: [36.49255180358887, 0.02238792832940817]\n",
      "  batch 30 loss: [33.881789207458496, 0.01391344889998436]\n",
      "  batch 32 loss: [36.369380950927734, 0.031799052841961384]\n",
      "  batch 34 loss: [35.522186279296875, 0.03537496738135815]\n",
      "  batch 36 loss: [32.511741638183594, 0.013554338132962584]\n",
      "  batch 38 loss: [29.16313362121582, 0.023719217628240585]\n",
      "  batch 40 loss: [31.07516098022461, 0.018062254413962364]\n",
      "  batch 42 loss: [33.543649673461914, 0.01356072211638093]\n",
      "  batch 44 loss: [37.34959030151367, 0.023201446048915386]\n",
      "  batch 46 loss: [35.37814712524414, 0.009320550132542849]\n",
      "  batch 48 loss: [32.787010192871094, 0.012484670616686344]\n",
      "  batch 50 loss: [35.36059761047363, 0.0042536386754363775]\n",
      "  batch 52 loss: [32.52639579772949, 0.007583222584798932]\n",
      "  batch 54 loss: [34.21709442138672, 0.017350144684314728]\n",
      "LOSS generator 34.21709442138672 discriminator 0.017350144684314728\n",
      "EPOCH 203:\n",
      "  batch 0 loss: [25.87225914001465, 0.1979554295539856]\n",
      "  batch 2 loss: [37.79265022277832, 0.07122967764735222]\n",
      "  batch 4 loss: [38.26176643371582, 0.016325815115123987]\n",
      "  batch 6 loss: [29.90359878540039, 0.013935365714132786]\n",
      "  batch 8 loss: [33.31174850463867, 0.011621479410678148]\n",
      "  batch 10 loss: [31.88302993774414, 0.011431836290284991]\n",
      "  batch 12 loss: [38.42110824584961, 0.008822701871395111]\n",
      "  batch 14 loss: [37.38208198547363, 0.029524831101298332]\n",
      "  batch 16 loss: [33.99065399169922, 0.020841576159000397]\n",
      "  batch 18 loss: [37.62055015563965, 0.0224524918012321]\n",
      "  batch 20 loss: [32.44247055053711, 0.01168323727324605]\n",
      "  batch 22 loss: [33.73929977416992, 0.005658706650137901]\n",
      "  batch 24 loss: [36.126070976257324, 0.011302320985123515]\n",
      "  batch 26 loss: [30.861547470092773, 0.009642774239182472]\n",
      "  batch 28 loss: [32.89661502838135, 0.06677340064197779]\n",
      "  batch 30 loss: [36.38054084777832, 0.052516400814056396]\n",
      "  batch 32 loss: [28.745145797729492, 0.09718388691544533]\n",
      "  batch 34 loss: [30.7671480178833, 0.01992701832205057]\n",
      "  batch 36 loss: [33.655625343322754, 0.03887278027832508]\n",
      "  batch 38 loss: [31.53590965270996, 0.02072008652612567]\n",
      "  batch 40 loss: [37.23946189880371, 0.025769961532205343]\n",
      "  batch 42 loss: [31.341124534606934, 0.0265515623614192]\n",
      "  batch 44 loss: [37.486188888549805, 0.01812131702899933]\n",
      "  batch 46 loss: [35.62656784057617, 0.015144138364121318]\n",
      "  batch 48 loss: [28.956193923950195, 0.020117146894335747]\n",
      "  batch 50 loss: [38.49697494506836, 0.01024092617444694]\n",
      "  batch 52 loss: [31.678961753845215, 0.016642342321574688]\n",
      "  batch 54 loss: [33.590871810913086, 0.006388006266206503]\n",
      "LOSS generator 33.590871810913086 discriminator 0.006388006266206503\n",
      "EPOCH 204:\n",
      "  batch 0 loss: [34.32638931274414, 0.0069967289455235004]\n",
      "  batch 2 loss: [29.8379487991333, 0.012078871484845877]\n",
      "  batch 4 loss: [36.84794521331787, 0.05051374435424805]\n",
      "  batch 6 loss: [33.63197422027588, 0.00984634505584836]\n",
      "  batch 8 loss: [35.48926258087158, 0.008275346364825964]\n",
      "  batch 10 loss: [31.424501419067383, 0.014894297812134027]\n",
      "  batch 12 loss: [31.60898208618164, 0.017278671264648438]\n",
      "  batch 14 loss: [36.01609420776367, 0.025770406238734722]\n",
      "  batch 16 loss: [36.551025390625, 0.051944345235824585]\n",
      "  batch 18 loss: [35.58004188537598, 0.07122060097754002]\n",
      "  batch 20 loss: [31.805490493774414, 0.01021744217723608]\n",
      "  batch 22 loss: [31.898262977600098, 0.008215252310037613]\n",
      "  batch 24 loss: [34.50826644897461, 0.020691504701972008]\n",
      "  batch 26 loss: [32.8623046875, 0.008917019935324788]\n",
      "  batch 28 loss: [31.663259506225586, 0.01133390236645937]\n",
      "  batch 30 loss: [39.296010971069336, 0.03788081312086433]\n",
      "  batch 32 loss: [34.280391693115234, 0.10481863841414452]\n",
      "  batch 34 loss: [25.141664505004883, 0.0748769287019968]\n",
      "  batch 36 loss: [30.185161590576172, 1.1776000261306763]\n",
      "  batch 38 loss: [30.773818969726562, 0.9057924747467041]\n",
      "  batch 40 loss: [26.293720245361328, 0.5985497683286667]\n",
      "  batch 42 loss: [29.18316078186035, 0.335465207695961]\n",
      "  batch 44 loss: [39.36167907714844, 0.16826589405536652]\n",
      "  batch 46 loss: [35.46274948120117, 0.10641985386610031]\n",
      "  batch 48 loss: [28.837299346923828, 0.1214575469493866]\n",
      "  batch 50 loss: [32.49975395202637, 0.06562790647149086]\n",
      "  batch 52 loss: [33.34344673156738, 0.03861854039132595]\n",
      "  batch 54 loss: [33.421146392822266, 0.12899749353528023]\n",
      "LOSS generator 33.421146392822266 discriminator 0.12899749353528023\n",
      "EPOCH 205:\n",
      "  batch 0 loss: [38.94834518432617, 0.0752626359462738]\n",
      "  batch 2 loss: [37.90277099609375, 0.046067818999290466]\n",
      "  batch 4 loss: [22.99491024017334, 0.36089514195919037]\n",
      "  batch 6 loss: [31.115554809570312, 0.4758940413594246]\n",
      "  batch 8 loss: [28.541661262512207, 0.34466540813446045]\n",
      "  batch 10 loss: [28.32870101928711, 0.20256302878260612]\n",
      "  batch 12 loss: [31.522088050842285, 0.14604666084051132]\n",
      "  batch 14 loss: [37.01036834716797, 0.07610864192247391]\n",
      "  batch 16 loss: [25.436904907226562, 0.13794269412755966]\n",
      "  batch 18 loss: [35.42409896850586, 0.1399259939789772]\n",
      "  batch 20 loss: [30.432035446166992, 0.08125850930809975]\n",
      "  batch 22 loss: [36.30831336975098, 0.02709681261330843]\n",
      "  batch 24 loss: [33.48811149597168, 0.046183290891349316]\n",
      "  batch 26 loss: [32.69282150268555, 0.052375391125679016]\n",
      "  batch 28 loss: [32.56850051879883, 0.036530593410134315]\n",
      "  batch 30 loss: [34.473806381225586, 0.007843594532459974]\n",
      "  batch 32 loss: [36.800785064697266, 0.029134800657629967]\n",
      "  batch 34 loss: [30.476308822631836, 0.03160868678241968]\n",
      "  batch 36 loss: [37.13787841796875, 0.011549617629498243]\n",
      "  batch 38 loss: [36.32051086425781, 0.027535177767276764]\n",
      "  batch 40 loss: [37.30427551269531, 0.02500433847308159]\n",
      "  batch 42 loss: [35.03474807739258, 0.01569317141547799]\n",
      "  batch 44 loss: [30.64042854309082, 0.02796244155615568]\n",
      "  batch 46 loss: [34.08756065368652, 0.10077721206471324]\n",
      "  batch 48 loss: [32.81931781768799, 0.04515129909850657]\n",
      "  batch 50 loss: [34.357229232788086, 0.031084982678294182]\n",
      "  batch 52 loss: [31.588123321533203, 0.018299919087439775]\n",
      "  batch 54 loss: [30.53305149078369, 0.05951785296201706]\n",
      "LOSS generator 30.53305149078369 discriminator 0.05951785296201706\n",
      "EPOCH 206:\n",
      "  batch 0 loss: [29.762508392333984, 0.14203114807605743]\n",
      "  batch 2 loss: [39.139625549316406, 0.03700306452810764]\n",
      "  batch 4 loss: [29.031190872192383, 0.046410076320171356]\n",
      "  batch 6 loss: [33.830848693847656, 0.02115793339908123]\n",
      "  batch 8 loss: [33.871089935302734, 0.011761246249079704]\n",
      "  batch 10 loss: [31.691229820251465, 0.01640394888818264]\n",
      "  batch 12 loss: [37.4052677154541, 0.010098912753164768]\n",
      "  batch 14 loss: [37.53021049499512, 0.041294895112514496]\n",
      "  batch 16 loss: [35.55336380004883, 0.021498648449778557]\n",
      "  batch 18 loss: [31.944069862365723, 0.017448716796934605]\n",
      "  batch 20 loss: [32.69180488586426, 0.03906352911144495]\n",
      "  batch 22 loss: [39.11088752746582, 0.013130598701536655]\n",
      "  batch 24 loss: [38.99089241027832, 0.031246387399733067]\n",
      "  batch 26 loss: [32.42435836791992, 0.023249135352671146]\n",
      "  batch 28 loss: [35.225810050964355, 0.035807088017463684]\n",
      "  batch 30 loss: [34.925209045410156, 0.043706417083740234]\n",
      "  batch 32 loss: [29.11051845550537, 0.08046547323465347]\n",
      "  batch 34 loss: [36.025590896606445, 0.021252532955259085]\n",
      "  batch 36 loss: [29.62871265411377, 0.02306638192385435]\n",
      "  batch 38 loss: [31.79593849182129, 0.032701547257602215]\n",
      "  batch 40 loss: [36.71453666687012, 0.029947915114462376]\n",
      "  batch 42 loss: [38.09954071044922, 0.014216107316315174]\n",
      "  batch 44 loss: [33.00852012634277, 0.009245362249203026]\n",
      "  batch 46 loss: [35.90991401672363, 0.015039477497339249]\n",
      "  batch 48 loss: [33.034605979919434, 0.03730659931898117]\n",
      "  batch 50 loss: [33.985374450683594, 0.004065555054694414]\n",
      "  batch 52 loss: [26.86463451385498, 0.06184995546936989]\n",
      "  batch 54 loss: [31.39158821105957, 0.04082104377448559]\n",
      "LOSS generator 31.39158821105957 discriminator 0.04082104377448559\n",
      "EPOCH 207:\n",
      "  batch 0 loss: [29.74197769165039, 0.005494114942848682]\n",
      "  batch 2 loss: [34.35913276672363, 0.015000633429735899]\n",
      "  batch 4 loss: [33.09209442138672, 0.061081413179636]\n",
      "  batch 6 loss: [28.76095485687256, 0.030899887904524803]\n",
      "  batch 8 loss: [37.465314865112305, 0.030703316442668438]\n",
      "  batch 10 loss: [38.661678314208984, 0.024499186547473073]\n",
      "  batch 12 loss: [34.33518981933594, 0.00899176369421184]\n",
      "  batch 14 loss: [37.31501388549805, 0.007915453054010868]\n",
      "  batch 16 loss: [34.63686561584473, 0.024868492037057877]\n",
      "  batch 18 loss: [30.514540672302246, 0.05565222166478634]\n",
      "  batch 20 loss: [32.86274814605713, 0.011787123163230717]\n",
      "  batch 22 loss: [29.13680362701416, 0.013077965006232262]\n",
      "  batch 24 loss: [36.01428031921387, 0.010753067093901336]\n",
      "  batch 26 loss: [35.61103439331055, 0.011522458866238594]\n",
      "  batch 28 loss: [37.6601619720459, 0.02407295862212777]\n",
      "  batch 30 loss: [32.86883354187012, 0.0078407300170511]\n",
      "  batch 32 loss: [26.784205436706543, 0.13677262607961893]\n",
      "  batch 34 loss: [36.57795715332031, 0.002703527337871492]\n",
      "  batch 36 loss: [32.12624454498291, 0.016024932265281677]\n",
      "  batch 38 loss: [38.0211238861084, 0.04166440665721893]\n",
      "  batch 40 loss: [38.7225341796875, 0.023815136402845383]\n",
      "  batch 42 loss: [39.25564002990723, 0.030966060236096382]\n",
      "  batch 44 loss: [36.105852127075195, 0.014134038239717484]\n",
      "  batch 46 loss: [36.35780143737793, 0.007871589856222272]\n",
      "  batch 48 loss: [32.39122295379639, 0.029411137104034424]\n",
      "  batch 50 loss: [36.58747673034668, 0.017099205870181322]\n",
      "  batch 52 loss: [32.02063751220703, 0.01109318365342915]\n",
      "  batch 54 loss: [32.08866024017334, 0.019881397718563676]\n",
      "LOSS generator 32.08866024017334 discriminator 0.019881397718563676\n",
      "EPOCH 208:\n",
      "  batch 0 loss: [34.59724426269531, 0.003002666402608156]\n",
      "  batch 2 loss: [30.015700340270996, 0.04564895434305072]\n",
      "  batch 4 loss: [33.201011657714844, 0.007139372872188687]\n",
      "  batch 6 loss: [28.502822875976562, 0.02317253313958645]\n",
      "  batch 8 loss: [31.626178741455078, 0.055084499064832926]\n",
      "  batch 10 loss: [31.902188301086426, 0.01524483086541295]\n",
      "  batch 12 loss: [44.711830139160156, 0.060811666771769524]\n",
      "  batch 14 loss: [36.726646423339844, 0.024001614190638065]\n",
      "  batch 16 loss: [39.94750213623047, 0.016908036544919014]\n",
      "  batch 18 loss: [33.31516361236572, 0.031848931685090065]\n",
      "  batch 20 loss: [37.64871788024902, 0.028621772304177284]\n",
      "  batch 22 loss: [34.2043399810791, 0.007493328768759966]\n",
      "  batch 24 loss: [35.20210075378418, 0.03426027670502663]\n",
      "  batch 26 loss: [35.29234504699707, 0.012886200565844774]\n",
      "  batch 28 loss: [30.898015022277832, 0.10298814345151186]\n",
      "  batch 30 loss: [37.318071365356445, 0.008945466950535774]\n",
      "  batch 32 loss: [32.97159004211426, 0.00876766536384821]\n",
      "  batch 34 loss: [33.48067092895508, 0.01771597540937364]\n",
      "  batch 36 loss: [32.02242851257324, 0.02425214182585478]\n",
      "  batch 38 loss: [36.98678779602051, 0.006082409061491489]\n",
      "  batch 40 loss: [38.00202560424805, 0.00903963134624064]\n",
      "  batch 42 loss: [34.65175437927246, 0.014785961480811238]\n",
      "  batch 44 loss: [32.15719032287598, 0.030883103609085083]\n",
      "  batch 46 loss: [30.520336151123047, 0.02389508904889226]\n",
      "  batch 48 loss: [30.488019943237305, 0.026474968064576387]\n",
      "  batch 50 loss: [35.14961242675781, 0.016075370367616415]\n",
      "  batch 52 loss: [37.230584144592285, 0.005833723582327366]\n",
      "  batch 54 loss: [32.080763816833496, 0.008194950176402926]\n",
      "LOSS generator 32.080763816833496 discriminator 0.008194950176402926\n",
      "EPOCH 209:\n",
      "  batch 0 loss: [38.04618835449219, 0.0016643512062728405]\n",
      "  batch 2 loss: [40.33536148071289, 0.017191610764712095]\n",
      "  batch 4 loss: [29.463607788085938, 0.014011616120114923]\n",
      "  batch 6 loss: [35.55486297607422, 0.009914629394188523]\n",
      "  batch 8 loss: [29.54587745666504, 0.013407024554908276]\n",
      "  batch 10 loss: [37.6486759185791, 0.023047986440360546]\n",
      "  batch 12 loss: [33.80886459350586, 0.015473013510927558]\n",
      "  batch 14 loss: [35.096641540527344, 0.005770625895820558]\n",
      "  batch 16 loss: [39.217803955078125, 0.01581462938338518]\n",
      "  batch 18 loss: [37.329551696777344, 0.004927506321109831]\n",
      "  batch 20 loss: [35.2887020111084, 0.005098393769003451]\n",
      "  batch 22 loss: [30.90714454650879, 0.0077397702261805534]\n",
      "  batch 24 loss: [32.58405303955078, 0.005970693891867995]\n",
      "  batch 26 loss: [30.112422943115234, 0.03161344490945339]\n",
      "  batch 28 loss: [25.489877700805664, 0.04616297967731953]\n",
      "  batch 30 loss: [37.320817947387695, 0.03765949606895447]\n",
      "  batch 32 loss: [35.57113742828369, 0.07973611843772233]\n",
      "  batch 34 loss: [39.969024658203125, 0.02230361755937338]\n",
      "  batch 36 loss: [39.21278953552246, 0.005104083218611777]\n",
      "  batch 38 loss: [37.05816459655762, 0.01142892544157803]\n",
      "  batch 40 loss: [39.95203971862793, 0.037381257861852646]\n",
      "  batch 42 loss: [31.66275978088379, 0.015170343220233917]\n",
      "  batch 44 loss: [39.551687240600586, 0.022162660025060177]\n",
      "  batch 46 loss: [34.28268814086914, 0.018254977650940418]\n",
      "  batch 48 loss: [32.56059646606445, 0.016973186284303665]\n",
      "  batch 50 loss: [30.336848258972168, 0.01989781204611063]\n",
      "  batch 52 loss: [33.203603744506836, 0.006237905938178301]\n",
      "  batch 54 loss: [36.64396286010742, 0.038339374121278524]\n",
      "LOSS generator 36.64396286010742 discriminator 0.038339374121278524\n",
      "EPOCH 210:\n",
      "  batch 0 loss: [33.70710754394531, 0.01749730110168457]\n",
      "  batch 2 loss: [35.80561637878418, 0.020414914935827255]\n",
      "  batch 4 loss: [39.51052665710449, 0.035964036360383034]\n",
      "  batch 6 loss: [37.99332618713379, 0.014144766610115767]\n",
      "  batch 8 loss: [32.35552787780762, 0.004543570335954428]\n",
      "  batch 10 loss: [30.148900985717773, 0.022570262663066387]\n",
      "  batch 12 loss: [31.41242218017578, 0.020872082095593214]\n",
      "  batch 14 loss: [37.02181625366211, 0.020795535994693637]\n",
      "  batch 16 loss: [37.76924133300781, 0.01122570550069213]\n",
      "  batch 18 loss: [37.59993648529053, 0.018222395330667496]\n",
      "  batch 20 loss: [38.76424217224121, 0.02415298903360963]\n",
      "  batch 22 loss: [33.720279693603516, 0.0052730373572558165]\n",
      "  batch 24 loss: [32.490793228149414, 0.06048448570072651]\n",
      "  batch 26 loss: [32.15997123718262, 0.0060276000294834375]\n",
      "  batch 28 loss: [36.76842498779297, 0.003135014441795647]\n",
      "  batch 30 loss: [34.39077663421631, 0.025293497368693352]\n",
      "  batch 32 loss: [33.048274993896484, 0.01190914586186409]\n",
      "  batch 34 loss: [30.53334617614746, 0.008266053162515163]\n",
      "  batch 36 loss: [37.06985855102539, 0.006026036862749606]\n",
      "  batch 38 loss: [39.20240592956543, 0.014941475354135036]\n",
      "  batch 40 loss: [32.47734832763672, 0.0041353481356054544]\n",
      "  batch 42 loss: [30.604952812194824, 0.028483104892075062]\n",
      "  batch 44 loss: [31.081202507019043, 0.005664550932124257]\n",
      "  batch 46 loss: [33.81705379486084, 0.013889980036765337]\n",
      "  batch 48 loss: [33.81293964385986, 0.0034041795879602432]\n",
      "  batch 50 loss: [31.801382064819336, 0.08503781817853451]\n",
      "  batch 52 loss: [38.449838638305664, 0.022274942137300968]\n",
      "  batch 54 loss: [33.23431968688965, 0.01078063528984785]\n",
      "LOSS generator 33.23431968688965 discriminator 0.01078063528984785\n",
      "EPOCH 211:\n",
      "  batch 0 loss: [32.05858612060547, 0.00546772126108408]\n",
      "  batch 2 loss: [28.75246238708496, 0.10613875137642026]\n",
      "  batch 4 loss: [36.80200004577637, 0.0033272835426032543]\n",
      "  batch 6 loss: [37.02404975891113, 0.03036878863349557]\n",
      "  batch 8 loss: [31.590185165405273, 0.015602465951815248]\n",
      "  batch 10 loss: [34.139580726623535, 0.012632421217858791]\n",
      "  batch 12 loss: [31.14842700958252, 0.011801404878497124]\n",
      "  batch 14 loss: [35.821889877319336, 0.010869944002479315]\n",
      "  batch 16 loss: [40.83119583129883, 0.037635382264852524]\n",
      "  batch 18 loss: [28.92180633544922, 0.024475199170410633]\n",
      "  batch 20 loss: [27.827597618103027, 0.016992610413581133]\n",
      "  batch 22 loss: [36.7136344909668, 0.0364626394584775]\n",
      "  batch 24 loss: [33.828853607177734, 0.008058757986873388]\n",
      "  batch 26 loss: [33.91878128051758, 0.008591432706452906]\n",
      "  batch 28 loss: [30.69090175628662, 0.05142147094011307]\n",
      "  batch 30 loss: [38.17099189758301, 0.013107812032103539]\n",
      "  batch 32 loss: [32.701826095581055, 0.04073123075067997]\n",
      "  batch 34 loss: [38.99739646911621, 0.02649352978914976]\n",
      "  batch 36 loss: [37.33053779602051, 0.013441210612654686]\n",
      "  batch 38 loss: [35.0797233581543, 0.005750068696215749]\n",
      "  batch 40 loss: [39.4657039642334, 0.03134494833648205]\n",
      "  batch 42 loss: [33.49951171875, 0.027361661195755005]\n",
      "  batch 44 loss: [34.26884174346924, 0.026476669125258923]\n",
      "  batch 46 loss: [32.34571933746338, 0.02761274902150035]\n",
      "  batch 48 loss: [32.89416313171387, 0.029623770155012608]\n",
      "  batch 50 loss: [34.651126861572266, 0.008117781020700932]\n",
      "  batch 52 loss: [31.32868766784668, 0.007491587428376079]\n",
      "  batch 54 loss: [34.59279251098633, 0.006240901770070195]\n",
      "LOSS generator 34.59279251098633 discriminator 0.006240901770070195\n",
      "EPOCH 212:\n",
      "  batch 0 loss: [29.587282180786133, 0.004995984025299549]\n",
      "  batch 2 loss: [33.54947471618652, 0.13338324427604675]\n",
      "  batch 4 loss: [33.43234062194824, 0.10197551175951958]\n",
      "  batch 6 loss: [34.883296966552734, 0.0317268455401063]\n",
      "  batch 8 loss: [33.89316368103027, 0.04644234012812376]\n",
      "  batch 10 loss: [31.9282283782959, 0.3926534429192543]\n",
      "  batch 12 loss: [35.33867263793945, 0.6717242300510406]\n",
      "  batch 14 loss: [36.628108978271484, 1.620135486125946]\n",
      "  batch 16 loss: [34.81700134277344, 0.4562893807888031]\n",
      "  batch 18 loss: [33.35200119018555, 0.24603139609098434]\n",
      "  batch 20 loss: [31.02509307861328, 0.08487540483474731]\n",
      "  batch 22 loss: [36.036821365356445, 0.13273339346051216]\n",
      "  batch 24 loss: [30.234920501708984, 0.05771351419389248]\n",
      "  batch 26 loss: [31.870986938476562, 0.04020123928785324]\n",
      "  batch 28 loss: [32.25431442260742, 0.05362510588020086]\n",
      "  batch 30 loss: [30.73511505126953, 0.6811022162437439]\n",
      "  batch 32 loss: [31.206157684326172, 0.287570595741272]\n",
      "  batch 34 loss: [36.500770568847656, 0.17765334993600845]\n",
      "  batch 36 loss: [34.13021469116211, 0.1338818185031414]\n",
      "  batch 38 loss: [30.917277336120605, 0.10269078612327576]\n",
      "  batch 40 loss: [34.429168701171875, 0.07362299598753452]\n",
      "  batch 42 loss: [29.6972074508667, 0.30795614421367645]\n",
      "  batch 44 loss: [34.0082368850708, 0.14126503467559814]\n",
      "  batch 46 loss: [30.601609230041504, 0.13761962577700615]\n",
      "  batch 48 loss: [21.33809185028076, 0.32279905676841736]\n",
      "  batch 50 loss: [35.66872978210449, 0.07995418831706047]\n",
      "  batch 52 loss: [36.112592697143555, 0.04038785770535469]\n",
      "  batch 54 loss: [31.266881942749023, 0.0195579850114882]\n",
      "LOSS generator 31.266881942749023 discriminator 0.0195579850114882\n",
      "EPOCH 213:\n",
      "  batch 0 loss: [39.976165771484375, 0.0990045890212059]\n",
      "  batch 2 loss: [30.27616024017334, 0.014107808470726013]\n",
      "  batch 4 loss: [36.77995681762695, 0.18962855637073517]\n",
      "  batch 6 loss: [31.776564598083496, 0.021891995798796415]\n",
      "  batch 8 loss: [31.05806255340576, 0.04997241124510765]\n",
      "  batch 10 loss: [31.907772064208984, 0.05794175108894706]\n",
      "  batch 12 loss: [35.01975727081299, 0.05385689623653889]\n",
      "  batch 14 loss: [33.52320098876953, 0.13807854801416397]\n",
      "  batch 16 loss: [25.65031337738037, 0.12114128842949867]\n",
      "  batch 18 loss: [39.85070610046387, 0.08719299174845219]\n",
      "  batch 20 loss: [29.058119773864746, 0.07057459093630314]\n",
      "  batch 22 loss: [34.79807472229004, 0.0513710118830204]\n",
      "  batch 24 loss: [29.703447341918945, 0.0566345639526844]\n",
      "  batch 26 loss: [43.902095794677734, 0.04103756044059992]\n",
      "  batch 28 loss: [35.522345542907715, 0.014415903948247433]\n",
      "  batch 30 loss: [37.07342720031738, 0.007625152822583914]\n",
      "  batch 32 loss: [36.016618728637695, 0.006152937712613493]\n",
      "  batch 34 loss: [37.239078521728516, 0.023418553173542023]\n",
      "  batch 36 loss: [38.0593204498291, 0.006936724996194243]\n",
      "  batch 38 loss: [35.04262161254883, 0.0041508544236421585]\n",
      "  batch 40 loss: [34.26693344116211, 0.011096275644376874]\n",
      "  batch 42 loss: [30.990331649780273, 0.02305338205769658]\n",
      "  batch 44 loss: [31.76900863647461, 0.0059686144813895226]\n",
      "  batch 46 loss: [31.45115375518799, 0.03555963560938835]\n",
      "  batch 48 loss: [35.79997444152832, 0.020683922804892063]\n",
      "  batch 50 loss: [38.423126220703125, 0.015914309304207563]\n",
      "  batch 52 loss: [29.74693012237549, 0.06495799217373133]\n",
      "  batch 54 loss: [27.73192024230957, 0.05101403035223484]\n",
      "LOSS generator 27.73192024230957 discriminator 0.05101403035223484\n",
      "EPOCH 214:\n",
      "  batch 0 loss: [36.4815559387207, 0.02016221173107624]\n",
      "  batch 2 loss: [33.389742851257324, 0.0150825425516814]\n",
      "  batch 4 loss: [38.13640213012695, 0.01706595066934824]\n",
      "  batch 6 loss: [30.972862243652344, 0.12348770163953304]\n",
      "  batch 8 loss: [30.16854763031006, 0.03167215269058943]\n",
      "  batch 10 loss: [30.146759033203125, 0.042545951902866364]\n",
      "  batch 12 loss: [35.90405082702637, 0.014401810942217708]\n",
      "  batch 14 loss: [35.25941848754883, 0.021187392761930823]\n",
      "  batch 16 loss: [37.18853569030762, 0.047618250362575054]\n",
      "  batch 18 loss: [32.11286640167236, 0.014891892671585083]\n",
      "  batch 20 loss: [35.200008392333984, 0.02090098336338997]\n",
      "  batch 22 loss: [35.306159019470215, 0.026749152690172195]\n",
      "  batch 24 loss: [34.76016807556152, 0.005100521259009838]\n",
      "  batch 26 loss: [34.35891914367676, 0.021631288807839155]\n",
      "  batch 28 loss: [33.64290904998779, 0.03582211770117283]\n",
      "  batch 30 loss: [28.786394119262695, 0.011787832714617252]\n",
      "  batch 32 loss: [35.11686420440674, 0.014662570785731077]\n",
      "  batch 34 loss: [40.2021484375, 0.008568279445171356]\n",
      "  batch 36 loss: [40.42341995239258, 0.008064126712270081]\n",
      "  batch 38 loss: [36.76369667053223, 0.008524677716195583]\n",
      "  batch 40 loss: [33.42351055145264, 0.011991625651717186]\n",
      "  batch 42 loss: [35.99012756347656, 0.03669796325266361]\n",
      "  batch 44 loss: [37.17186164855957, 0.010247711325064301]\n",
      "  batch 46 loss: [38.156232833862305, 0.009848516900092363]\n",
      "  batch 48 loss: [38.097782135009766, 0.010690523311495781]\n",
      "  batch 50 loss: [35.713674545288086, 0.07138789398595691]\n",
      "  batch 52 loss: [30.04304027557373, 0.08692997694015503]\n",
      "  batch 54 loss: [31.810604095458984, 0.14300699904561043]\n",
      "LOSS generator 31.810604095458984 discriminator 0.14300699904561043\n",
      "EPOCH 215:\n",
      "  batch 0 loss: [27.772232055664062, 0.03646653890609741]\n",
      "  batch 2 loss: [27.124906539916992, 0.0682978555560112]\n",
      "  batch 4 loss: [35.06349754333496, 0.016809185151942074]\n",
      "  batch 6 loss: [36.927894592285156, 0.012100186198949814]\n",
      "  batch 8 loss: [37.906463623046875, 0.010741994716227055]\n",
      "  batch 10 loss: [35.81085014343262, 0.08331539249047637]\n",
      "  batch 12 loss: [33.70846939086914, 0.025254678912460804]\n",
      "  batch 14 loss: [31.192808151245117, 0.1852525188587606]\n",
      "  batch 16 loss: [27.86660671234131, 0.24516760557889938]\n",
      "  batch 18 loss: [28.075325965881348, 0.11572804301977158]\n",
      "  batch 20 loss: [35.61447334289551, 0.0693680141121149]\n",
      "  batch 22 loss: [34.10666370391846, 0.02898961305618286]\n",
      "  batch 24 loss: [33.34678077697754, 0.04770153574645519]\n",
      "  batch 26 loss: [38.44913673400879, 0.03450690396130085]\n",
      "  batch 28 loss: [32.69759654998779, 0.05272856634110212]\n",
      "  batch 30 loss: [34.50401306152344, 0.028767631389200687]\n",
      "  batch 32 loss: [31.45369243621826, 0.06037755589932203]\n",
      "  batch 34 loss: [35.557748794555664, 0.011873220792040229]\n",
      "  batch 36 loss: [33.93389701843262, 0.022477011778391898]\n",
      "  batch 38 loss: [34.700117111206055, 0.15253261663019657]\n",
      "  batch 40 loss: [39.42741012573242, 0.07467490434646606]\n",
      "  batch 42 loss: [38.22950839996338, 0.017821165267378092]\n",
      "  batch 44 loss: [35.365901947021484, 0.00611887127161026]\n",
      "  batch 46 loss: [38.17320251464844, 0.01693057082593441]\n",
      "  batch 48 loss: [31.22174644470215, 0.01958226691931486]\n",
      "  batch 50 loss: [37.07495880126953, 0.005945901852101088]\n",
      "  batch 52 loss: [33.34394645690918, 0.021236293949186802]\n",
      "  batch 54 loss: [38.84839630126953, 0.0187205346301198]\n",
      "LOSS generator 38.84839630126953 discriminator 0.0187205346301198\n",
      "EPOCH 216:\n",
      "  batch 0 loss: [34.9881477355957, 0.0035460214130580425]\n",
      "  batch 2 loss: [34.052066802978516, 0.01226132269948721]\n",
      "  batch 4 loss: [35.439374923706055, 0.009027794934809208]\n",
      "  batch 6 loss: [41.29770469665527, 0.015652837697416544]\n",
      "  batch 8 loss: [33.12355613708496, 0.01665212120860815]\n",
      "  batch 10 loss: [34.74034881591797, 0.007622502278536558]\n",
      "  batch 12 loss: [29.767498016357422, 0.029787792824208736]\n",
      "  batch 14 loss: [42.83606719970703, 0.06107404641807079]\n",
      "  batch 16 loss: [32.739006996154785, 0.11583780124783516]\n",
      "  batch 18 loss: [34.73659133911133, 0.022044396959245205]\n",
      "  batch 20 loss: [33.03098106384277, 0.017501202411949635]\n",
      "  batch 22 loss: [38.024925231933594, 0.027871236205101013]\n",
      "  batch 24 loss: [36.95225715637207, 0.034423891454935074]\n",
      "  batch 26 loss: [33.85280799865723, 0.024475243873894215]\n",
      "  batch 28 loss: [31.848819732666016, 0.05672988248988986]\n",
      "  batch 30 loss: [33.820173263549805, 0.016619190573692322]\n",
      "  batch 32 loss: [40.68331336975098, 0.19580984488129616]\n",
      "  batch 34 loss: [38.01577091217041, 0.6731434762477875]\n",
      "  batch 36 loss: [32.78951644897461, 0.7403735816478729]\n",
      "  batch 38 loss: [37.899070739746094, 0.3930233120918274]\n",
      "  batch 40 loss: [35.35849571228027, 0.2459203153848648]\n",
      "  batch 42 loss: [34.86216735839844, 0.11895639821887016]\n",
      "  batch 44 loss: [38.063913345336914, 0.13007835298776627]\n",
      "  batch 46 loss: [39.16873741149902, 0.12942521274089813]\n",
      "  batch 48 loss: [39.45591354370117, 0.19305329211056232]\n",
      "  batch 50 loss: [33.78341579437256, 0.4785214960575104]\n",
      "  batch 52 loss: [38.50857734680176, 0.15349599719047546]\n",
      "  batch 54 loss: [37.598825454711914, 0.18012585490942]\n",
      "LOSS generator 37.598825454711914 discriminator 0.18012585490942\n",
      "EPOCH 217:\n",
      "  batch 0 loss: [36.47947692871094, 0.054242685437202454]\n",
      "  batch 2 loss: [40.73252487182617, 0.09525075741112232]\n",
      "  batch 4 loss: [40.74417304992676, 0.14393873512744904]\n",
      "  batch 6 loss: [31.420353889465332, 0.17440862953662872]\n",
      "  batch 8 loss: [32.71042442321777, 0.07683739066123962]\n",
      "  batch 10 loss: [40.54312324523926, 0.10354935005307198]\n",
      "  batch 12 loss: [32.10890865325928, 0.07557636871933937]\n",
      "  batch 14 loss: [34.638336181640625, 0.06801387667655945]\n",
      "  batch 16 loss: [37.48194694519043, 0.13366838172078133]\n",
      "  batch 18 loss: [45.16476249694824, 0.1889699324965477]\n",
      "  batch 20 loss: [51.417863845825195, 0.2769021838903427]\n",
      "  batch 22 loss: [39.308515548706055, 0.483248770236969]\n",
      "  batch 24 loss: [36.258304595947266, 0.4829583466053009]\n",
      "  batch 26 loss: [40.874732971191406, 0.40560591220855713]\n",
      "  batch 28 loss: [31.4363956451416, 0.20550259202718735]\n",
      "  batch 30 loss: [36.02747917175293, 0.20500943809747696]\n",
      "  batch 32 loss: [37.310720443725586, 0.08244303613901138]\n",
      "  batch 34 loss: [40.51877403259277, 0.04670636123046279]\n",
      "  batch 36 loss: [38.36810302734375, 0.1759883277118206]\n",
      "  batch 38 loss: [41.25039863586426, 0.053342945873737335]\n",
      "  batch 40 loss: [44.55290222167969, 0.0716510508209467]\n",
      "  batch 42 loss: [38.49933338165283, 0.03417280688881874]\n",
      "  batch 44 loss: [41.81608772277832, 0.03915800899267197]\n",
      "  batch 46 loss: [38.959564208984375, 0.11481129936873913]\n",
      "  batch 48 loss: [32.24084186553955, 0.0510986540466547]\n",
      "  batch 50 loss: [40.08880424499512, 0.021324149798601866]\n",
      "  batch 52 loss: [39.31679153442383, 0.025873178616166115]\n",
      "  batch 54 loss: [37.626747131347656, 0.04363944008946419]\n",
      "LOSS generator 37.626747131347656 discriminator 0.04363944008946419\n",
      "EPOCH 218:\n",
      "  batch 0 loss: [32.63774490356445, 0.25693634152412415]\n",
      "  batch 2 loss: [35.79260063171387, 0.17869186773896217]\n",
      "  batch 4 loss: [35.18926429748535, 0.07217647507786751]\n",
      "  batch 6 loss: [34.5687198638916, 0.03770289942622185]\n",
      "  batch 8 loss: [30.566394805908203, 0.02769764419645071]\n",
      "  batch 10 loss: [37.10011672973633, 0.012967163231223822]\n",
      "  batch 12 loss: [31.404735565185547, 0.014127243543043733]\n",
      "  batch 14 loss: [34.28291893005371, 0.014703031862154603]\n",
      "  batch 16 loss: [38.449241638183594, 0.028146890923380852]\n",
      "  batch 18 loss: [32.85501289367676, 0.02556093828752637]\n",
      "  batch 20 loss: [31.897403717041016, 0.024364508222788572]\n",
      "  batch 22 loss: [32.704100608825684, 0.01841035159304738]\n",
      "  batch 24 loss: [35.55297088623047, 0.0046253560576587915]\n",
      "  batch 26 loss: [32.2268705368042, 0.03869343176484108]\n",
      "  batch 28 loss: [28.92594337463379, 0.05107004567980766]\n",
      "  batch 30 loss: [38.494951248168945, 0.03166386391967535]\n",
      "  batch 32 loss: [28.93832015991211, 0.012299984693527222]\n",
      "  batch 34 loss: [38.044321060180664, 0.03773502469994128]\n",
      "  batch 36 loss: [34.63473320007324, 0.05417440598830581]\n",
      "  batch 38 loss: [32.163583755493164, 0.061551572754979134]\n",
      "  batch 40 loss: [30.582146644592285, 0.020989549346268177]\n",
      "  batch 42 loss: [32.757615089416504, 0.04832045640796423]\n",
      "  batch 44 loss: [31.517969131469727, 0.1416613687761128]\n",
      "  batch 46 loss: [39.28835868835449, 0.010254514054395258]\n",
      "  batch 48 loss: [36.58778381347656, 0.03846756927669048]\n",
      "  batch 50 loss: [35.21975898742676, 0.022016688715666533]\n",
      "  batch 52 loss: [31.45146369934082, 0.006070224568247795]\n",
      "  batch 54 loss: [35.27070999145508, 0.011381807271391153]\n",
      "LOSS generator 35.27070999145508 discriminator 0.011381807271391153\n",
      "EPOCH 219:\n",
      "  batch 0 loss: [34.16304397583008, 0.19485968351364136]\n",
      "  batch 2 loss: [35.345712661743164, 0.009116380009800196]\n",
      "  batch 4 loss: [31.0228910446167, 0.012182893231511116]\n",
      "  batch 6 loss: [35.16298484802246, 0.008210803847759962]\n",
      "  batch 8 loss: [35.16965675354004, 0.012591833248734474]\n",
      "  batch 10 loss: [32.642266273498535, 0.013747964054346085]\n",
      "  batch 12 loss: [35.10197639465332, 0.003150054137222469]\n",
      "  batch 14 loss: [30.586883544921875, 0.006242010043933988]\n",
      "  batch 16 loss: [35.71506881713867, 0.011310048750601709]\n",
      "  batch 18 loss: [34.97739601135254, 0.016913147643208504]\n",
      "  batch 20 loss: [31.75543212890625, 0.04907510336488485]\n",
      "  batch 22 loss: [34.315778732299805, 0.02577069401741028]\n",
      "  batch 24 loss: [34.128403663635254, 0.03499955893494189]\n",
      "  batch 26 loss: [32.874308586120605, 0.009941987693309784]\n",
      "  batch 28 loss: [38.358890533447266, 0.024289541877806187]\n",
      "  batch 30 loss: [36.602996826171875, 0.009674964006990194]\n",
      "  batch 32 loss: [32.755255699157715, 0.027291765436530113]\n",
      "  batch 34 loss: [37.57693290710449, 0.013318236451596022]\n",
      "  batch 36 loss: [35.276180267333984, 0.03279731050133705]\n",
      "  batch 38 loss: [37.13649368286133, 0.038271660916507244]\n",
      "  batch 40 loss: [29.719182014465332, 0.011847073677927256]\n",
      "  batch 42 loss: [33.62722206115723, 0.010726551990956068]\n",
      "  batch 44 loss: [39.42770957946777, 0.013551997486501932]\n",
      "  batch 46 loss: [37.373207092285156, 0.008029970806092024]\n",
      "  batch 48 loss: [40.89206886291504, 0.008043968467973173]\n",
      "  batch 50 loss: [37.73240852355957, 0.010339524887967855]\n",
      "  batch 52 loss: [33.164703369140625, 0.012133209966123104]\n",
      "  batch 54 loss: [27.377578735351562, 0.01099024759605527]\n",
      "LOSS generator 27.377578735351562 discriminator 0.01099024759605527\n",
      "EPOCH 220:\n",
      "  batch 0 loss: [35.898067474365234, 0.005928738042712212]\n",
      "  batch 2 loss: [34.37187194824219, 0.0054905773140490055]\n",
      "  batch 4 loss: [27.307395935058594, 0.10387194063514471]\n",
      "  batch 6 loss: [33.71245002746582, 0.0036664727376773953]\n",
      "  batch 8 loss: [34.229318618774414, 0.00411519524641335]\n",
      "  batch 10 loss: [37.15632247924805, 0.024772540666162968]\n",
      "  batch 12 loss: [31.177637100219727, 0.007589129381813109]\n",
      "  batch 14 loss: [42.16089630126953, 0.0577706266194582]\n",
      "  batch 16 loss: [31.8104305267334, 0.008259305555839092]\n",
      "  batch 18 loss: [35.984609603881836, 0.005949234357103705]\n",
      "  batch 20 loss: [37.807931900024414, 0.014119716128334403]\n",
      "  batch 22 loss: [37.719669342041016, 0.011176623404026031]\n",
      "  batch 24 loss: [36.17873954772949, 0.009848356246948242]\n",
      "  batch 26 loss: [32.296268463134766, 0.003922204719856381]\n",
      "  batch 28 loss: [38.122520446777344, 0.008626261143945158]\n",
      "  batch 30 loss: [34.04498100280762, 0.005407848861068487]\n",
      "  batch 32 loss: [30.520133018493652, 0.004702244070358574]\n",
      "  batch 34 loss: [34.7941837310791, 0.002603382454253733]\n",
      "  batch 36 loss: [33.22209072113037, 0.014549122657626867]\n",
      "  batch 38 loss: [36.25485706329346, 0.012987423688173294]\n",
      "  batch 40 loss: [35.026018142700195, 0.005246567772701383]\n",
      "  batch 42 loss: [36.230018615722656, 0.009989232756197453]\n",
      "  batch 44 loss: [32.321553230285645, 0.03434791415929794]\n",
      "  batch 46 loss: [31.545785903930664, 0.009953963570296764]\n",
      "  batch 48 loss: [29.0308198928833, 0.013721761293709278]\n",
      "  batch 50 loss: [32.44303226470947, 0.010447397828102112]\n",
      "  batch 52 loss: [40.37940216064453, 0.027340620756149292]\n",
      "  batch 54 loss: [39.616111755371094, 0.01709361933171749]\n",
      "LOSS generator 39.616111755371094 discriminator 0.01709361933171749\n",
      "EPOCH 221:\n",
      "  batch 0 loss: [36.24956512451172, 0.006225102115422487]\n",
      "  batch 2 loss: [36.23378944396973, 0.02818411123007536]\n",
      "  batch 4 loss: [37.37104415893555, 0.003566289320588112]\n",
      "  batch 6 loss: [36.19003677368164, 0.022756863851100206]\n",
      "  batch 8 loss: [38.721160888671875, 0.0029219798743724823]\n",
      "  batch 10 loss: [35.56486225128174, 0.011921165511012077]\n",
      "  batch 12 loss: [29.608989715576172, 0.00593405996914953]\n",
      "  batch 14 loss: [39.787363052368164, 0.010044981725513935]\n",
      "  batch 16 loss: [28.821834564208984, 0.015009395312517881]\n",
      "  batch 18 loss: [36.48175811767578, 0.014495555311441422]\n",
      "  batch 20 loss: [34.569597244262695, 0.00888399058021605]\n",
      "  batch 22 loss: [31.423405647277832, 0.007196400896646082]\n",
      "  batch 24 loss: [30.245454788208008, 0.025142680387943983]\n",
      "  batch 26 loss: [27.002063751220703, 0.08032062463462353]\n",
      "  batch 28 loss: [40.47534370422363, 0.01617979584261775]\n",
      "  batch 30 loss: [34.43370819091797, 0.006199944706168026]\n",
      "  batch 32 loss: [41.20786476135254, 0.006567756179720163]\n",
      "  batch 34 loss: [36.96739959716797, 0.019877180457115173]\n",
      "  batch 36 loss: [41.16696739196777, 0.020124987233430147]\n",
      "  batch 38 loss: [36.94749641418457, 0.008634144207462668]\n",
      "  batch 40 loss: [29.67475414276123, 0.041670211823657155]\n",
      "  batch 42 loss: [30.21588706970215, 0.00930414511822164]\n",
      "  batch 44 loss: [33.14521884918213, 0.007675086846575141]\n",
      "  batch 46 loss: [36.2686767578125, 0.004519685287959874]\n",
      "  batch 48 loss: [36.60153579711914, 0.006417752476409078]\n",
      "  batch 50 loss: [30.63027286529541, 0.008327336981892586]\n",
      "  batch 52 loss: [39.25636863708496, 0.015709681436419487]\n",
      "  batch 54 loss: [29.82155704498291, 0.014385454007424414]\n",
      "LOSS generator 29.82155704498291 discriminator 0.014385454007424414\n",
      "EPOCH 222:\n",
      "  batch 0 loss: [34.003543853759766, 0.0041294824331998825]\n",
      "  batch 2 loss: [30.39422607421875, 0.014828058890998363]\n",
      "  batch 4 loss: [33.25175380706787, 0.005578290205448866]\n",
      "  batch 6 loss: [32.755733489990234, 0.01450746227055788]\n",
      "  batch 8 loss: [34.49343681335449, 0.010149737121537328]\n",
      "  batch 10 loss: [40.28256797790527, 0.02021562959998846]\n",
      "  batch 12 loss: [37.54334259033203, 0.008905465481802821]\n",
      "  batch 14 loss: [38.91265296936035, 0.00417078728787601]\n",
      "  batch 16 loss: [36.614274978637695, 0.008993310621008277]\n",
      "  batch 18 loss: [38.70013999938965, 0.009299115743488073]\n",
      "  batch 20 loss: [36.424373626708984, 0.0066063906997442245]\n",
      "  batch 22 loss: [32.145277976989746, 0.004053080105222762]\n",
      "  batch 24 loss: [42.721771240234375, 0.04003231227397919]\n",
      "  batch 26 loss: [35.706665992736816, 0.033181460574269295]\n",
      "  batch 28 loss: [32.24001979827881, 0.006090124370530248]\n",
      "  batch 30 loss: [30.713366508483887, 0.008948355913162231]\n",
      "  batch 32 loss: [33.47662925720215, 0.019527117256075144]\n",
      "  batch 34 loss: [27.567489624023438, 0.01469274889677763]\n",
      "  batch 36 loss: [39.62833786010742, 0.013579495251178741]\n",
      "  batch 38 loss: [28.90994644165039, 0.040210493840277195]\n",
      "  batch 40 loss: [36.98379135131836, 0.04005077760666609]\n",
      "  batch 42 loss: [34.431602478027344, 0.0049426662735641]\n",
      "  batch 44 loss: [32.45633888244629, 0.010683313012123108]\n",
      "  batch 46 loss: [31.60140323638916, 0.005635211477056146]\n",
      "  batch 48 loss: [33.568461418151855, 0.010532684624195099]\n",
      "  batch 50 loss: [36.68178176879883, 0.009125576354563236]\n",
      "  batch 52 loss: [35.57063674926758, 0.004838662571273744]\n",
      "  batch 54 loss: [30.42397689819336, 0.08625090215355158]\n",
      "LOSS generator 30.42397689819336 discriminator 0.08625090215355158\n",
      "EPOCH 223:\n",
      "  batch 0 loss: [28.29192543029785, 0.007358201779425144]\n",
      "  batch 2 loss: [37.05562210083008, 0.00396516197361052]\n",
      "  batch 4 loss: [36.05493354797363, 0.013521521352231503]\n",
      "  batch 6 loss: [35.67456245422363, 0.014326809556223452]\n",
      "  batch 8 loss: [28.488499641418457, 0.02003649203106761]\n",
      "  batch 10 loss: [38.3167667388916, 0.014143186621367931]\n",
      "  batch 12 loss: [38.3533821105957, 0.0063619043212383986]\n",
      "  batch 14 loss: [36.57450485229492, 0.005673989770002663]\n",
      "  batch 16 loss: [37.61613655090332, 0.004430122673511505]\n",
      "  batch 18 loss: [35.16571521759033, 0.039082568138837814]\n",
      "  batch 20 loss: [32.77459239959717, 0.02342773787677288]\n",
      "  batch 22 loss: [34.496280670166016, 0.09229528764262795]\n",
      "  batch 24 loss: [38.70180130004883, 0.015786744887009263]\n",
      "  batch 26 loss: [35.16920471191406, 0.027637998573482037]\n",
      "  batch 28 loss: [35.0654411315918, 0.0605451725423336]\n",
      "  batch 30 loss: [39.74371337890625, 0.051435140892863274]\n",
      "  batch 32 loss: [33.02194118499756, 0.020093608647584915]\n",
      "  batch 34 loss: [36.75850868225098, 0.009373510722070932]\n",
      "  batch 36 loss: [35.09016704559326, 0.0025842912727966905]\n",
      "  batch 38 loss: [35.359846115112305, 0.022428262513130903]\n",
      "  batch 40 loss: [33.2326774597168, 0.012061836197972298]\n",
      "  batch 42 loss: [30.88491439819336, 0.007452993304468691]\n",
      "  batch 44 loss: [32.29182529449463, 0.002265229355543852]\n",
      "  batch 46 loss: [31.961697578430176, 0.006213578628376126]\n",
      "  batch 48 loss: [36.28937530517578, 0.003234776173485443]\n",
      "  batch 50 loss: [34.0145320892334, 0.009205745183862746]\n",
      "  batch 52 loss: [33.576927185058594, 0.019026711583137512]\n",
      "  batch 54 loss: [32.30217361450195, 0.03469237219542265]\n",
      "LOSS generator 32.30217361450195 discriminator 0.03469237219542265\n",
      "EPOCH 224:\n",
      "  batch 0 loss: [30.793203353881836, 0.009219604544341564]\n",
      "  batch 2 loss: [30.013806343078613, 0.004923443542793393]\n",
      "  batch 4 loss: [34.37121772766113, 0.011029893532395363]\n",
      "  batch 6 loss: [39.4018669128418, 0.009590805624611676]\n",
      "  batch 8 loss: [39.215213775634766, 0.01615315640810877]\n",
      "  batch 10 loss: [30.921513557434082, 0.011931991437450051]\n",
      "  batch 12 loss: [39.24261474609375, 0.006638969061896205]\n",
      "  batch 14 loss: [30.72684383392334, 0.03198214713484049]\n",
      "  batch 16 loss: [30.467857360839844, 0.02214694768190384]\n",
      "  batch 18 loss: [38.502994537353516, 0.02565711084753275]\n",
      "  batch 20 loss: [34.62818717956543, 0.00542434467934072]\n",
      "  batch 22 loss: [30.955683708190918, 0.01853552646934986]\n",
      "  batch 24 loss: [33.88753604888916, 0.012272031744942069]\n",
      "  batch 26 loss: [29.4410982131958, 0.0084316770080477]\n",
      "  batch 28 loss: [32.75955009460449, 0.022816565120592713]\n",
      "  batch 30 loss: [34.1003303527832, 0.008268081117421389]\n",
      "  batch 32 loss: [39.343528747558594, 0.0057137757539749146]\n",
      "  batch 34 loss: [31.16212272644043, 0.009146928321570158]\n",
      "  batch 36 loss: [40.049631118774414, 0.002927956869825721]\n",
      "  batch 38 loss: [36.65020561218262, 0.004698140430264175]\n",
      "  batch 40 loss: [33.991756439208984, 0.008282510098069906]\n",
      "  batch 42 loss: [32.401018142700195, 0.003204554319381714]\n",
      "  batch 44 loss: [36.25229454040527, 0.0035725790658034384]\n",
      "  batch 46 loss: [37.80496788024902, 0.004478322458453476]\n",
      "  batch 48 loss: [35.079729080200195, 0.11523856595158577]\n",
      "  batch 50 loss: [35.925519943237305, 0.004055539378896356]\n",
      "  batch 52 loss: [37.56784629821777, 0.02582101128064096]\n",
      "  batch 54 loss: [37.52016258239746, 0.011912745889276266]\n",
      "LOSS generator 37.52016258239746 discriminator 0.011912745889276266\n",
      "EPOCH 225:\n",
      "  batch 0 loss: [34.235286712646484, 0.0025275866501033306]\n",
      "  batch 2 loss: [33.67719841003418, 0.013602077262476087]\n",
      "  batch 4 loss: [34.04499053955078, 0.007038976531475782]\n",
      "  batch 6 loss: [32.2437744140625, 0.017593536525964737]\n",
      "  batch 8 loss: [29.78848361968994, 0.004824856761842966]\n",
      "  batch 10 loss: [33.30695343017578, 0.003595382848288864]\n",
      "  batch 12 loss: [34.06022834777832, 0.0033163237967528403]\n",
      "  batch 14 loss: [35.41338348388672, 0.003197801939677447]\n",
      "  batch 16 loss: [29.33666706085205, 0.007830711081624031]\n",
      "  batch 18 loss: [33.91617774963379, 0.015142235904932022]\n",
      "  batch 20 loss: [32.05795669555664, 0.010672732722014189]\n",
      "  batch 22 loss: [38.50667190551758, 0.011807348928414285]\n",
      "  batch 24 loss: [42.12736701965332, 0.010732450988143682]\n",
      "  batch 26 loss: [36.454952239990234, 0.004134386661462486]\n",
      "  batch 28 loss: [42.89876937866211, 0.018401985988020897]\n",
      "  batch 30 loss: [38.39088439941406, 0.012161191727500409]\n",
      "  batch 32 loss: [40.831769943237305, 0.011893469840288162]\n",
      "  batch 34 loss: [37.09195899963379, 0.011490876087918878]\n",
      "  batch 36 loss: [31.0760440826416, 0.0031149476999416947]\n",
      "  batch 38 loss: [33.90199947357178, 0.004118888871744275]\n",
      "  batch 40 loss: [42.772775650024414, 0.010218316689133644]\n",
      "  batch 42 loss: [32.43671989440918, 0.013287522364407778]\n",
      "  batch 44 loss: [39.880659103393555, 0.0034798248088918626]\n",
      "  batch 46 loss: [30.574448585510254, 0.0541845322586596]\n",
      "  batch 48 loss: [31.4940242767334, 0.010439535602927208]\n",
      "  batch 50 loss: [34.30045700073242, 0.00671747513115406]\n",
      "  batch 52 loss: [37.11713790893555, 0.003222390601877123]\n",
      "  batch 54 loss: [30.35764789581299, 0.004807058488950133]\n",
      "LOSS generator 30.35764789581299 discriminator 0.004807058488950133\n",
      "EPOCH 226:\n",
      "  batch 0 loss: [39.196170806884766, 0.023624205961823463]\n",
      "  batch 2 loss: [32.87044143676758, 0.004396375501528382]\n",
      "  batch 4 loss: [29.76767063140869, 0.004310647724196315]\n",
      "  batch 6 loss: [42.74671173095703, 0.0059439989272505045]\n",
      "  batch 8 loss: [35.72560691833496, 0.008063537767156959]\n",
      "  batch 10 loss: [35.66959285736084, 0.0057492058258503675]\n",
      "  batch 12 loss: [29.911474227905273, 0.004644716391339898]\n",
      "  batch 14 loss: [36.203996658325195, 0.017179522663354874]\n",
      "  batch 16 loss: [35.19928741455078, 0.015849809162318707]\n",
      "  batch 18 loss: [34.84199619293213, 0.0061503141187131405]\n",
      "  batch 20 loss: [36.62350082397461, 0.0049700632225722075]\n",
      "  batch 22 loss: [36.853498458862305, 0.0036950833746232092]\n",
      "  batch 24 loss: [33.648780822753906, 0.006402791477739811]\n",
      "  batch 26 loss: [39.59803771972656, 0.006748064886778593]\n",
      "  batch 28 loss: [39.55988883972168, 0.010028609307482839]\n",
      "  batch 30 loss: [29.108169555664062, 0.004070070222951472]\n",
      "  batch 32 loss: [34.93425750732422, 0.0065183076076209545]\n",
      "  batch 34 loss: [41.26763343811035, 0.005051491549238563]\n",
      "  batch 36 loss: [31.4456205368042, 0.004487507278099656]\n",
      "  batch 38 loss: [35.190317153930664, 0.0036640671314671636]\n",
      "  batch 40 loss: [32.80960464477539, 0.006728647509589791]\n",
      "  batch 42 loss: [38.78121471405029, 0.00872071017511189]\n",
      "  batch 44 loss: [34.918704986572266, 0.002147394639905542]\n",
      "  batch 46 loss: [36.86229705810547, 0.006070213043130934]\n",
      "  batch 48 loss: [35.081167221069336, 0.015472188126295805]\n",
      "  batch 50 loss: [35.27111053466797, 0.012374426238238811]\n",
      "  batch 52 loss: [37.65528106689453, 0.019743451150134206]\n",
      "  batch 54 loss: [25.34992218017578, 0.08273122808896005]\n",
      "LOSS generator 25.34992218017578 discriminator 0.08273122808896005\n",
      "EPOCH 227:\n",
      "  batch 0 loss: [28.902875900268555, 0.00826355442404747]\n",
      "  batch 2 loss: [39.71809768676758, 0.015944873448461294]\n",
      "  batch 4 loss: [37.07733917236328, 0.010457559721544385]\n",
      "  batch 6 loss: [31.2962703704834, 0.012368563911877573]\n",
      "  batch 8 loss: [37.224735260009766, 0.007774488884024322]\n",
      "  batch 10 loss: [40.18960189819336, 0.01705903932452202]\n",
      "  batch 12 loss: [36.59610939025879, 0.0012489217333495617]\n",
      "  batch 14 loss: [32.18526077270508, 0.016111462377011776]\n",
      "  batch 16 loss: [36.06831359863281, 0.028639431577175856]\n",
      "  batch 18 loss: [31.807217597961426, 0.011230451986193657]\n",
      "  batch 20 loss: [34.860389709472656, 0.0029340905603021383]\n",
      "  batch 22 loss: [38.62622833251953, 0.019627400673925877]\n",
      "  batch 24 loss: [28.687479972839355, 0.01615795074030757]\n",
      "  batch 26 loss: [31.145410537719727, 0.007955979323014617]\n",
      "  batch 28 loss: [32.65597057342529, 0.1408566515892744]\n",
      "  batch 30 loss: [34.959970474243164, 0.02201487496495247]\n",
      "  batch 32 loss: [33.59417247772217, 0.00696458900347352]\n",
      "  batch 34 loss: [35.788827896118164, 0.013620746321976185]\n",
      "  batch 36 loss: [30.78726863861084, 0.05792563688009977]\n",
      "  batch 38 loss: [36.18283176422119, 0.007611006963998079]\n",
      "  batch 40 loss: [36.137417793273926, 0.004212256986647844]\n",
      "  batch 42 loss: [39.34055709838867, 0.002584498026408255]\n",
      "  batch 44 loss: [29.811440467834473, 0.00798783591017127]\n",
      "  batch 46 loss: [38.3589973449707, 0.003912488813512027]\n",
      "  batch 48 loss: [43.602325439453125, 0.01579423388466239]\n",
      "  batch 50 loss: [36.403615951538086, 0.005523039028048515]\n",
      "  batch 52 loss: [35.12255096435547, 0.0032528750598430634]\n",
      "  batch 54 loss: [34.73336219787598, 0.006930268602445722]\n",
      "LOSS generator 34.73336219787598 discriminator 0.006930268602445722\n",
      "EPOCH 228:\n",
      "  batch 0 loss: [34.09749984741211, 0.00848955474793911]\n",
      "  batch 2 loss: [37.85162544250488, 0.013329565292224288]\n",
      "  batch 4 loss: [35.13731670379639, 0.010661540785804391]\n",
      "  batch 6 loss: [37.82915687561035, 0.007560748083051294]\n",
      "  batch 8 loss: [38.71359634399414, 0.011903400183655322]\n",
      "  batch 10 loss: [33.101613998413086, 0.007747391238808632]\n",
      "  batch 12 loss: [37.091901779174805, 0.0206652139313519]\n",
      "  batch 14 loss: [38.51304817199707, 0.009666818892583251]\n",
      "  batch 16 loss: [30.069540977478027, 0.09673399245366454]\n",
      "  batch 18 loss: [32.48533916473389, 0.0030522712040692568]\n",
      "  batch 20 loss: [35.986854553222656, 0.0072017229394987226]\n",
      "  batch 22 loss: [38.349002838134766, 0.008938992861658335]\n",
      "  batch 24 loss: [33.01091194152832, 0.009059939067810774]\n",
      "  batch 26 loss: [31.634960174560547, 0.005543409148231149]\n",
      "  batch 28 loss: [37.27117156982422, 0.001347912009805441]\n",
      "  batch 30 loss: [37.64177894592285, 0.003003392950631678]\n",
      "  batch 32 loss: [32.809858322143555, 0.01898456853814423]\n",
      "  batch 34 loss: [35.729217529296875, 0.011786147253587842]\n",
      "  batch 36 loss: [31.203237533569336, 0.002637807803694159]\n",
      "  batch 38 loss: [33.5931282043457, 0.007648840779438615]\n",
      "  batch 40 loss: [37.940134048461914, 0.005818464211188257]\n",
      "  batch 42 loss: [37.2017822265625, 0.011605948791839182]\n",
      "  batch 44 loss: [34.37587356567383, 0.02721948828548193]\n",
      "  batch 46 loss: [37.405303955078125, 0.009531085845082998]\n",
      "  batch 48 loss: [35.71777057647705, 0.008424374973401427]\n",
      "  batch 50 loss: [34.21492385864258, 0.012649071402847767]\n",
      "  batch 52 loss: [33.6263427734375, 0.004592668148688972]\n",
      "  batch 54 loss: [33.106027603149414, 0.0028043537749908864]\n",
      "LOSS generator 33.106027603149414 discriminator 0.0028043537749908864\n",
      "EPOCH 229:\n",
      "  batch 0 loss: [42.485595703125, 0.007107165642082691]\n",
      "  batch 2 loss: [32.93365478515625, 0.008239153306931257]\n",
      "  batch 4 loss: [34.555429458618164, 0.006395355332642794]\n",
      "  batch 6 loss: [37.14969348907471, 0.00356506829848513]\n",
      "  batch 8 loss: [35.28585624694824, 0.003550864290446043]\n",
      "  batch 10 loss: [32.12672424316406, 0.0026641167933121324]\n",
      "  batch 12 loss: [42.191741943359375, 0.02015048125758767]\n",
      "  batch 14 loss: [37.80797004699707, 0.02355978824198246]\n",
      "  batch 16 loss: [39.567874908447266, 0.021180650917813182]\n",
      "  batch 18 loss: [37.67216682434082, 0.012103507062420249]\n",
      "  batch 20 loss: [38.545631408691406, 0.004125936306081712]\n",
      "  batch 22 loss: [34.47607231140137, 0.001451912336051464]\n",
      "  batch 24 loss: [35.79086685180664, 0.004454381298273802]\n",
      "  batch 26 loss: [36.80553436279297, 0.0030268642585724592]\n",
      "  batch 28 loss: [30.378793716430664, 0.006027239141985774]\n",
      "  batch 30 loss: [37.22335433959961, 0.010534533066675067]\n",
      "  batch 32 loss: [29.95139503479004, 0.005331954453140497]\n",
      "  batch 34 loss: [37.31044960021973, 0.0060104412259534]\n",
      "  batch 36 loss: [32.38052558898926, 0.010265254881232977]\n",
      "  batch 38 loss: [37.314443588256836, 0.0035465190885588527]\n",
      "  batch 40 loss: [34.170034408569336, 0.0032207879703491926]\n",
      "  batch 42 loss: [31.315357208251953, 0.014336729538626969]\n",
      "  batch 44 loss: [33.95179462432861, 0.09831365430727601]\n",
      "  batch 46 loss: [30.759319305419922, 0.015572233125567436]\n",
      "  batch 48 loss: [32.78179359436035, 0.0029800081392750144]\n",
      "  batch 50 loss: [37.52698516845703, 0.007847457891330123]\n",
      "  batch 52 loss: [35.83229446411133, 0.002343038795515895]\n",
      "  batch 54 loss: [33.84220600128174, 0.0071233774069696665]\n",
      "LOSS generator 33.84220600128174 discriminator 0.0071233774069696665\n",
      "EPOCH 230:\n",
      "  batch 0 loss: [42.155303955078125, 0.0014570779167115688]\n",
      "  batch 2 loss: [33.80978965759277, 0.0049076719442382455]\n",
      "  batch 4 loss: [36.213727951049805, 0.006325315684080124]\n",
      "  batch 6 loss: [37.90987777709961, 0.013880149344913661]\n",
      "  batch 8 loss: [35.545724868774414, 0.0011977330432273448]\n",
      "  batch 10 loss: [35.2063627243042, 0.009373916313052177]\n",
      "  batch 12 loss: [32.86848545074463, 0.008269847370684147]\n",
      "  batch 14 loss: [35.73545265197754, 0.0040272679179906845]\n",
      "  batch 16 loss: [34.54022216796875, 0.009613545727916062]\n",
      "  batch 18 loss: [29.832887649536133, 0.0045408838195726275]\n",
      "  batch 20 loss: [34.33243942260742, 0.005457002203911543]\n",
      "  batch 22 loss: [40.898916244506836, 0.0037764302687719464]\n",
      "  batch 24 loss: [28.844443321228027, 0.01583275618031621]\n",
      "  batch 26 loss: [37.62184524536133, 0.012547491118311882]\n",
      "  batch 28 loss: [32.19584274291992, 0.09095723554491997]\n",
      "  batch 30 loss: [37.29150390625, 0.009184706024825573]\n",
      "  batch 32 loss: [37.400882720947266, 0.004636879311874509]\n",
      "  batch 34 loss: [32.40005874633789, 0.013709019403904676]\n",
      "  batch 36 loss: [41.09587287902832, 0.02426358126103878]\n",
      "  batch 38 loss: [34.13814926147461, 0.024819132406264544]\n",
      "  batch 40 loss: [34.56721305847168, 0.007737854844890535]\n",
      "  batch 42 loss: [35.43908882141113, 0.018648208351805806]\n",
      "  batch 44 loss: [32.62275218963623, 0.003180378582328558]\n",
      "  batch 46 loss: [33.978816986083984, 0.012883009854704142]\n",
      "  batch 48 loss: [37.17460536956787, 0.010462015401571989]\n",
      "  batch 50 loss: [37.75898361206055, 0.00810575159266591]\n",
      "  batch 52 loss: [34.96205711364746, 0.003304774989373982]\n",
      "  batch 54 loss: [38.17630195617676, 0.004889470641501248]\n",
      "LOSS generator 38.17630195617676 discriminator 0.004889470641501248\n",
      "EPOCH 231:\n",
      "  batch 0 loss: [30.83188819885254, 0.005042704753577709]\n",
      "  batch 2 loss: [36.70452880859375, 0.018758670426905155]\n",
      "  batch 4 loss: [31.0212345123291, 0.005032718938309699]\n",
      "  batch 6 loss: [32.626142501831055, 0.0155515824444592]\n",
      "  batch 8 loss: [46.390567779541016, 0.013782659079879522]\n",
      "  batch 10 loss: [38.508548736572266, 0.03985603526234627]\n",
      "  batch 12 loss: [32.13376045227051, 0.01753703341819346]\n",
      "  batch 14 loss: [34.41953372955322, 0.025062634609639645]\n",
      "  batch 16 loss: [35.112030029296875, 0.0249709514901042]\n",
      "  batch 18 loss: [33.869136810302734, 0.09401416033506393]\n",
      "  batch 20 loss: [38.54067611694336, 0.08131180703639984]\n",
      "  batch 22 loss: [39.58288764953613, 0.009796492755413055]\n",
      "  batch 24 loss: [37.6272029876709, 0.01150162797421217]\n",
      "  batch 26 loss: [34.70112991333008, 0.008267083787359297]\n",
      "  batch 28 loss: [36.32162857055664, 0.021317965583875775]\n",
      "  batch 30 loss: [32.89620113372803, 0.009804824367165565]\n",
      "  batch 32 loss: [27.172490119934082, 0.01754056289792061]\n",
      "  batch 34 loss: [33.68556213378906, 0.10408104467205703]\n",
      "  batch 36 loss: [34.55917167663574, 0.028191767632961273]\n",
      "  batch 38 loss: [32.57708740234375, 0.042782654985785484]\n",
      "  batch 40 loss: [32.265512466430664, 0.0404076986014843]\n",
      "  batch 42 loss: [35.389366149902344, 0.05055997148156166]\n",
      "  batch 44 loss: [37.890573501586914, 0.0783650353550911]\n",
      "  batch 46 loss: [39.80548858642578, 0.12685651145875454]\n",
      "  batch 48 loss: [30.666674613952637, 0.46298739314079285]\n",
      "  batch 50 loss: [30.508682250976562, 0.27394460141658783]\n",
      "  batch 52 loss: [32.0623779296875, 0.10631238855421543]\n",
      "  batch 54 loss: [30.138294219970703, 0.08301708661019802]\n",
      "LOSS generator 30.138294219970703 discriminator 0.08301708661019802\n",
      "EPOCH 232:\n",
      "  batch 0 loss: [32.84735870361328, 0.11268838495016098]\n",
      "  batch 2 loss: [37.808881759643555, 0.048884568735957146]\n",
      "  batch 4 loss: [37.5267448425293, 0.042761119082570076]\n",
      "  batch 6 loss: [38.814287185668945, 0.021813143976032734]\n",
      "  batch 8 loss: [36.8254508972168, 0.21405916661024094]\n",
      "  batch 10 loss: [30.288716316223145, 0.46882715821266174]\n",
      "  batch 12 loss: [36.61861610412598, 0.2571794018149376]\n",
      "  batch 14 loss: [28.337890625, 0.2670602798461914]\n",
      "  batch 16 loss: [32.27240562438965, 0.16818979941308498]\n",
      "  batch 18 loss: [31.704360008239746, 0.17372030019760132]\n",
      "  batch 20 loss: [29.414515495300293, 0.15699342638254166]\n",
      "  batch 22 loss: [35.79977989196777, 0.2135898321866989]\n",
      "  batch 24 loss: [32.12825965881348, 0.08657117187976837]\n",
      "  batch 26 loss: [35.991262435913086, 0.08365383744239807]\n",
      "  batch 28 loss: [30.3966121673584, 0.028284569969400764]\n",
      "  batch 30 loss: [36.17068099975586, 0.009084342047572136]\n",
      "  batch 32 loss: [32.853742599487305, 0.009611733490601182]\n",
      "  batch 34 loss: [40.8606071472168, 0.017843339825049043]\n",
      "  batch 36 loss: [34.202385902404785, 0.013307022978551686]\n",
      "  batch 38 loss: [33.506690979003906, 0.01977333379909396]\n",
      "  batch 40 loss: [29.55880069732666, 0.033754835836589336]\n",
      "  batch 42 loss: [30.179482460021973, 0.023161265067756176]\n",
      "  batch 44 loss: [39.77617263793945, 0.027208941872231662]\n",
      "  batch 46 loss: [34.62523078918457, 0.029361797496676445]\n",
      "  batch 48 loss: [30.654781341552734, 0.01540317153558135]\n",
      "  batch 50 loss: [32.22070503234863, 0.010705439373850822]\n",
      "  batch 52 loss: [30.143256187438965, 0.01317803212441504]\n",
      "  batch 54 loss: [30.45928192138672, 0.11738994438201189]\n",
      "LOSS generator 30.45928192138672 discriminator 0.11738994438201189\n",
      "EPOCH 233:\n",
      "  batch 0 loss: [37.956031799316406, 0.0796281099319458]\n",
      "  batch 2 loss: [33.83664608001709, 0.011561176041141152]\n",
      "  batch 4 loss: [35.605483055114746, 0.02359472867101431]\n",
      "  batch 6 loss: [35.75084686279297, 0.0018333353800699115]\n",
      "  batch 8 loss: [30.453838348388672, 0.012806311715394258]\n",
      "  batch 10 loss: [38.48380088806152, 0.011013283859938383]\n",
      "  batch 12 loss: [35.658265113830566, 0.014855487272143364]\n",
      "  batch 14 loss: [33.80513954162598, 0.009590080007910728]\n",
      "  batch 16 loss: [37.02716636657715, 0.007286424748599529]\n",
      "  batch 18 loss: [28.853148460388184, 0.16158668464049697]\n",
      "  batch 20 loss: [35.31235313415527, 0.0169285349547863]\n",
      "  batch 22 loss: [35.87012481689453, 0.005529391462914646]\n",
      "  batch 24 loss: [38.312278747558594, 0.04222685098648071]\n",
      "  batch 26 loss: [31.8257999420166, 0.03614932391792536]\n",
      "  batch 28 loss: [33.59334182739258, 0.01673205755650997]\n",
      "  batch 30 loss: [38.10725402832031, 0.04412875615525991]\n",
      "  batch 32 loss: [32.22354984283447, 0.016310148872435093]\n",
      "  batch 34 loss: [33.82350540161133, 0.012211440596729517]\n",
      "  batch 36 loss: [32.490108489990234, 0.008831918705254793]\n",
      "  batch 38 loss: [38.82960319519043, 0.00502916460391134]\n",
      "  batch 40 loss: [34.23970031738281, 0.013662287965416908]\n",
      "  batch 42 loss: [38.22810745239258, 0.04505312070250511]\n",
      "  batch 44 loss: [33.28548049926758, 0.027875198516994715]\n",
      "  batch 46 loss: [33.322824478149414, 0.031182263046503067]\n",
      "  batch 48 loss: [35.31122398376465, 0.02027697768062353]\n",
      "  batch 50 loss: [36.90427589416504, 0.012601519003510475]\n",
      "  batch 52 loss: [36.75460720062256, 0.003352303639985621]\n",
      "  batch 54 loss: [34.963043212890625, 0.018007637467235327]\n",
      "LOSS generator 34.963043212890625 discriminator 0.018007637467235327\n",
      "EPOCH 234:\n",
      "  batch 0 loss: [40.362579345703125, 0.02375197410583496]\n",
      "  batch 2 loss: [32.710350036621094, 0.02371911844238639]\n",
      "  batch 4 loss: [31.650346755981445, 0.011678413022309542]\n",
      "  batch 6 loss: [39.10859489440918, 0.04021420422941446]\n",
      "  batch 8 loss: [35.56490898132324, 0.022748771123588085]\n",
      "  batch 10 loss: [37.83740997314453, 0.019475060747936368]\n",
      "  batch 12 loss: [36.36343765258789, 0.022303587291389704]\n",
      "  batch 14 loss: [34.56277847290039, 0.00918877124786377]\n",
      "  batch 16 loss: [34.040719985961914, 0.02142309956252575]\n",
      "  batch 18 loss: [34.061954498291016, 0.014836720656603575]\n",
      "  batch 20 loss: [39.66799736022949, 0.007171439006924629]\n",
      "  batch 22 loss: [36.04786205291748, 0.03358963131904602]\n",
      "  batch 24 loss: [33.65569305419922, 0.005913183675147593]\n",
      "  batch 26 loss: [29.423623085021973, 0.038329596631228924]\n",
      "  batch 28 loss: [37.60050010681152, 0.013298149802722037]\n",
      "  batch 30 loss: [38.167396545410156, 0.011242499109357595]\n",
      "  batch 32 loss: [37.97139930725098, 0.0029635519022122025]\n",
      "  batch 34 loss: [34.43397235870361, 0.00562249799259007]\n",
      "  batch 36 loss: [33.993038177490234, 0.006854494567960501]\n",
      "  batch 38 loss: [33.18060111999512, 0.09656264423392713]\n",
      "  batch 40 loss: [31.383176803588867, 0.02678182302042842]\n",
      "  batch 42 loss: [38.22427749633789, 0.01602099882438779]\n",
      "  batch 44 loss: [28.311026573181152, 0.008955622091889381]\n",
      "  batch 46 loss: [34.512943267822266, 0.025340840918943286]\n",
      "  batch 48 loss: [36.290672302246094, 0.01006623962894082]\n",
      "  batch 50 loss: [38.844581604003906, 0.011553520802408457]\n",
      "  batch 52 loss: [36.16001510620117, 0.006267214892432094]\n",
      "  batch 54 loss: [35.68325614929199, 0.004454476526007056]\n",
      "LOSS generator 35.68325614929199 discriminator 0.004454476526007056\n",
      "EPOCH 235:\n",
      "  batch 0 loss: [34.19919967651367, 0.0019782164599746466]\n",
      "  batch 2 loss: [34.77609825134277, 0.011033922201022506]\n",
      "  batch 4 loss: [37.70235252380371, 0.004032703349366784]\n",
      "  batch 6 loss: [41.503543853759766, 0.006652157986536622]\n",
      "  batch 8 loss: [38.4182071685791, 0.0026206867187283933]\n",
      "  batch 10 loss: [31.646751403808594, 0.0027668699622154236]\n",
      "  batch 12 loss: [35.08878421783447, 0.004708164604380727]\n",
      "  batch 14 loss: [34.03647422790527, 0.040589346550405025]\n",
      "  batch 16 loss: [36.908390045166016, 0.017935103038325906]\n",
      "  batch 18 loss: [35.92230033874512, 0.012238874100148678]\n",
      "  batch 20 loss: [32.4865083694458, 0.13019485003314912]\n",
      "  batch 22 loss: [39.47490692138672, 0.010550375562161207]\n",
      "  batch 24 loss: [36.778343200683594, 0.008493404078762978]\n",
      "  batch 26 loss: [32.10788154602051, 0.013296221848577261]\n",
      "  batch 28 loss: [35.92509651184082, 0.04972461424767971]\n",
      "  batch 30 loss: [36.106611251831055, 0.05072740465402603]\n",
      "  batch 32 loss: [37.79111671447754, 0.024566572159528732]\n",
      "  batch 34 loss: [33.723124504089355, 0.009673035703599453]\n",
      "  batch 36 loss: [28.209381103515625, 0.012454206589609385]\n",
      "  batch 38 loss: [37.469587326049805, 0.0018941487069241703]\n",
      "  batch 40 loss: [38.25832557678223, 0.005164864473044872]\n",
      "  batch 42 loss: [37.408342361450195, 0.017689448781311512]\n",
      "  batch 44 loss: [31.41099739074707, 0.007560275262221694]\n",
      "  batch 46 loss: [33.241580963134766, 0.011829338036477566]\n",
      "  batch 48 loss: [34.85051345825195, 0.0017279299208894372]\n",
      "  batch 50 loss: [37.25107383728027, 0.0064650122076272964]\n",
      "  batch 52 loss: [33.97779560089111, 0.028294689022004604]\n",
      "  batch 54 loss: [40.64921760559082, 0.009383969474583864]\n",
      "LOSS generator 40.64921760559082 discriminator 0.009383969474583864\n",
      "EPOCH 236:\n",
      "  batch 0 loss: [32.3300895690918, 0.0046259076334536076]\n",
      "  batch 2 loss: [29.94547939300537, 0.008399782236665487]\n",
      "  batch 4 loss: [37.96775817871094, 0.006271070800721645]\n",
      "  batch 6 loss: [34.27012634277344, 0.11742653325200081]\n",
      "  batch 8 loss: [35.00627517700195, 0.019844473339617252]\n",
      "  batch 10 loss: [30.786036491394043, 0.011187782045453787]\n",
      "  batch 12 loss: [36.70332145690918, 0.01894138753414154]\n",
      "  batch 14 loss: [40.32186508178711, 0.0032504842383787036]\n",
      "  batch 16 loss: [33.851762771606445, 0.0037477496662177145]\n",
      "  batch 18 loss: [36.21615982055664, 0.005023182311560959]\n",
      "  batch 20 loss: [37.34317588806152, 0.02438279375201091]\n",
      "  batch 22 loss: [38.35281944274902, 0.006309865042567253]\n",
      "  batch 24 loss: [38.618316650390625, 0.015903184888884425]\n",
      "  batch 26 loss: [35.69954872131348, 0.01977619482204318]\n",
      "  batch 28 loss: [34.106990814208984, 0.008894490078091621]\n",
      "  batch 30 loss: [41.236019134521484, 0.02775565627962351]\n",
      "  batch 32 loss: [38.35557556152344, 0.005184224806725979]\n",
      "  batch 34 loss: [37.03466606140137, 0.010842871386557817]\n",
      "  batch 36 loss: [38.94033622741699, 0.004347719252109528]\n",
      "  batch 38 loss: [35.370431900024414, 0.004561256384477019]\n",
      "  batch 40 loss: [35.61271667480469, 0.01716037653386593]\n",
      "  batch 42 loss: [32.240142822265625, 0.01805379893630743]\n",
      "  batch 44 loss: [33.753360748291016, 0.011561854276806116]\n",
      "  batch 46 loss: [32.92055702209473, 0.004435985581949353]\n",
      "  batch 48 loss: [34.37709331512451, 0.005199314095079899]\n",
      "  batch 50 loss: [37.224021911621094, 0.0039972924860194325]\n",
      "  batch 52 loss: [33.36793327331543, 0.004717123927548528]\n",
      "  batch 54 loss: [38.61206245422363, 0.0039462814456783235]\n",
      "LOSS generator 38.61206245422363 discriminator 0.0039462814456783235\n",
      "EPOCH 237:\n",
      "  batch 0 loss: [35.75593185424805, 0.006471693050116301]\n",
      "  batch 2 loss: [37.95409393310547, 0.011068704072386026]\n",
      "  batch 4 loss: [34.063737869262695, 0.0036116294213570654]\n",
      "  batch 6 loss: [41.47839164733887, 0.012044523609802127]\n",
      "  batch 8 loss: [34.5886287689209, 0.005004652077332139]\n",
      "  batch 10 loss: [37.15370750427246, 0.0009370088810101151]\n",
      "  batch 12 loss: [37.30193901062012, 0.003443928435444832]\n",
      "  batch 14 loss: [35.95486640930176, 0.00409650697838515]\n",
      "  batch 16 loss: [34.074405670166016, 0.01422967854887247]\n",
      "  batch 18 loss: [36.11242866516113, 0.01032999437302351]\n",
      "  batch 20 loss: [35.93317985534668, 0.009717567823827267]\n",
      "  batch 22 loss: [36.5494327545166, 0.12166317156516016]\n",
      "  batch 24 loss: [36.36218452453613, 0.005502262501977384]\n",
      "  batch 26 loss: [36.20436477661133, 0.0014566194731742144]\n",
      "  batch 28 loss: [39.05387496948242, 0.008236204739660025]\n",
      "  batch 30 loss: [30.366073608398438, 0.0043183849193155766]\n",
      "  batch 32 loss: [42.68877410888672, 0.003733829187694937]\n",
      "  batch 34 loss: [30.549504280090332, 0.004795511486008763]\n",
      "  batch 36 loss: [36.09915542602539, 0.03737920895218849]\n",
      "  batch 38 loss: [34.505563735961914, 0.006488286657258868]\n",
      "  batch 40 loss: [34.33192825317383, 0.004280255932826549]\n",
      "  batch 42 loss: [30.695271492004395, 0.002962307306006551]\n",
      "  batch 44 loss: [40.7568416595459, 0.010472276480868459]\n",
      "  batch 46 loss: [34.03508758544922, 0.010204901918768883]\n",
      "  batch 48 loss: [38.97019958496094, 0.047864051535725594]\n",
      "  batch 50 loss: [33.714741706848145, 0.00829925388097763]\n",
      "  batch 52 loss: [38.30786895751953, 0.008618250023573637]\n",
      "  batch 54 loss: [34.7340087890625, 0.028120482340455055]\n",
      "LOSS generator 34.7340087890625 discriminator 0.028120482340455055\n",
      "EPOCH 238:\n",
      "  batch 0 loss: [34.5992317199707, 0.01058928668498993]\n",
      "  batch 2 loss: [35.407461166381836, 0.015070745255798101]\n",
      "  batch 4 loss: [30.709166526794434, 0.017898897407576442]\n",
      "  batch 6 loss: [38.0770378112793, 0.009418571833521128]\n",
      "  batch 8 loss: [34.218101501464844, 0.005802685162052512]\n",
      "  batch 10 loss: [31.151066780090332, 0.007015432696789503]\n",
      "  batch 12 loss: [36.02140235900879, 0.019798392429947853]\n",
      "  batch 14 loss: [40.7852840423584, 0.017042950727045536]\n",
      "  batch 16 loss: [32.03368282318115, 0.11011230875737965]\n",
      "  batch 18 loss: [35.80075454711914, 0.006241321098059416]\n",
      "  batch 20 loss: [37.830177307128906, 0.029249374754726887]\n",
      "  batch 22 loss: [36.68830108642578, 0.009944396559149027]\n",
      "  batch 24 loss: [37.08310508728027, 0.0024677483597770333]\n",
      "  batch 26 loss: [43.125, 0.01712474087253213]\n",
      "  batch 28 loss: [37.639137268066406, 0.05071934312582016]\n",
      "  batch 30 loss: [36.59829902648926, 0.01516240881755948]\n",
      "  batch 32 loss: [29.743194580078125, 0.012036539614200592]\n",
      "  batch 34 loss: [35.95026206970215, 0.029280302114784718]\n",
      "  batch 36 loss: [35.814016342163086, 0.006475345930084586]\n",
      "  batch 38 loss: [32.950416564941406, 0.017548026982694864]\n",
      "  batch 40 loss: [32.03313159942627, 0.21841184981167316]\n",
      "  batch 42 loss: [30.500093460083008, 1.2175785154104233]\n",
      "  batch 44 loss: [41.926109313964844, 1.6321037411689758]\n",
      "  batch 46 loss: [35.30691909790039, 2.1195560693740845]\n",
      "  batch 48 loss: [35.0504264831543, 1.7400928139686584]\n",
      "  batch 50 loss: [33.170623779296875, 0.9869747161865234]\n",
      "  batch 52 loss: [35.63333702087402, 1.104374647140503]\n",
      "  batch 54 loss: [39.58074951171875, 0.8279670178890228]\n",
      "LOSS generator 39.58074951171875 discriminator 0.8279670178890228\n",
      "EPOCH 239:\n",
      "  batch 0 loss: [39.7903938293457, 0.6830541491508484]\n",
      "  batch 2 loss: [32.497941970825195, 0.7334108948707581]\n",
      "  batch 4 loss: [40.647504806518555, 0.6535966694355011]\n",
      "  batch 6 loss: [30.479416847229004, 0.6238872408866882]\n",
      "  batch 8 loss: [32.92730522155762, 0.5135771334171295]\n",
      "  batch 10 loss: [31.201218605041504, 0.5392877459526062]\n",
      "  batch 12 loss: [34.150248527526855, 0.35606080293655396]\n",
      "  batch 14 loss: [35.41391563415527, 0.19671353697776794]\n",
      "  batch 16 loss: [40.11973571777344, 0.4186360239982605]\n",
      "  batch 18 loss: [29.514171600341797, 0.38421986997127533]\n",
      "  batch 20 loss: [30.07854461669922, 0.2665238454937935]\n",
      "  batch 22 loss: [39.40659141540527, 0.48983240127563477]\n",
      "  batch 24 loss: [39.063316345214844, 0.36341772973537445]\n",
      "  batch 26 loss: [44.21043395996094, 0.8321147859096527]\n",
      "  batch 28 loss: [32.00523567199707, 0.6464590430259705]\n",
      "  batch 30 loss: [35.16118812561035, 0.9279948472976685]\n",
      "  batch 32 loss: [37.52131271362305, 0.6705479323863983]\n",
      "  batch 34 loss: [37.53921699523926, 0.8063965737819672]\n",
      "  batch 36 loss: [33.634175300598145, 0.5803298801183701]\n",
      "  batch 38 loss: [37.65534210205078, 0.6687747836112976]\n",
      "  batch 40 loss: [39.9417724609375, 0.5017025023698807]\n",
      "  batch 42 loss: [35.843313217163086, 0.30365490913391113]\n",
      "  batch 44 loss: [34.02251052856445, 0.06451814249157906]\n",
      "  batch 46 loss: [46.03643989562988, 0.22593770921230316]\n",
      "  batch 48 loss: [42.22477912902832, 0.3365000933408737]\n",
      "  batch 50 loss: [33.397409439086914, 0.3755185008049011]\n",
      "  batch 52 loss: [37.80379295349121, 0.5487585365772247]\n",
      "  batch 54 loss: [39.365211486816406, 0.7624009009450674]\n",
      "LOSS generator 39.365211486816406 discriminator 0.7624009009450674\n",
      "EPOCH 240:\n",
      "  batch 0 loss: [22.990297317504883, 1.079145908355713]\n",
      "  batch 2 loss: [33.829668045043945, 0.9054684042930603]\n",
      "  batch 4 loss: [28.72408962249756, 0.7800193428993225]\n",
      "  batch 6 loss: [28.828147888183594, 0.5679604113101959]\n",
      "  batch 8 loss: [24.446521759033203, 0.5323490649461746]\n",
      "  batch 10 loss: [32.7423038482666, 0.5041146576404572]\n",
      "  batch 12 loss: [27.714613914489746, 0.32575900852680206]\n",
      "  batch 14 loss: [31.351051330566406, 0.17912910133600235]\n",
      "  batch 16 loss: [33.14434242248535, 0.08333296701312065]\n",
      "  batch 18 loss: [31.76289176940918, 0.14352503418922424]\n",
      "  batch 20 loss: [29.15667152404785, 0.08030874654650688]\n",
      "  batch 22 loss: [33.94436264038086, 0.1187255010008812]\n",
      "  batch 24 loss: [32.10334396362305, 0.08940074220299721]\n",
      "  batch 26 loss: [31.55524253845215, 0.2437698170542717]\n",
      "  batch 28 loss: [31.84721279144287, 0.23647800087928772]\n",
      "  batch 30 loss: [33.2576789855957, 0.21802333742380142]\n",
      "  batch 32 loss: [34.889596939086914, 0.16607646644115448]\n",
      "  batch 34 loss: [26.19976234436035, 0.11115743778645992]\n",
      "  batch 36 loss: [31.33462905883789, 0.158673245459795]\n",
      "  batch 38 loss: [30.763065338134766, 0.12898297607898712]\n",
      "  batch 40 loss: [35.053701400756836, 0.1831759363412857]\n",
      "  batch 42 loss: [26.157690048217773, 0.11925894021987915]\n",
      "  batch 44 loss: [32.41449546813965, 0.1728445291519165]\n",
      "  batch 46 loss: [33.56795120239258, 0.07191975135356188]\n",
      "  batch 48 loss: [33.171953201293945, 0.058707782067358494]\n",
      "  batch 50 loss: [30.64840316772461, 0.04967520013451576]\n",
      "  batch 52 loss: [25.537282943725586, 0.2674225065857172]\n",
      "  batch 54 loss: [33.07558631896973, 0.013044954743236303]\n",
      "LOSS generator 33.07558631896973 discriminator 0.013044954743236303\n",
      "EPOCH 241:\n",
      "  batch 0 loss: [23.804489135742188, 0.07766123116016388]\n",
      "  batch 2 loss: [31.66652011871338, 0.014209879096597433]\n",
      "  batch 4 loss: [31.176793098449707, 0.5316895991563797]\n",
      "  batch 6 loss: [39.52324104309082, 0.5859433710575104]\n",
      "  batch 8 loss: [35.844276428222656, 0.36338450014591217]\n",
      "  batch 10 loss: [31.154516220092773, 0.3915786147117615]\n",
      "  batch 12 loss: [33.43929672241211, 0.3299047648906708]\n",
      "  batch 14 loss: [29.534592628479004, 0.20244696736335754]\n",
      "  batch 16 loss: [27.585402488708496, 0.1617708057165146]\n",
      "  batch 18 loss: [32.06819820404053, 0.07380063086748123]\n",
      "  batch 20 loss: [32.79795265197754, 0.10839998163282871]\n",
      "  batch 22 loss: [44.29612922668457, 0.08859849721193314]\n",
      "  batch 24 loss: [29.04276943206787, 0.17785301804542542]\n",
      "  batch 26 loss: [30.48806858062744, 0.21228176355361938]\n",
      "  batch 28 loss: [28.30096435546875, 0.27873949706554413]\n",
      "  batch 30 loss: [27.31260108947754, 0.1956985890865326]\n",
      "  batch 32 loss: [28.68673801422119, 0.16266094893217087]\n",
      "  batch 34 loss: [30.46442985534668, 0.2543003559112549]\n",
      "  batch 36 loss: [28.144794464111328, 0.37905921041965485]\n",
      "  batch 38 loss: [29.019195556640625, 0.15560756623744965]\n",
      "  batch 40 loss: [29.734580039978027, 0.2949020303785801]\n",
      "  batch 42 loss: [39.02349662780762, 0.17524270713329315]\n",
      "  batch 44 loss: [30.664416313171387, 0.3266298472881317]\n",
      "  batch 46 loss: [27.06065845489502, 0.21385589241981506]\n",
      "  batch 48 loss: [33.32232189178467, 0.11520962230861187]\n",
      "  batch 50 loss: [33.05386734008789, 0.10977880284190178]\n",
      "  batch 52 loss: [33.17447471618652, 0.07479155249893665]\n",
      "  batch 54 loss: [35.04811096191406, 0.1243903785943985]\n",
      "LOSS generator 35.04811096191406 discriminator 0.1243903785943985\n",
      "EPOCH 242:\n",
      "  batch 0 loss: [36.050880432128906, 0.0449998714029789]\n",
      "  batch 2 loss: [33.69050216674805, 0.03343915659934282]\n",
      "  batch 4 loss: [30.867835998535156, 0.10247921198606491]\n",
      "  batch 6 loss: [34.911499977111816, 0.7510240077972412]\n",
      "  batch 8 loss: [32.635823249816895, 0.7206439673900604]\n",
      "  batch 10 loss: [25.371333122253418, 0.586135059595108]\n",
      "  batch 12 loss: [30.84011459350586, 0.5154251754283905]\n",
      "  batch 14 loss: [34.312002182006836, 0.34554146230220795]\n",
      "  batch 16 loss: [30.549047470092773, 0.25443606078624725]\n",
      "  batch 18 loss: [30.0792293548584, 0.14790529757738113]\n",
      "  batch 20 loss: [30.885583877563477, 0.11893710494041443]\n",
      "  batch 22 loss: [30.548622131347656, 0.09221138805150986]\n",
      "  batch 24 loss: [37.814101219177246, 0.09984898939728737]\n",
      "  batch 26 loss: [31.408315658569336, 0.08458397537469864]\n",
      "  batch 28 loss: [29.902873992919922, 0.24936912208795547]\n",
      "  batch 30 loss: [36.52978324890137, 0.08876572921872139]\n",
      "  batch 32 loss: [27.056922912597656, 0.2513142302632332]\n",
      "  batch 34 loss: [30.771743774414062, 0.20269780606031418]\n",
      "  batch 36 loss: [27.53459644317627, 0.16351863369345665]\n",
      "  batch 38 loss: [37.241804122924805, 0.09842336550354958]\n",
      "  batch 40 loss: [31.14554214477539, 0.03839491959661245]\n",
      "  batch 42 loss: [31.59059429168701, 0.07530969567596912]\n",
      "  batch 44 loss: [28.55082607269287, 0.343726247549057]\n",
      "  batch 46 loss: [34.39895725250244, 0.27409304305911064]\n",
      "  batch 48 loss: [28.65133571624756, 0.1225408986210823]\n",
      "  batch 50 loss: [29.384809494018555, 0.0852639377117157]\n",
      "  batch 52 loss: [28.52060317993164, 0.0639728270471096]\n",
      "  batch 54 loss: [31.257997512817383, 0.07199411652982235]\n",
      "LOSS generator 31.257997512817383 discriminator 0.07199411652982235\n",
      "EPOCH 243:\n",
      "  batch 0 loss: [30.819128036499023, 0.0580274723470211]\n",
      "  batch 2 loss: [27.05659008026123, 0.11109359189867973]\n",
      "  batch 4 loss: [29.589755058288574, 0.16955949552357197]\n",
      "  batch 6 loss: [35.49422550201416, 0.06455685198307037]\n",
      "  batch 8 loss: [35.20522689819336, 0.09539931640028954]\n",
      "  batch 10 loss: [35.99864959716797, 0.07203147932887077]\n",
      "  batch 12 loss: [29.217958450317383, 0.0538159254938364]\n",
      "  batch 14 loss: [35.253273010253906, 0.10717227682471275]\n",
      "  batch 16 loss: [27.95808219909668, 0.04652274772524834]\n",
      "  batch 18 loss: [31.889991760253906, 0.057612329721450806]\n",
      "  batch 20 loss: [34.40585803985596, 0.028546687215566635]\n",
      "  batch 22 loss: [30.24667263031006, 0.024502863874658942]\n",
      "  batch 24 loss: [34.316710472106934, 0.018811997957527637]\n",
      "  batch 26 loss: [27.180426597595215, 0.04029291681945324]\n",
      "  batch 28 loss: [36.68556213378906, 0.032953493762761354]\n",
      "  batch 30 loss: [33.396334648132324, 0.012863792013376951]\n",
      "  batch 32 loss: [32.61406230926514, 0.04720309376716614]\n",
      "  batch 34 loss: [31.97529888153076, 0.05807329714298248]\n",
      "  batch 36 loss: [31.43351459503174, 0.024505960755050182]\n",
      "  batch 38 loss: [32.97477149963379, 0.0308487587608397]\n",
      "  batch 40 loss: [40.243539810180664, 0.007692465325817466]\n",
      "  batch 42 loss: [36.31020736694336, 0.09264444932341576]\n",
      "  batch 44 loss: [39.43472480773926, 0.06189516559243202]\n",
      "  batch 46 loss: [32.86709976196289, 0.048915496096014977]\n",
      "  batch 48 loss: [33.94170665740967, 0.08405474573373795]\n",
      "  batch 50 loss: [37.50975227355957, 0.02812981093302369]\n",
      "  batch 52 loss: [24.358736991882324, 0.09451914951205254]\n",
      "  batch 54 loss: [29.64227294921875, 0.1074494868516922]\n",
      "LOSS generator 29.64227294921875 discriminator 0.1074494868516922\n",
      "EPOCH 244:\n",
      "  batch 0 loss: [30.867446899414062, 0.021005436778068542]\n",
      "  batch 2 loss: [36.05947685241699, 0.06124967895448208]\n",
      "  batch 4 loss: [39.686737060546875, 0.01275143027305603]\n",
      "  batch 6 loss: [34.64613342285156, 0.008433269569650292]\n",
      "  batch 8 loss: [31.381744384765625, 0.051660675555467606]\n",
      "  batch 10 loss: [34.163400650024414, 0.013043151702731848]\n",
      "  batch 12 loss: [32.22377586364746, 0.014512876980006695]\n",
      "  batch 14 loss: [37.006595611572266, 0.02535604126751423]\n",
      "  batch 16 loss: [31.39182758331299, 0.04575091600418091]\n",
      "  batch 18 loss: [33.903364181518555, 0.01011653570458293]\n",
      "  batch 20 loss: [39.10548782348633, 0.03877957444638014]\n",
      "  batch 22 loss: [38.36109733581543, 0.07752833794802427]\n",
      "  batch 24 loss: [33.78521537780762, 0.026539706625044346]\n",
      "  batch 26 loss: [29.325081825256348, 0.03188532590866089]\n",
      "  batch 28 loss: [35.279903411865234, 0.027077728882431984]\n",
      "  batch 30 loss: [29.70198917388916, 0.011519593186676502]\n",
      "  batch 32 loss: [36.24428176879883, 0.013969336287118495]\n",
      "  batch 34 loss: [38.74485397338867, 0.030030589550733566]\n",
      "  batch 36 loss: [30.59459686279297, 0.07471028272993863]\n",
      "  batch 38 loss: [36.983102798461914, 0.04100984334945679]\n",
      "  batch 40 loss: [33.71088790893555, 0.08581463992595673]\n",
      "  batch 42 loss: [30.60035800933838, 0.03231966122984886]\n",
      "  batch 44 loss: [28.00162696838379, 0.043096356093883514]\n",
      "  batch 46 loss: [32.19299507141113, 0.025491666048765182]\n",
      "  batch 48 loss: [31.189977645874023, 0.016557736322283745]\n",
      "  batch 50 loss: [31.496004104614258, 0.06102217547595501]\n",
      "  batch 52 loss: [36.4847297668457, 0.07257282547652721]\n",
      "  batch 54 loss: [31.259977340698242, 0.021569428965449333]\n",
      "LOSS generator 31.259977340698242 discriminator 0.021569428965449333\n",
      "EPOCH 245:\n",
      "  batch 0 loss: [20.025997161865234, 0.05307053029537201]\n",
      "  batch 2 loss: [29.83062171936035, 0.023888065479695797]\n",
      "  batch 4 loss: [33.97140884399414, 0.013415230554528534]\n",
      "  batch 6 loss: [33.64632606506348, 0.01466380013152957]\n",
      "  batch 8 loss: [37.14437007904053, 0.028782173991203308]\n",
      "  batch 10 loss: [31.682777404785156, 0.15666448697447777]\n",
      "  batch 12 loss: [31.822853088378906, 0.005634693196043372]\n",
      "  batch 14 loss: [33.515899658203125, 0.030485632829368114]\n",
      "  batch 16 loss: [34.255343437194824, 0.03778187930583954]\n",
      "  batch 18 loss: [35.61123847961426, 0.011058753123506904]\n",
      "  batch 20 loss: [34.317880630493164, 0.007667627884075046]\n",
      "  batch 22 loss: [37.02243614196777, 0.012732394970953465]\n",
      "  batch 24 loss: [37.33600616455078, 0.006922888802364469]\n",
      "  batch 26 loss: [34.49180221557617, 0.016037645749747753]\n",
      "  batch 28 loss: [34.34472179412842, 0.07534709945321083]\n",
      "  batch 30 loss: [36.033607482910156, 0.06787585094571114]\n",
      "  batch 32 loss: [32.6329231262207, 0.032600197941064835]\n",
      "  batch 34 loss: [35.321279525756836, 0.1266051810234785]\n",
      "  batch 36 loss: [30.7167911529541, 0.18248270824551582]\n",
      "  batch 38 loss: [31.83650779724121, 0.1337215006351471]\n",
      "  batch 40 loss: [41.179758071899414, 0.15736445039510727]\n",
      "  batch 42 loss: [31.00599193572998, 0.08382928371429443]\n",
      "  batch 44 loss: [31.553903579711914, 0.10772845149040222]\n",
      "  batch 46 loss: [36.33296585083008, 0.09175443649291992]\n",
      "  batch 48 loss: [31.352978706359863, 0.044287522323429585]\n",
      "  batch 50 loss: [36.07972717285156, 0.07291695103049278]\n",
      "  batch 52 loss: [32.6256217956543, 0.0715082660317421]\n",
      "  batch 54 loss: [31.482379913330078, 0.05710264667868614]\n",
      "LOSS generator 31.482379913330078 discriminator 0.05710264667868614\n",
      "EPOCH 246:\n",
      "  batch 0 loss: [35.28793716430664, 0.038863006979227066]\n",
      "  batch 2 loss: [36.23446178436279, 0.017854321282356977]\n",
      "  batch 4 loss: [30.244831085205078, 0.04502526670694351]\n",
      "  batch 6 loss: [36.09013748168945, 0.027218706905841827]\n",
      "  batch 8 loss: [32.959075927734375, 0.02555816061794758]\n",
      "  batch 10 loss: [31.55549907684326, 0.04012215510010719]\n",
      "  batch 12 loss: [36.489044189453125, 0.009883605409413576]\n",
      "  batch 14 loss: [35.49700355529785, 0.013948109466582537]\n",
      "  batch 16 loss: [33.9232063293457, 0.03170247748494148]\n",
      "  batch 18 loss: [28.142108917236328, 0.05194438528269529]\n",
      "  batch 20 loss: [30.441930770874023, 0.030570865608751774]\n",
      "  batch 22 loss: [31.259737968444824, 0.055633410811424255]\n",
      "  batch 24 loss: [36.635719299316406, 0.030639201402664185]\n",
      "  batch 26 loss: [39.1633358001709, 0.014645888935774565]\n",
      "  batch 28 loss: [39.54360580444336, 0.01599809853360057]\n",
      "  batch 30 loss: [35.98764991760254, 0.0480522345751524]\n",
      "  batch 32 loss: [35.45126533508301, 0.06499672867357731]\n",
      "  batch 34 loss: [32.37409591674805, 0.021060895174741745]\n",
      "  batch 36 loss: [36.507198333740234, 0.012457611039280891]\n",
      "  batch 38 loss: [30.819028854370117, 0.033649840857833624]\n",
      "  batch 40 loss: [36.243404388427734, 0.011594749987125397]\n",
      "  batch 42 loss: [33.17624473571777, 0.019227683544158936]\n",
      "  batch 44 loss: [38.68196487426758, 0.05084111588075757]\n",
      "  batch 46 loss: [27.30730438232422, 0.25641002506017685]\n",
      "  batch 48 loss: [37.01774024963379, 0.10453399270772934]\n",
      "  batch 50 loss: [30.097999572753906, 0.17016455810517073]\n",
      "  batch 52 loss: [32.403903007507324, 0.023767875507473946]\n",
      "  batch 54 loss: [35.21998405456543, 0.020299728959798813]\n",
      "LOSS generator 35.21998405456543 discriminator 0.020299728959798813\n",
      "EPOCH 247:\n",
      "  batch 0 loss: [35.784297943115234, 0.05751741677522659]\n",
      "  batch 2 loss: [33.08629608154297, 0.05131398979574442]\n",
      "  batch 4 loss: [26.319726943969727, 0.041847990825772285]\n",
      "  batch 6 loss: [37.78068923950195, 0.010951447067782283]\n",
      "  batch 8 loss: [37.153733253479004, 0.08124447613954544]\n",
      "  batch 10 loss: [27.631139755249023, 0.026829146780073643]\n",
      "  batch 12 loss: [32.19106674194336, 0.012153516057878733]\n",
      "  batch 14 loss: [34.28395080566406, 0.0051847866852767766]\n",
      "  batch 16 loss: [33.14336967468262, 0.006423830520361662]\n",
      "  batch 18 loss: [34.24844169616699, 0.033195984084159136]\n",
      "  batch 20 loss: [37.82567024230957, 0.019212146755307913]\n",
      "  batch 22 loss: [34.963937759399414, 0.009338383562862873]\n",
      "  batch 24 loss: [34.23191452026367, 0.008950072806328535]\n",
      "  batch 26 loss: [39.075467109680176, 0.010716098127886653]\n",
      "  batch 28 loss: [25.761981964111328, 0.01968360599130392]\n",
      "  batch 30 loss: [31.13259220123291, 0.011897067073732615]\n",
      "  batch 32 loss: [39.27081108093262, 0.021387874148786068]\n",
      "  batch 34 loss: [37.54201889038086, 0.007415856351144612]\n",
      "  batch 36 loss: [37.80883979797363, 0.008992324583232403]\n",
      "  batch 38 loss: [35.230414390563965, 0.015600436367094517]\n",
      "  batch 40 loss: [33.558013916015625, 0.020685872063040733]\n",
      "  batch 42 loss: [34.306631088256836, 0.00371594843454659]\n",
      "  batch 44 loss: [40.99379539489746, 0.016574214212596416]\n",
      "  batch 46 loss: [37.08321189880371, 0.09795155515894294]\n",
      "  batch 48 loss: [39.942874908447266, 0.17400575801730156]\n",
      "  batch 50 loss: [34.24904251098633, 0.12725620158016682]\n",
      "  batch 52 loss: [30.05274200439453, 0.10865180939435959]\n",
      "  batch 54 loss: [33.51988887786865, 0.17142057046294212]\n",
      "LOSS generator 33.51988887786865 discriminator 0.17142057046294212\n",
      "EPOCH 248:\n",
      "  batch 0 loss: [29.668750762939453, 0.5601087212562561]\n",
      "  batch 2 loss: [24.909794807434082, 0.6718555986881256]\n",
      "  batch 4 loss: [29.691020965576172, 0.4474114775657654]\n",
      "  batch 6 loss: [26.681133270263672, 0.47963207960128784]\n",
      "  batch 8 loss: [29.955820083618164, 0.32687990367412567]\n",
      "  batch 10 loss: [30.042725563049316, 0.12425923347473145]\n",
      "  batch 12 loss: [34.537498474121094, 0.07657641917467117]\n",
      "  batch 14 loss: [37.63720512390137, 0.06538386456668377]\n",
      "  batch 16 loss: [32.02204704284668, 0.10424640029668808]\n",
      "  batch 18 loss: [33.087679862976074, 0.0959012545645237]\n",
      "  batch 20 loss: [28.75434112548828, 0.1205216832458973]\n",
      "  batch 22 loss: [32.17020797729492, 0.08410669304430485]\n",
      "  batch 24 loss: [27.980384826660156, 0.05248182266950607]\n",
      "  batch 26 loss: [34.12144088745117, 0.040541297756135464]\n",
      "  batch 28 loss: [33.46125411987305, 0.1136641874909401]\n",
      "  batch 30 loss: [34.817975997924805, 0.05558762326836586]\n",
      "  batch 32 loss: [34.07554054260254, 0.03868179814890027]\n",
      "  batch 34 loss: [25.977214813232422, 0.05659506842494011]\n",
      "  batch 36 loss: [31.512758255004883, 0.037225671112537384]\n",
      "  batch 38 loss: [33.85850143432617, 0.02433486096560955]\n",
      "  batch 40 loss: [31.874189376831055, 0.045080143958330154]\n",
      "  batch 42 loss: [34.74872398376465, 0.026112018153071404]\n",
      "  batch 44 loss: [34.86457633972168, 0.06449441704899073]\n",
      "  batch 46 loss: [34.86620807647705, 0.23424163460731506]\n",
      "  batch 48 loss: [33.03964614868164, 0.10230697877705097]\n",
      "  batch 50 loss: [31.001266479492188, 0.03870293311774731]\n",
      "  batch 52 loss: [30.108644485473633, 0.03387404605746269]\n",
      "  batch 54 loss: [25.687158584594727, 0.032609691843390465]\n",
      "LOSS generator 25.687158584594727 discriminator 0.032609691843390465\n",
      "EPOCH 249:\n",
      "  batch 0 loss: [37.399784088134766, 0.029400521889328957]\n",
      "  batch 2 loss: [32.68657112121582, 0.012817577458918095]\n",
      "  batch 4 loss: [38.59670829772949, 0.039808087050914764]\n",
      "  batch 6 loss: [28.563124656677246, 0.019396211951971054]\n",
      "  batch 8 loss: [31.74046039581299, 0.021557291969656944]\n",
      "  batch 10 loss: [33.879475593566895, 0.0320651400834322]\n",
      "  batch 12 loss: [33.42241096496582, 0.01933843083679676]\n",
      "  batch 14 loss: [34.888017654418945, 0.010964888148009777]\n",
      "  batch 16 loss: [28.598045349121094, 0.12867258116602898]\n",
      "  batch 18 loss: [32.93998718261719, 0.01914092432707548]\n",
      "  batch 20 loss: [38.2576961517334, 0.006234995787963271]\n",
      "  batch 22 loss: [30.250691413879395, 0.014056898653507233]\n",
      "  batch 24 loss: [30.113040924072266, 0.020191002637147903]\n",
      "  batch 26 loss: [31.393502235412598, 0.0390965947881341]\n",
      "  batch 28 loss: [37.46286106109619, 0.02436114102602005]\n",
      "  batch 30 loss: [30.43706512451172, 0.015352880582213402]\n",
      "  batch 32 loss: [30.54498863220215, 0.043946728110313416]\n",
      "  batch 34 loss: [32.01511478424072, 0.014827492646872997]\n",
      "  batch 36 loss: [40.73400115966797, 0.010055219288915396]\n",
      "  batch 38 loss: [35.18846130371094, 0.01809115894138813]\n",
      "  batch 40 loss: [35.04531955718994, 0.010219952324405313]\n",
      "  batch 42 loss: [32.85613441467285, 0.010844694683328271]\n",
      "  batch 44 loss: [36.958152770996094, 0.02446633530780673]\n",
      "  batch 46 loss: [31.361316680908203, 0.04062863066792488]\n",
      "  batch 48 loss: [38.29205131530762, 0.02609583013691008]\n",
      "  batch 50 loss: [36.184621810913086, 0.009612499736249447]\n",
      "  batch 52 loss: [33.308237075805664, 0.013209887780249119]\n",
      "  batch 54 loss: [26.5460262298584, 0.06643235310912132]\n",
      "LOSS generator 26.5460262298584 discriminator 0.06643235310912132\n",
      "EPOCH 250:\n",
      "  batch 0 loss: [35.28292465209961, 0.009950454346835613]\n",
      "  batch 2 loss: [34.92635726928711, 0.03932726942002773]\n",
      "  batch 4 loss: [34.06442832946777, 0.027422389015555382]\n",
      "  batch 6 loss: [27.20137310028076, 0.04611075296998024]\n",
      "  batch 8 loss: [36.73951530456543, 0.14280058816075325]\n",
      "  batch 10 loss: [50.51345252990723, 0.2884102016687393]\n",
      "  batch 12 loss: [36.9514102935791, 0.3097364008426666]\n",
      "  batch 14 loss: [37.051002502441406, 0.17695323377847672]\n",
      "  batch 16 loss: [36.93368339538574, 0.045316603034734726]\n",
      "  batch 18 loss: [42.9048957824707, 0.04344306979328394]\n",
      "  batch 20 loss: [32.46352291107178, 0.054862769320607185]\n",
      "  batch 22 loss: [49.75457000732422, 0.4773237630724907]\n",
      "  batch 24 loss: [29.634811401367188, 0.4292174205183983]\n",
      "  batch 26 loss: [34.657705307006836, 0.5539295673370361]\n",
      "  batch 28 loss: [29.596338272094727, 0.17673584073781967]\n",
      "  batch 30 loss: [35.32367706298828, 0.3028516471385956]\n",
      "  batch 32 loss: [28.926435470581055, 0.23957198858261108]\n",
      "  batch 34 loss: [29.19065761566162, 0.13593624159693718]\n",
      "  batch 36 loss: [36.830827713012695, 0.140756756067276]\n",
      "  batch 38 loss: [29.65780735015869, 0.11802525073289871]\n",
      "  batch 40 loss: [31.680147171020508, 0.11959916725754738]\n",
      "  batch 42 loss: [37.00321388244629, 0.07959530130028725]\n",
      "  batch 44 loss: [28.900611877441406, 0.15376751124858856]\n",
      "  batch 46 loss: [33.31504440307617, 0.031473103910684586]\n",
      "  batch 48 loss: [36.79613494873047, 0.14215465635061264]\n",
      "  batch 50 loss: [36.230655670166016, 0.025580848567187786]\n",
      "  batch 52 loss: [32.705881118774414, 0.04598766379058361]\n",
      "  batch 54 loss: [27.191197395324707, 0.045417215675115585]\n",
      "LOSS generator 27.191197395324707 discriminator 0.045417215675115585\n",
      "EPOCH 251:\n",
      "  batch 0 loss: [24.400270462036133, 0.1327119618654251]\n",
      "  batch 2 loss: [31.478042602539062, 0.03764927666634321]\n",
      "  batch 4 loss: [30.612271308898926, 0.0383097268640995]\n",
      "  batch 6 loss: [37.287593841552734, 0.04205097258090973]\n",
      "  batch 8 loss: [32.52690887451172, 0.07940110191702843]\n",
      "  batch 10 loss: [31.760682106018066, 0.03097432851791382]\n",
      "  batch 12 loss: [32.26914405822754, 0.08114223182201385]\n",
      "  batch 14 loss: [34.8593864440918, 0.04751522280275822]\n",
      "  batch 16 loss: [38.29162788391113, 0.03850847017019987]\n",
      "  batch 18 loss: [30.168723106384277, 0.03218756429851055]\n",
      "  batch 20 loss: [34.15480899810791, 0.18988985568284988]\n",
      "  batch 22 loss: [38.247474670410156, 0.08366577699780464]\n",
      "  batch 24 loss: [34.27462100982666, 0.02678575925529003]\n",
      "  batch 26 loss: [33.66292476654053, 0.018835337832570076]\n",
      "  batch 28 loss: [35.37399864196777, 0.03605051338672638]\n",
      "  batch 30 loss: [34.02773094177246, 0.009181249421089888]\n",
      "  batch 32 loss: [32.251516342163086, 0.07446194067597389]\n",
      "  batch 34 loss: [33.21508026123047, 0.03307189606130123]\n",
      "  batch 36 loss: [35.9633674621582, 0.03114840481430292]\n",
      "  batch 38 loss: [28.59593963623047, 0.08291381411254406]\n",
      "  batch 40 loss: [30.959181785583496, 0.051485318690538406]\n",
      "  batch 42 loss: [34.29163932800293, 0.026408815756440163]\n",
      "  batch 44 loss: [36.3743782043457, 0.013451992068439722]\n",
      "  batch 46 loss: [40.7428092956543, 0.009133441373705864]\n",
      "  batch 48 loss: [35.02426528930664, 0.03288393374532461]\n",
      "  batch 50 loss: [37.28632640838623, 0.03661022521555424]\n",
      "  batch 52 loss: [27.866512298583984, 0.03284827806055546]\n",
      "  batch 54 loss: [31.218297958374023, 0.033855835907161236]\n",
      "LOSS generator 31.218297958374023 discriminator 0.033855835907161236\n",
      "EPOCH 252:\n",
      "  batch 0 loss: [41.05338668823242, 0.010000806301832199]\n",
      "  batch 2 loss: [31.029129028320312, 0.024423479102551937]\n",
      "  batch 4 loss: [34.52425003051758, 0.017565761227160692]\n",
      "  batch 6 loss: [34.56020927429199, 0.020334352273494005]\n",
      "  batch 8 loss: [31.131643295288086, 0.028560538543388247]\n",
      "  batch 10 loss: [36.297603607177734, 0.02572445012629032]\n",
      "  batch 12 loss: [39.91250991821289, 0.021247674711048603]\n",
      "  batch 14 loss: [37.447105407714844, 0.011479920707643032]\n",
      "  batch 16 loss: [37.46174621582031, 0.010309710400179029]\n",
      "  batch 18 loss: [35.223965644836426, 0.007298450917005539]\n",
      "  batch 20 loss: [31.85557460784912, 0.04816697910428047]\n",
      "  batch 22 loss: [29.480708122253418, 0.10382680222392082]\n",
      "  batch 24 loss: [28.67637348175049, 0.05123742762953043]\n",
      "  batch 26 loss: [27.694680213928223, 0.027430158108472824]\n",
      "  batch 28 loss: [32.27547836303711, 0.008602390764281154]\n",
      "  batch 30 loss: [28.32009983062744, 0.024843614548444748]\n",
      "  batch 32 loss: [34.759178161621094, 0.010491062887012959]\n",
      "  batch 34 loss: [35.47926330566406, 0.02231601160019636]\n",
      "  batch 36 loss: [36.4633731842041, 0.007742848247289658]\n",
      "  batch 38 loss: [26.985942840576172, 0.026096496731042862]\n",
      "  batch 40 loss: [33.70848846435547, 0.042462488636374474]\n",
      "  batch 42 loss: [37.83187294006348, 0.02178836800158024]\n",
      "  batch 44 loss: [35.66618633270264, 0.05371963977813721]\n",
      "  batch 46 loss: [42.255544662475586, 0.047462550923228264]\n",
      "  batch 48 loss: [41.126708984375, 0.012093377998098731]\n",
      "  batch 50 loss: [32.507097244262695, 0.04108669050037861]\n",
      "  batch 52 loss: [33.60099411010742, 0.040585264563560486]\n",
      "  batch 54 loss: [33.80170822143555, 0.01973653770983219]\n",
      "LOSS generator 33.80170822143555 discriminator 0.01973653770983219\n",
      "EPOCH 253:\n",
      "  batch 0 loss: [31.943923950195312, 0.0685829222202301]\n",
      "  batch 2 loss: [33.295204162597656, 0.10442989319562912]\n",
      "  batch 4 loss: [30.559311866760254, 0.03352827485650778]\n",
      "  batch 6 loss: [40.01162147521973, 0.04810415953397751]\n",
      "  batch 8 loss: [36.55408477783203, 0.03571273619309068]\n",
      "  batch 10 loss: [39.54958152770996, 0.011780550703406334]\n",
      "  batch 12 loss: [29.21963405609131, 0.04688790440559387]\n",
      "  batch 14 loss: [38.4741153717041, 0.02866291906684637]\n",
      "  batch 16 loss: [37.16840171813965, 0.01037734467536211]\n",
      "  batch 18 loss: [35.37009239196777, 0.062356858514249325]\n",
      "  batch 20 loss: [30.414193153381348, 0.03748061880469322]\n",
      "  batch 22 loss: [30.00991439819336, 0.040197862312197685]\n",
      "  batch 24 loss: [26.618268966674805, 0.07762979064136744]\n",
      "  batch 26 loss: [31.790642738342285, 0.02331445924937725]\n",
      "  batch 28 loss: [34.056053161621094, 0.042439697310328484]\n",
      "  batch 30 loss: [35.05217361450195, 0.027415350545197725]\n",
      "  batch 32 loss: [31.685617446899414, 0.027925364207476377]\n",
      "  batch 34 loss: [32.68754005432129, 0.020257404074072838]\n",
      "  batch 36 loss: [30.125839233398438, 0.01895770523697138]\n",
      "  batch 38 loss: [28.817829132080078, 0.01212053606286645]\n",
      "  batch 40 loss: [35.460060119628906, 0.014226955361664295]\n",
      "  batch 42 loss: [33.86273193359375, 0.005878633353859186]\n",
      "  batch 44 loss: [33.07591438293457, 0.014524949248880148]\n",
      "  batch 46 loss: [34.66623783111572, 0.004942916566506028]\n",
      "  batch 48 loss: [33.081729888916016, 0.009515883401036263]\n",
      "  batch 50 loss: [46.68046760559082, 0.020507078617811203]\n",
      "  batch 52 loss: [37.83740520477295, 0.025588173884898424]\n",
      "  batch 54 loss: [35.19670581817627, 0.02090979367494583]\n",
      "LOSS generator 35.19670581817627 discriminator 0.02090979367494583\n",
      "EPOCH 254:\n",
      "  batch 0 loss: [28.19635009765625, 0.015300823375582695]\n",
      "  batch 2 loss: [33.94899368286133, 0.004053054843097925]\n",
      "  batch 4 loss: [38.13392448425293, 0.029167382046580315]\n",
      "  batch 6 loss: [33.2712287902832, 0.008650607895106077]\n",
      "  batch 8 loss: [39.60638236999512, 0.031216545030474663]\n",
      "  batch 10 loss: [37.31554412841797, 0.02006424218416214]\n",
      "  batch 12 loss: [32.10173225402832, 0.00826282799243927]\n",
      "  batch 14 loss: [39.649091720581055, 0.020493505289778113]\n",
      "  batch 16 loss: [34.775733947753906, 0.021617653081193566]\n",
      "  batch 18 loss: [38.41586112976074, 0.008644459769129753]\n",
      "  batch 20 loss: [38.35540962219238, 0.027738278731703758]\n",
      "  batch 22 loss: [34.26968765258789, 0.029175008181482553]\n",
      "  batch 24 loss: [29.101322174072266, 0.03549771010875702]\n",
      "  batch 26 loss: [27.992886543273926, 0.032578022219240665]\n",
      "  batch 28 loss: [30.283846855163574, 0.02507279673591256]\n",
      "  batch 30 loss: [32.36257743835449, 0.011139142792671919]\n",
      "  batch 32 loss: [37.78912162780762, 0.004860329674556851]\n",
      "  batch 34 loss: [40.31508827209473, 0.004104676831047982]\n",
      "  batch 36 loss: [31.29229736328125, 0.012163559906184673]\n",
      "  batch 38 loss: [33.546531677246094, 0.01149873249232769]\n",
      "  batch 40 loss: [35.351922035217285, 0.015979018062353134]\n",
      "  batch 42 loss: [29.892044067382812, 0.007215479272417724]\n",
      "  batch 44 loss: [36.091970443725586, 0.010369205847382545]\n",
      "  batch 46 loss: [30.272170066833496, 0.037858817260712385]\n",
      "  batch 48 loss: [39.6444206237793, 0.010678659193217754]\n",
      "  batch 50 loss: [37.869516372680664, 0.09870257088914514]\n",
      "  batch 52 loss: [32.221017837524414, 0.031545182690024376]\n",
      "  batch 54 loss: [32.35963249206543, 0.03034011833369732]\n",
      "LOSS generator 32.35963249206543 discriminator 0.03034011833369732\n",
      "EPOCH 255:\n",
      "  batch 0 loss: [41.019447326660156, 0.010242771357297897]\n",
      "  batch 2 loss: [35.32985496520996, 0.015153686981648207]\n",
      "  batch 4 loss: [29.839529991149902, 0.035958328284323215]\n",
      "  batch 6 loss: [33.91006374359131, 0.05016034794971347]\n",
      "  batch 8 loss: [43.10574722290039, 0.018940679728984833]\n",
      "  batch 10 loss: [36.11268138885498, 0.0749385803937912]\n",
      "  batch 12 loss: [34.75747299194336, 0.1400156281888485]\n",
      "  batch 14 loss: [28.406920433044434, 0.1273293662816286]\n",
      "  batch 16 loss: [40.72382354736328, 0.10153709352016449]\n",
      "  batch 18 loss: [31.536460876464844, 0.0956324078142643]\n",
      "  batch 20 loss: [32.48650932312012, 0.05068756826221943]\n",
      "  batch 22 loss: [34.273193359375, 0.019678284414112568]\n",
      "  batch 24 loss: [32.63430595397949, 0.026966202771291137]\n",
      "  batch 26 loss: [33.85616874694824, 0.012760497629642487]\n",
      "  batch 28 loss: [31.305131912231445, 0.014440374448895454]\n",
      "  batch 30 loss: [31.89624786376953, 0.012693827040493488]\n",
      "  batch 32 loss: [33.62062454223633, 0.03117172885686159]\n",
      "  batch 34 loss: [33.61293029785156, 0.03639540262520313]\n",
      "  batch 36 loss: [33.79478645324707, 0.03033060720190406]\n",
      "  batch 38 loss: [37.14916229248047, 0.010757708922028542]\n",
      "  batch 40 loss: [31.29077911376953, 0.014917829539626837]\n",
      "  batch 42 loss: [38.07114791870117, 0.024705507792532444]\n",
      "  batch 44 loss: [31.251416206359863, 0.014658651314675808]\n",
      "  batch 46 loss: [37.66275501251221, 0.02177385427057743]\n",
      "  batch 48 loss: [30.790523529052734, 0.01723207114264369]\n",
      "  batch 50 loss: [35.081220626831055, 0.027055487735196948]\n",
      "  batch 52 loss: [31.17682456970215, 0.05370086804032326]\n",
      "  batch 54 loss: [29.91754150390625, 0.02299054665490985]\n",
      "LOSS generator 29.91754150390625 discriminator 0.02299054665490985\n",
      "EPOCH 256:\n",
      "  batch 0 loss: [34.16914367675781, 0.11783147603273392]\n",
      "  batch 2 loss: [30.36052417755127, 0.02148771332576871]\n",
      "  batch 4 loss: [35.71242904663086, 0.015835159458220005]\n",
      "  batch 6 loss: [36.131826400756836, 0.030647466192021966]\n",
      "  batch 8 loss: [28.217548370361328, 0.027696676552295685]\n",
      "  batch 10 loss: [32.425981521606445, 0.006345757283270359]\n",
      "  batch 12 loss: [31.77699851989746, 0.016671184450387955]\n",
      "  batch 14 loss: [34.206031799316406, 0.04304848052561283]\n",
      "  batch 16 loss: [40.263357162475586, 0.020643779076635838]\n",
      "  batch 18 loss: [33.47278022766113, 0.010451686568558216]\n",
      "  batch 20 loss: [36.229705810546875, 0.013789006974548101]\n",
      "  batch 22 loss: [34.83517837524414, 0.004651919007301331]\n",
      "  batch 24 loss: [34.78919219970703, 0.09606869891285896]\n",
      "  batch 26 loss: [29.238012313842773, 0.053769197314977646]\n",
      "  batch 28 loss: [39.237504959106445, 0.2196262925863266]\n",
      "  batch 30 loss: [33.797606468200684, 0.10269312560558319]\n",
      "  batch 32 loss: [34.38837242126465, 0.06909018196165562]\n",
      "  batch 34 loss: [38.96457862854004, 0.08505310397595167]\n",
      "  batch 36 loss: [37.54605293273926, 0.05546972528100014]\n",
      "  batch 38 loss: [40.73460578918457, 0.028476130217313766]\n",
      "  batch 40 loss: [28.775291442871094, 0.1119664553552866]\n",
      "  batch 42 loss: [34.94670486450195, 0.05379907786846161]\n",
      "  batch 44 loss: [35.22002029418945, 0.014562123455107212]\n",
      "  batch 46 loss: [31.06670570373535, 0.02521359082311392]\n",
      "  batch 48 loss: [31.872069358825684, 0.016992129385471344]\n",
      "  batch 50 loss: [37.11874008178711, 0.009117003064602613]\n",
      "  batch 52 loss: [33.032835960388184, 0.017720448784530163]\n",
      "  batch 54 loss: [33.7808952331543, 0.02174526813905686]\n",
      "LOSS generator 33.7808952331543 discriminator 0.02174526813905686\n",
      "EPOCH 257:\n",
      "  batch 0 loss: [27.42810821533203, 0.05093349516391754]\n",
      "  batch 2 loss: [41.91657829284668, 0.029302316368557513]\n",
      "  batch 4 loss: [35.616766929626465, 0.02751354780048132]\n",
      "  batch 6 loss: [31.96415138244629, 0.014872562140226364]\n",
      "  batch 8 loss: [34.267391204833984, 0.01628050021827221]\n",
      "  batch 10 loss: [40.29318428039551, 0.028395191417075694]\n",
      "  batch 12 loss: [39.82406425476074, 0.013843266293406487]\n",
      "  batch 14 loss: [41.24858856201172, 0.01740115135908127]\n",
      "  batch 16 loss: [32.05640125274658, 0.01786200236529112]\n",
      "  batch 18 loss: [33.542510986328125, 0.11547747533768415]\n",
      "  batch 20 loss: [29.41685199737549, 0.03426548931747675]\n",
      "  batch 22 loss: [29.34654712677002, 0.4844697117805481]\n",
      "  batch 24 loss: [31.137563705444336, 0.2870115041732788]\n",
      "  batch 26 loss: [33.284820556640625, 0.160067830234766]\n",
      "  batch 28 loss: [27.769466400146484, 0.16897082701325417]\n",
      "  batch 30 loss: [26.525525093078613, 0.03812852315604687]\n",
      "  batch 32 loss: [37.214378356933594, 0.012106040958315134]\n",
      "  batch 34 loss: [32.25269603729248, 0.03988354420289397]\n",
      "  batch 36 loss: [31.85679340362549, 0.04942131228744984]\n",
      "  batch 38 loss: [36.70491027832031, 0.012613918166607618]\n",
      "  batch 40 loss: [36.90491199493408, 0.010993881151080132]\n",
      "  batch 42 loss: [37.14930725097656, 0.020241623744368553]\n",
      "  batch 44 loss: [38.10304832458496, 0.06625694036483765]\n",
      "  batch 46 loss: [30.337690353393555, 0.02316916733980179]\n",
      "  batch 48 loss: [35.377925872802734, 0.016887021018192172]\n",
      "  batch 50 loss: [33.01218032836914, 0.015195174142718315]\n",
      "  batch 52 loss: [29.73552131652832, 0.02066792594268918]\n",
      "  batch 54 loss: [30.164140701293945, 0.020445624366402626]\n",
      "LOSS generator 30.164140701293945 discriminator 0.020445624366402626\n",
      "EPOCH 258:\n",
      "  batch 0 loss: [28.463491439819336, 0.05272553861141205]\n",
      "  batch 2 loss: [31.110966682434082, 0.01662869146093726]\n",
      "  batch 4 loss: [40.438886642456055, 0.027230885112658143]\n",
      "  batch 6 loss: [38.19888496398926, 0.01195452269166708]\n",
      "  batch 8 loss: [34.88955307006836, 0.02675456553697586]\n",
      "  batch 10 loss: [42.045156478881836, 0.006640727166086435]\n",
      "  batch 12 loss: [35.81865692138672, 0.010679204016923904]\n",
      "  batch 14 loss: [32.93022918701172, 0.022546641528606415]\n",
      "  batch 16 loss: [28.99989891052246, 0.022201070096343756]\n",
      "  batch 18 loss: [36.01131248474121, 0.16433837451040745]\n",
      "  batch 20 loss: [30.93404197692871, 0.02000647410750389]\n",
      "  batch 22 loss: [40.2830810546875, 0.04302218556404114]\n",
      "  batch 24 loss: [33.79417896270752, 0.010854621883481741]\n",
      "  batch 26 loss: [35.832353591918945, 0.004786985693499446]\n",
      "  batch 28 loss: [33.10866451263428, 0.005961537593975663]\n",
      "  batch 30 loss: [33.99271869659424, 0.007694821339100599]\n",
      "  batch 32 loss: [35.01506423950195, 0.012715955264866352]\n",
      "  batch 34 loss: [34.14090442657471, 0.016013008542358875]\n",
      "  batch 36 loss: [35.1878662109375, 0.014808650128543377]\n",
      "  batch 38 loss: [32.043612480163574, 0.030664494959637523]\n",
      "  batch 40 loss: [32.91702842712402, 0.04039070289582014]\n",
      "  batch 42 loss: [35.186363220214844, 0.03712970146443695]\n",
      "  batch 44 loss: [34.22089958190918, 0.02916317479684949]\n",
      "  batch 46 loss: [33.054017066955566, 0.02082785591483116]\n",
      "  batch 48 loss: [37.23734092712402, 0.016238216310739517]\n",
      "  batch 50 loss: [34.17199516296387, 0.013881076127290726]\n",
      "  batch 52 loss: [30.947504997253418, 0.020072354469448328]\n",
      "  batch 54 loss: [31.39982318878174, 0.024536006152629852]\n",
      "LOSS generator 31.39982318878174 discriminator 0.024536006152629852\n",
      "EPOCH 259:\n",
      "  batch 0 loss: [29.066926956176758, 0.10680161416530609]\n",
      "  batch 2 loss: [31.566484451293945, 0.033805477898567915]\n",
      "  batch 4 loss: [28.132628440856934, 0.031095324084162712]\n",
      "  batch 6 loss: [34.77348518371582, 0.014789936132729053]\n",
      "  batch 8 loss: [39.9234619140625, 0.0178626945707947]\n",
      "  batch 10 loss: [34.26931190490723, 0.009480403736233711]\n",
      "  batch 12 loss: [35.033406257629395, 0.010858760913833976]\n",
      "  batch 14 loss: [26.17678165435791, 0.072962187230587]\n",
      "  batch 16 loss: [32.57313346862793, 0.024169559590518475]\n",
      "  batch 18 loss: [30.90479278564453, 0.017382819205522537]\n",
      "  batch 20 loss: [34.68460941314697, 0.010782170691527426]\n",
      "  batch 22 loss: [30.919172286987305, 0.010142761748284101]\n",
      "  batch 24 loss: [39.34882736206055, 0.029196648858487606]\n",
      "  batch 26 loss: [34.97353935241699, 0.009589192224666476]\n",
      "  batch 28 loss: [32.84401893615723, 0.1781848892569542]\n",
      "  batch 30 loss: [33.67282485961914, 0.012813798850402236]\n",
      "  batch 32 loss: [33.02642631530762, 0.0426933579146862]\n",
      "  batch 34 loss: [34.981712341308594, 0.023126068525016308]\n",
      "  batch 36 loss: [36.60508918762207, 0.012903648894280195]\n",
      "  batch 38 loss: [33.63107872009277, 0.013639000244438648]\n",
      "  batch 40 loss: [35.08660316467285, 0.013471984304487705]\n",
      "  batch 42 loss: [35.55774688720703, 0.007408716017380357]\n",
      "  batch 44 loss: [34.797109603881836, 0.022741911932826042]\n",
      "  batch 46 loss: [35.864662170410156, 0.018414017278701067]\n",
      "  batch 48 loss: [34.04566764831543, 0.005794630153104663]\n",
      "  batch 50 loss: [35.82582092285156, 0.0037478411104530096]\n",
      "  batch 52 loss: [38.11341667175293, 0.009702506009489298]\n",
      "  batch 54 loss: [38.826133728027344, 0.009228162467479706]\n",
      "LOSS generator 38.826133728027344 discriminator 0.009228162467479706\n",
      "EPOCH 260:\n",
      "  batch 0 loss: [40.45944595336914, 0.004492664709687233]\n",
      "  batch 2 loss: [32.60981559753418, 0.021750015672296286]\n",
      "  batch 4 loss: [34.05217742919922, 0.010654021345544606]\n",
      "  batch 6 loss: [35.65657997131348, 0.022205942310392857]\n",
      "  batch 8 loss: [37.72614288330078, 0.018398824147880077]\n",
      "  batch 10 loss: [32.48824882507324, 0.009887988911941648]\n",
      "  batch 12 loss: [32.78969097137451, 0.00989388709422201]\n",
      "  batch 14 loss: [33.349260330200195, 0.035114989848807454]\n",
      "  batch 16 loss: [32.16378688812256, 0.009990086778998375]\n",
      "  batch 18 loss: [34.483177185058594, 0.048887318756897]\n",
      "  batch 20 loss: [36.40072822570801, 0.03338363114744425]\n",
      "  batch 22 loss: [33.080575942993164, 0.02390154730528593]\n",
      "  batch 24 loss: [39.41836738586426, 0.2924514412879944]\n",
      "  batch 26 loss: [39.10966682434082, 0.14111647009849548]\n",
      "  batch 28 loss: [35.96730041503906, 0.0072241813177242875]\n",
      "  batch 30 loss: [30.469298362731934, 0.05083289369940758]\n",
      "  batch 32 loss: [28.654229164123535, 0.03119001747108996]\n",
      "  batch 34 loss: [34.08384132385254, 0.006795624038204551]\n",
      "  batch 36 loss: [30.27006721496582, 0.02950883097946644]\n",
      "  batch 38 loss: [34.5224494934082, 0.012704874388873577]\n",
      "  batch 40 loss: [39.172149658203125, 0.016629605554044247]\n",
      "  batch 42 loss: [31.368836402893066, 0.017109951935708523]\n",
      "  batch 44 loss: [34.98537063598633, 0.006810932885855436]\n",
      "  batch 46 loss: [35.11194038391113, 0.08274471387267113]\n",
      "  batch 48 loss: [31.998083114624023, 0.012333218939602375]\n",
      "  batch 50 loss: [27.730804443359375, 0.03999333828687668]\n",
      "  batch 52 loss: [40.20623779296875, 0.03245155280455947]\n",
      "  batch 54 loss: [35.99683380126953, 0.02758803404867649]\n",
      "LOSS generator 35.99683380126953 discriminator 0.02758803404867649\n",
      "EPOCH 261:\n",
      "  batch 0 loss: [29.9372501373291, 0.010533377528190613]\n",
      "  batch 2 loss: [33.92440414428711, 0.010020763147622347]\n",
      "  batch 4 loss: [31.358118057250977, 0.019357753917574883]\n",
      "  batch 6 loss: [35.635361671447754, 0.0235533369705081]\n",
      "  batch 8 loss: [31.999199867248535, 0.006509033963084221]\n",
      "  batch 10 loss: [40.38241958618164, 0.0310635631904006]\n",
      "  batch 12 loss: [35.087995529174805, 0.00879347464069724]\n",
      "  batch 14 loss: [34.23238563537598, 0.014301220420747995]\n",
      "  batch 16 loss: [37.62217712402344, 0.0075745307840406895]\n",
      "  batch 18 loss: [37.075843811035156, 0.020857341587543488]\n",
      "  batch 20 loss: [35.16523742675781, 0.02043041493743658]\n",
      "  batch 22 loss: [34.57291030883789, 0.011057109571993351]\n",
      "  batch 24 loss: [34.588327407836914, 0.01367738377302885]\n",
      "  batch 26 loss: [26.09694004058838, 0.11383292498067021]\n",
      "  batch 28 loss: [29.88985538482666, 0.0238955644890666]\n",
      "  batch 30 loss: [32.391483306884766, 0.012067699572071433]\n",
      "  batch 32 loss: [35.489213943481445, 0.013594659510999918]\n",
      "  batch 34 loss: [35.31707000732422, 0.00847339117899537]\n",
      "  batch 36 loss: [42.42250442504883, 0.009536868892610073]\n",
      "  batch 38 loss: [39.84819030761719, 0.020774558885022998]\n",
      "  batch 40 loss: [33.6246223449707, 0.02706517931073904]\n",
      "  batch 42 loss: [31.60719394683838, 0.027920469641685486]\n",
      "  batch 44 loss: [43.01816177368164, 0.02389561850577593]\n",
      "  batch 46 loss: [36.01701831817627, 0.022844484774395823]\n",
      "  batch 48 loss: [29.251688957214355, 0.012278235517442226]\n",
      "  batch 50 loss: [32.825246810913086, 0.02714206837117672]\n",
      "  batch 52 loss: [36.162771224975586, 0.00906002416741103]\n",
      "  batch 54 loss: [33.81790733337402, 0.007114797946996987]\n",
      "LOSS generator 33.81790733337402 discriminator 0.007114797946996987\n",
      "EPOCH 262:\n",
      "  batch 0 loss: [32.68820571899414, 0.003953157924115658]\n",
      "  batch 2 loss: [33.4879732131958, 0.011447055265307426]\n",
      "  batch 4 loss: [32.75675392150879, 0.014720797073096037]\n",
      "  batch 6 loss: [36.2662239074707, 0.006269877892918885]\n",
      "  batch 8 loss: [36.41069984436035, 0.0063570220954716206]\n",
      "  batch 10 loss: [34.26286506652832, 0.005294076167047024]\n",
      "  batch 12 loss: [36.89469814300537, 0.010880292393267155]\n",
      "  batch 14 loss: [36.64816093444824, 0.007382588577456772]\n",
      "  batch 16 loss: [35.99821472167969, 0.11785986961331218]\n",
      "  batch 18 loss: [39.72888374328613, 0.02396835060790181]\n",
      "  batch 20 loss: [40.2649040222168, 0.008489183615893126]\n",
      "  batch 22 loss: [30.895944595336914, 0.010014425031840801]\n",
      "  batch 24 loss: [37.75698661804199, 0.0428566113114357]\n",
      "  batch 26 loss: [35.845468521118164, 0.006170806707814336]\n",
      "  batch 28 loss: [38.60016632080078, 0.0061263368697836995]\n",
      "  batch 30 loss: [32.47919940948486, 0.012104800902307034]\n",
      "  batch 32 loss: [36.842647552490234, 0.0035541567485779524]\n",
      "  batch 34 loss: [36.548179626464844, 0.010699805803596973]\n",
      "  batch 36 loss: [28.463777542114258, 0.012710567098110914]\n",
      "  batch 38 loss: [35.07920265197754, 0.007451709825545549]\n",
      "  batch 40 loss: [33.1599817276001, 0.01426760759204626]\n",
      "  batch 42 loss: [37.82822799682617, 0.008056411985307932]\n",
      "  batch 44 loss: [34.622169494628906, 0.007550809532403946]\n",
      "  batch 46 loss: [35.1161470413208, 0.014365021605044603]\n",
      "  batch 48 loss: [31.58256721496582, 0.0075226707849651575]\n",
      "  batch 50 loss: [30.320220947265625, 0.03354565612971783]\n",
      "  batch 52 loss: [35.49023246765137, 0.007609063992276788]\n",
      "  batch 54 loss: [27.427565574645996, 0.022631687577813864]\n",
      "LOSS generator 27.427565574645996 discriminator 0.022631687577813864\n",
      "EPOCH 263:\n",
      "  batch 0 loss: [30.308937072753906, 0.006265425123274326]\n",
      "  batch 2 loss: [33.988125801086426, 0.010788029292598367]\n",
      "  batch 4 loss: [31.236576080322266, 0.010062637273222208]\n",
      "  batch 6 loss: [39.047372817993164, 0.01591348508372903]\n",
      "  batch 8 loss: [33.76059150695801, 0.013672834262251854]\n",
      "  batch 10 loss: [38.574262619018555, 0.018661600770428777]\n",
      "  batch 12 loss: [38.91916465759277, 0.05675899796187878]\n",
      "  batch 14 loss: [33.893829345703125, 0.045697493478655815]\n",
      "  batch 16 loss: [35.13442802429199, 0.013500427827239037]\n",
      "  batch 18 loss: [36.33402633666992, 0.008310604374855757]\n",
      "  batch 20 loss: [36.16159629821777, 0.013281719293445349]\n",
      "  batch 22 loss: [33.090396881103516, 0.014108278090134263]\n",
      "  batch 24 loss: [35.11441230773926, 0.014907934237271547]\n",
      "  batch 26 loss: [34.316816329956055, 0.005461835069581866]\n",
      "  batch 28 loss: [36.71114730834961, 0.0077780261635780334]\n",
      "  batch 30 loss: [34.6177396774292, 0.08293566107749939]\n",
      "  batch 32 loss: [35.21416664123535, 0.017260881140828133]\n",
      "  batch 34 loss: [36.57258224487305, 0.04731178469955921]\n",
      "  batch 36 loss: [39.33744430541992, 0.04644566588103771]\n",
      "  batch 38 loss: [35.85699653625488, 0.016866648104041815]\n",
      "  batch 40 loss: [36.764156341552734, 0.031026598997414112]\n",
      "  batch 42 loss: [32.355228424072266, 0.006413718918338418]\n",
      "  batch 44 loss: [30.949636459350586, 0.0115556251257658]\n",
      "  batch 46 loss: [29.33222007751465, 0.007692107930779457]\n",
      "  batch 48 loss: [28.117095947265625, 0.00976971397176385]\n",
      "  batch 50 loss: [39.306087493896484, 0.00452192802913487]\n",
      "  batch 52 loss: [31.23489475250244, 0.011510302545502782]\n",
      "  batch 54 loss: [33.12796974182129, 0.0033274381421506405]\n",
      "LOSS generator 33.12796974182129 discriminator 0.0033274381421506405\n",
      "EPOCH 264:\n",
      "  batch 0 loss: [35.94757080078125, 0.02328016795217991]\n",
      "  batch 2 loss: [33.73347091674805, 0.00738746440038085]\n",
      "  batch 4 loss: [32.83621025085449, 0.003153263358399272]\n",
      "  batch 6 loss: [32.84101867675781, 0.021496234461665154]\n",
      "  batch 8 loss: [38.100154876708984, 0.013010179623961449]\n",
      "  batch 10 loss: [37.569196701049805, 0.014837868278846145]\n",
      "  batch 12 loss: [36.47985076904297, 0.005599140306003392]\n",
      "  batch 14 loss: [36.122507095336914, 0.007810565875843167]\n",
      "  batch 16 loss: [36.87533378601074, 0.005938785150647163]\n",
      "  batch 18 loss: [36.068721771240234, 0.006147966021671891]\n",
      "  batch 20 loss: [35.95072937011719, 0.007917812326923013]\n",
      "  batch 22 loss: [30.86172103881836, 0.016572338063269854]\n",
      "  batch 24 loss: [31.053388595581055, 0.009082498261705041]\n",
      "  batch 26 loss: [35.877716064453125, 0.002744958270341158]\n",
      "  batch 28 loss: [33.0350341796875, 0.00610710890032351]\n",
      "  batch 30 loss: [37.46655082702637, 0.003115941653959453]\n",
      "  batch 32 loss: [34.10982608795166, 0.013883804203942418]\n",
      "  batch 34 loss: [37.61507225036621, 0.015085584367625415]\n",
      "  batch 36 loss: [29.8296480178833, 0.026175732724368572]\n",
      "  batch 38 loss: [39.57228469848633, 0.04949319176375866]\n",
      "  batch 40 loss: [38.2137393951416, 0.00262484943959862]\n",
      "  batch 42 loss: [35.93497657775879, 0.014592274557799101]\n",
      "  batch 44 loss: [25.969276428222656, 0.012658027932047844]\n",
      "  batch 46 loss: [33.18112087249756, 0.0045322764199227095]\n",
      "  batch 48 loss: [39.21611213684082, 0.008801247691735625]\n",
      "  batch 50 loss: [36.48166465759277, 0.017438913928344846]\n",
      "  batch 52 loss: [36.43435478210449, 0.03651196788996458]\n",
      "  batch 54 loss: [33.79365921020508, 0.0063584340969100595]\n",
      "LOSS generator 33.79365921020508 discriminator 0.0063584340969100595\n",
      "EPOCH 265:\n",
      "  batch 0 loss: [26.959983825683594, 0.011093183420598507]\n",
      "  batch 2 loss: [33.326327323913574, 0.011527701281011105]\n",
      "  batch 4 loss: [34.50123405456543, 0.009290300775319338]\n",
      "  batch 6 loss: [37.00018119812012, 0.005862103309482336]\n",
      "  batch 8 loss: [29.81743335723877, 0.017108629224821925]\n",
      "  batch 10 loss: [41.61244010925293, 0.013069694396108389]\n",
      "  batch 12 loss: [33.05031204223633, 0.009169167838990688]\n",
      "  batch 14 loss: [33.95443916320801, 0.004030062118545175]\n",
      "  batch 16 loss: [40.758840560913086, 0.008664919063448906]\n",
      "  batch 18 loss: [38.03425121307373, 0.014432918280363083]\n",
      "  batch 20 loss: [35.04964828491211, 0.005547645268961787]\n",
      "  batch 22 loss: [38.88698768615723, 0.01503277150914073]\n",
      "  batch 24 loss: [37.51139259338379, 0.004967343062162399]\n",
      "  batch 26 loss: [35.981544494628906, 0.006940934748854488]\n",
      "  batch 28 loss: [34.04536056518555, 0.006946453591808677]\n",
      "  batch 30 loss: [33.44647789001465, 0.013731762766838074]\n",
      "  batch 32 loss: [34.84677219390869, 0.017850863747298717]\n",
      "  batch 34 loss: [34.82881736755371, 0.012451933231204748]\n",
      "  batch 36 loss: [33.91054344177246, 0.008799184113740921]\n",
      "  batch 38 loss: [28.311067581176758, 0.05827564059291035]\n",
      "  batch 40 loss: [36.26137351989746, 0.007185126654803753]\n",
      "  batch 42 loss: [32.34336471557617, 0.008999075274914503]\n",
      "  batch 44 loss: [32.57600021362305, 0.010960821760818362]\n",
      "  batch 46 loss: [43.64903259277344, 0.04552837321534753]\n",
      "  batch 48 loss: [39.18338203430176, 0.11401514336466789]\n",
      "  batch 50 loss: [31.116039276123047, 0.03788073547184467]\n",
      "  batch 52 loss: [33.09408473968506, 0.033284162636846304]\n",
      "  batch 54 loss: [33.093788146972656, 0.038375516422092915]\n",
      "LOSS generator 33.093788146972656 discriminator 0.038375516422092915\n",
      "EPOCH 266:\n",
      "  batch 0 loss: [36.181640625, 0.007265720050781965]\n",
      "  batch 2 loss: [32.25715255737305, 0.017091041896492243]\n",
      "  batch 4 loss: [33.90361499786377, 0.016619787784293294]\n",
      "  batch 6 loss: [33.372676849365234, 0.015813789563253522]\n",
      "  batch 8 loss: [34.791534423828125, 0.01088941190391779]\n",
      "  batch 10 loss: [28.672836303710938, 0.009572518989443779]\n",
      "  batch 12 loss: [32.74085235595703, 0.05120180640369654]\n",
      "  batch 14 loss: [31.268136978149414, 0.012601263937540352]\n",
      "  batch 16 loss: [34.88688850402832, 0.006648963317275047]\n",
      "  batch 18 loss: [33.99005126953125, 0.009399559814482927]\n",
      "  batch 20 loss: [37.5488395690918, 0.007363729644566774]\n",
      "  batch 22 loss: [38.11063575744629, 0.0201383912935853]\n",
      "  batch 24 loss: [40.94562530517578, 0.022380686830729246]\n",
      "  batch 26 loss: [27.69714641571045, 0.022712145000696182]\n",
      "  batch 28 loss: [37.49816131591797, 1.7268302887678146]\n",
      "  batch 30 loss: [30.430943489074707, 2.2403281927108765]\n",
      "  batch 32 loss: [30.71690559387207, 0.8315130174160004]\n",
      "  batch 34 loss: [33.34639358520508, 0.8460764586925507]\n",
      "  batch 36 loss: [27.437793731689453, 0.633899986743927]\n",
      "  batch 38 loss: [31.562294960021973, 0.6515063941478729]\n",
      "  batch 40 loss: [33.99888038635254, 0.42605921626091003]\n",
      "  batch 42 loss: [29.52316665649414, 0.23352687805891037]\n",
      "  batch 44 loss: [28.90917682647705, 0.22016355395317078]\n",
      "  batch 46 loss: [30.68836498260498, 0.14274928718805313]\n",
      "  batch 48 loss: [31.999335289001465, 0.08913125842809677]\n",
      "  batch 50 loss: [28.904078483581543, 0.11326611787080765]\n",
      "  batch 52 loss: [29.63258934020996, 0.10501554235816002]\n",
      "  batch 54 loss: [30.86464023590088, 0.045805249363183975]\n",
      "LOSS generator 30.86464023590088 discriminator 0.045805249363183975\n",
      "EPOCH 267:\n",
      "  batch 0 loss: [29.914260864257812, 0.1022467091679573]\n",
      "  batch 2 loss: [29.547134399414062, 0.1683022454380989]\n",
      "  batch 4 loss: [28.111360549926758, 0.1035589687526226]\n",
      "  batch 6 loss: [27.946332931518555, 0.20914174616336823]\n",
      "  batch 8 loss: [33.58123207092285, 0.08828878402709961]\n",
      "  batch 10 loss: [24.86947250366211, 0.10618028417229652]\n",
      "  batch 12 loss: [39.05891799926758, 0.07126941159367561]\n",
      "  batch 14 loss: [34.19621276855469, 0.09199860692024231]\n",
      "  batch 16 loss: [33.25588893890381, 0.05573324300348759]\n",
      "  batch 18 loss: [31.857778549194336, 0.12656636908650398]\n",
      "  batch 20 loss: [29.304274559020996, 0.04444944020360708]\n",
      "  batch 22 loss: [31.57325553894043, 0.1257314383983612]\n",
      "  batch 24 loss: [34.136375427246094, 0.029747972264885902]\n",
      "  batch 26 loss: [32.20268249511719, 0.026505875401198864]\n",
      "  batch 28 loss: [33.94245719909668, 0.022698821499943733]\n",
      "  batch 30 loss: [37.12371253967285, 0.017292216420173645]\n",
      "  batch 32 loss: [31.09927272796631, 0.034473683685064316]\n",
      "  batch 34 loss: [35.84059143066406, 0.05488189682364464]\n",
      "  batch 36 loss: [29.377856254577637, 0.052117420360445976]\n",
      "  batch 38 loss: [33.33359336853027, 0.06080516427755356]\n",
      "  batch 40 loss: [29.187517166137695, 0.03927772864699364]\n",
      "  batch 42 loss: [36.852006912231445, 0.01863555982708931]\n",
      "  batch 44 loss: [29.942331314086914, 0.02282595820724964]\n",
      "  batch 46 loss: [38.66748046875, 0.04346614331007004]\n",
      "  batch 48 loss: [33.17852020263672, 0.05064565083011985]\n",
      "  batch 50 loss: [33.647765159606934, 0.053633421659469604]\n",
      "  batch 52 loss: [27.087695121765137, 0.12485053762793541]\n",
      "  batch 54 loss: [31.993133544921875, 0.028603208251297474]\n",
      "LOSS generator 31.993133544921875 discriminator 0.028603208251297474\n",
      "EPOCH 268:\n",
      "  batch 0 loss: [34.42185592651367, 0.006217343732714653]\n",
      "  batch 2 loss: [30.87023639678955, 0.03435860062018037]\n",
      "  batch 4 loss: [38.64353561401367, 0.028193785343319178]\n",
      "  batch 6 loss: [35.95509910583496, 0.01870970893651247]\n",
      "  batch 8 loss: [34.04094123840332, 0.04448654316365719]\n",
      "  batch 10 loss: [30.748737335205078, 0.024900881573557854]\n",
      "  batch 12 loss: [37.298723220825195, 0.02813352644443512]\n",
      "  batch 14 loss: [34.07163429260254, 0.025481434538960457]\n",
      "  batch 16 loss: [34.652339935302734, 0.034583475440740585]\n",
      "  batch 18 loss: [31.9803524017334, 0.2169704269617796]\n",
      "  batch 20 loss: [32.154296875, 0.06033198721706867]\n",
      "  batch 22 loss: [32.893999099731445, 0.02254450973123312]\n",
      "  batch 24 loss: [37.901838302612305, 0.030087800696492195]\n",
      "  batch 26 loss: [35.944175720214844, 0.02805359521880746]\n",
      "  batch 28 loss: [30.823047637939453, 0.021920010447502136]\n",
      "  batch 30 loss: [35.90063667297363, 0.036133697256445885]\n",
      "  batch 32 loss: [35.24905967712402, 0.025060894899070263]\n",
      "  batch 34 loss: [38.09742546081543, 0.0612255334854126]\n",
      "  batch 36 loss: [32.09850025177002, 0.02835172601044178]\n",
      "  batch 38 loss: [29.40452766418457, 0.06091890297830105]\n",
      "  batch 40 loss: [33.471914291381836, 0.04243631660938263]\n",
      "  batch 42 loss: [34.85818672180176, 0.034113096073269844]\n",
      "  batch 44 loss: [40.65441131591797, 0.022428425028920174]\n",
      "  batch 46 loss: [28.503313064575195, 0.05304999276995659]\n",
      "  batch 48 loss: [30.823646545410156, 0.03311994485557079]\n",
      "  batch 50 loss: [30.19804859161377, 0.017607498914003372]\n",
      "  batch 52 loss: [28.082439422607422, 0.015197950880974531]\n",
      "  batch 54 loss: [34.21635818481445, 0.02264643833041191]\n",
      "LOSS generator 34.21635818481445 discriminator 0.02264643833041191\n",
      "EPOCH 269:\n",
      "  batch 0 loss: [41.113525390625, 0.02032613568007946]\n",
      "  batch 2 loss: [35.57497978210449, 0.012649263720959425]\n",
      "  batch 4 loss: [37.150779724121094, 0.014500414486974478]\n",
      "  batch 6 loss: [34.41801166534424, 0.013085821643471718]\n",
      "  batch 8 loss: [39.73764610290527, 0.009381620679050684]\n",
      "  batch 10 loss: [36.920087814331055, 0.0244862399995327]\n",
      "  batch 12 loss: [30.800257682800293, 0.020376290660351515]\n",
      "  batch 14 loss: [29.534488677978516, 0.28856920450925827]\n",
      "  batch 16 loss: [33.732139587402344, 0.040360769256949425]\n",
      "  batch 18 loss: [36.83881187438965, 0.0379372788593173]\n",
      "  batch 20 loss: [34.39893817901611, 0.028060149401426315]\n",
      "  batch 22 loss: [36.71180725097656, 0.006776917027309537]\n",
      "  batch 24 loss: [33.709882736206055, 0.04124977719038725]\n",
      "  batch 26 loss: [30.46714210510254, 0.04965216852724552]\n",
      "  batch 28 loss: [32.28172779083252, 0.08111526817083359]\n",
      "  batch 30 loss: [32.20000743865967, 0.0528762040194124]\n",
      "  batch 32 loss: [30.269224166870117, 0.012283266056329012]\n",
      "  batch 34 loss: [34.22648048400879, 0.012839872855693102]\n",
      "  batch 36 loss: [28.662720680236816, 0.021644254215061665]\n",
      "  batch 38 loss: [36.53203582763672, 0.031589468475431204]\n",
      "  batch 40 loss: [35.78355598449707, 0.038151733577251434]\n",
      "  batch 42 loss: [36.813385009765625, 0.010307303164154291]\n",
      "  batch 44 loss: [37.28500938415527, 0.02011806913651526]\n",
      "  batch 46 loss: [34.08543109893799, 0.014279517810791731]\n",
      "  batch 48 loss: [33.20020771026611, 0.010454825591295958]\n",
      "  batch 50 loss: [34.03153133392334, 0.007401701994240284]\n",
      "  batch 52 loss: [35.26406955718994, 0.021544447168707848]\n",
      "  batch 54 loss: [29.958459854125977, 0.011377601884305477]\n",
      "LOSS generator 29.958459854125977 discriminator 0.011377601884305477\n",
      "EPOCH 270:\n",
      "  batch 0 loss: [41.08289337158203, 0.015622632578015327]\n",
      "  batch 2 loss: [27.51492691040039, 0.01019971864297986]\n",
      "  batch 4 loss: [40.328819274902344, 0.008917611092329025]\n",
      "  batch 6 loss: [35.84820556640625, 0.008446939988061786]\n",
      "  batch 8 loss: [31.170775413513184, 0.014748255489394069]\n",
      "  batch 10 loss: [31.718098640441895, 0.027610791847109795]\n",
      "  batch 12 loss: [32.04811382293701, 0.021483562886714935]\n",
      "  batch 14 loss: [32.65237045288086, 0.007468057097867131]\n",
      "  batch 16 loss: [35.4191951751709, 0.01640099147334695]\n",
      "  batch 18 loss: [33.50247764587402, 0.1651143680792302]\n",
      "  batch 20 loss: [35.31562042236328, 0.0451582008972764]\n",
      "  batch 22 loss: [32.48989295959473, 0.008869749493896961]\n",
      "  batch 24 loss: [36.01120471954346, 0.022300495766103268]\n",
      "  batch 26 loss: [33.6242790222168, 0.010993364965543151]\n",
      "  batch 28 loss: [32.19131278991699, 0.0054950014455243945]\n",
      "  batch 30 loss: [36.552114486694336, 0.015599998645484447]\n",
      "  batch 32 loss: [35.8950309753418, 0.008635909063741565]\n",
      "  batch 34 loss: [33.95085334777832, 0.005672060186043382]\n",
      "  batch 36 loss: [38.086660385131836, 0.008662826381623745]\n",
      "  batch 38 loss: [35.39437294006348, 0.03133645001798868]\n",
      "  batch 40 loss: [43.24898719787598, 0.0234238151460886]\n",
      "  batch 42 loss: [37.73206043243408, 0.011479011620394886]\n",
      "  batch 44 loss: [30.749032020568848, 0.09409302636049688]\n",
      "  batch 46 loss: [38.392391204833984, 0.03640501666814089]\n",
      "  batch 48 loss: [37.364681243896484, 0.122572872787714]\n",
      "  batch 50 loss: [32.15593147277832, 0.05973838269710541]\n",
      "  batch 52 loss: [28.470319747924805, 0.09458354022353888]\n",
      "  batch 54 loss: [31.349122047424316, 0.03993184957653284]\n",
      "LOSS generator 31.349122047424316 discriminator 0.03993184957653284\n",
      "EPOCH 271:\n",
      "  batch 0 loss: [27.56124496459961, 0.022981926798820496]\n",
      "  batch 2 loss: [25.50318717956543, 0.1576737565919757]\n",
      "  batch 4 loss: [33.17031764984131, 0.007213196717202663]\n",
      "  batch 6 loss: [38.038686752319336, 0.10389810521155596]\n",
      "  batch 8 loss: [35.82041931152344, 0.08572698384523392]\n",
      "  batch 10 loss: [32.12868690490723, 0.021911666728556156]\n",
      "  batch 12 loss: [34.79783630371094, 0.02189693320542574]\n",
      "  batch 14 loss: [33.561699867248535, 0.00813290779478848]\n",
      "  batch 16 loss: [38.57409858703613, 0.011551328003406525]\n",
      "  batch 18 loss: [32.84897041320801, 0.020128801930695772]\n",
      "  batch 20 loss: [37.22424125671387, 0.024894855450838804]\n",
      "  batch 22 loss: [30.0230131149292, 0.018441136460751295]\n",
      "  batch 24 loss: [39.61175727844238, 0.05851305741816759]\n",
      "  batch 26 loss: [25.161526679992676, 0.08376112207770348]\n",
      "  batch 28 loss: [33.74619197845459, 0.03320689219981432]\n",
      "  batch 30 loss: [34.878631591796875, 0.05126780830323696]\n",
      "  batch 32 loss: [31.848796844482422, 0.01641320646740496]\n",
      "  batch 34 loss: [28.76697540283203, 0.011617489624768496]\n",
      "  batch 36 loss: [31.582486152648926, 0.005872033536434174]\n",
      "  batch 38 loss: [35.43514823913574, 0.008491165237501264]\n",
      "  batch 40 loss: [35.11184120178223, 0.010232457425445318]\n",
      "  batch 42 loss: [35.371238708496094, 0.012449555099010468]\n",
      "  batch 44 loss: [43.05869102478027, 0.012780185788869858]\n",
      "  batch 46 loss: [33.01770782470703, 0.010970244533382356]\n",
      "  batch 48 loss: [37.47509956359863, 0.013922745070885867]\n",
      "  batch 50 loss: [34.358741760253906, 0.018975253216922283]\n",
      "  batch 52 loss: [33.8494873046875, 0.010887987911701202]\n",
      "  batch 54 loss: [41.61485290527344, 0.006485326681286097]\n",
      "LOSS generator 41.61485290527344 discriminator 0.006485326681286097\n",
      "EPOCH 272:\n",
      "  batch 0 loss: [36.531246185302734, 0.013902992010116577]\n",
      "  batch 2 loss: [33.68172073364258, 0.00864521344192326]\n",
      "  batch 4 loss: [32.655898094177246, 0.00577137409709394]\n",
      "  batch 6 loss: [31.69658374786377, 0.003511260962113738]\n",
      "  batch 8 loss: [35.942551612854004, 0.04236853029578924]\n",
      "  batch 10 loss: [41.46377944946289, 0.03270966000854969]\n",
      "  batch 12 loss: [29.97230339050293, 0.01153109222650528]\n",
      "  batch 14 loss: [37.678443908691406, 0.011903524398803711]\n",
      "  batch 16 loss: [36.85292625427246, 0.013858166988939047]\n",
      "  batch 18 loss: [34.561461448669434, 0.015587629284709692]\n",
      "  batch 20 loss: [35.78856658935547, 0.002982589998282492]\n",
      "  batch 22 loss: [36.81289291381836, 0.014881289098411798]\n",
      "  batch 24 loss: [35.56336307525635, 0.006946830544620752]\n",
      "  batch 26 loss: [37.216238021850586, 0.010479329153895378]\n",
      "  batch 28 loss: [32.829702377319336, 0.015594269149005413]\n",
      "  batch 30 loss: [40.282514572143555, 0.022624980891123414]\n",
      "  batch 32 loss: [35.287625312805176, 0.031561726704239845]\n",
      "  batch 34 loss: [32.15494155883789, 0.009067833190783858]\n",
      "  batch 36 loss: [35.099239349365234, 0.09833303152117878]\n",
      "  batch 38 loss: [34.05576038360596, 0.023672418668866158]\n",
      "  batch 40 loss: [33.09078025817871, 0.007704310351982713]\n",
      "  batch 42 loss: [34.23590278625488, 0.0037568436237052083]\n",
      "  batch 44 loss: [40.176034927368164, 0.00956944446079433]\n",
      "  batch 46 loss: [32.82311248779297, 0.017988391686230898]\n",
      "  batch 48 loss: [29.75720500946045, 0.007437980733811855]\n",
      "  batch 50 loss: [33.73200225830078, 0.015202502720057964]\n",
      "  batch 52 loss: [32.51625442504883, 0.011789367534220219]\n",
      "  batch 54 loss: [33.41875648498535, 0.018456714693456888]\n",
      "LOSS generator 33.41875648498535 discriminator 0.018456714693456888\n",
      "EPOCH 273:\n",
      "  batch 0 loss: [38.96890640258789, 0.0065887668170034885]\n",
      "  batch 2 loss: [28.275379180908203, 0.013590170070528984]\n",
      "  batch 4 loss: [35.157822608947754, 0.01966047938913107]\n",
      "  batch 6 loss: [39.31973457336426, 0.013812670949846506]\n",
      "  batch 8 loss: [33.82185363769531, 0.09742989228107035]\n",
      "  batch 10 loss: [33.5419921875, 0.005506296409294009]\n",
      "  batch 12 loss: [32.76390266418457, 0.01134257111698389]\n",
      "  batch 14 loss: [40.15915107727051, 0.004017980303615332]\n",
      "  batch 16 loss: [33.55308437347412, 0.007408265955746174]\n",
      "  batch 18 loss: [34.901641845703125, 0.0015440654242411256]\n",
      "  batch 20 loss: [36.869699478149414, 0.031664250418543816]\n",
      "  batch 22 loss: [34.56729507446289, 0.03612495120614767]\n",
      "  batch 24 loss: [34.80156993865967, 0.009378686547279358]\n",
      "  batch 26 loss: [39.82464790344238, 0.009994828142225742]\n",
      "  batch 28 loss: [32.706682205200195, 0.022986019495874643]\n",
      "  batch 30 loss: [30.672086715698242, 0.009580663405358791]\n",
      "  batch 32 loss: [30.798845291137695, 0.0035832759458571672]\n",
      "  batch 34 loss: [37.22775077819824, 0.006313351448625326]\n",
      "  batch 36 loss: [35.29124927520752, 0.015411791857331991]\n",
      "  batch 38 loss: [40.609737396240234, 0.009926805505529046]\n",
      "  batch 40 loss: [38.40900421142578, 0.0028641419485211372]\n",
      "  batch 42 loss: [34.93710517883301, 0.02596491714939475]\n",
      "  batch 44 loss: [36.143009185791016, 0.004841287154704332]\n",
      "  batch 46 loss: [37.76905059814453, 0.01397879864089191]\n",
      "  batch 48 loss: [28.9456787109375, 0.04328463226556778]\n",
      "  batch 50 loss: [35.26018047332764, 0.017576826736330986]\n",
      "  batch 52 loss: [29.01580238342285, 0.023108872584998608]\n",
      "  batch 54 loss: [32.47966957092285, 0.021655510179698467]\n",
      "LOSS generator 32.47966957092285 discriminator 0.021655510179698467\n",
      "EPOCH 274:\n",
      "  batch 0 loss: [32.26617431640625, 0.014945199713110924]\n",
      "  batch 2 loss: [33.47601318359375, 0.006196762900799513]\n",
      "  batch 4 loss: [32.53537368774414, 0.00515286042355001]\n",
      "  batch 6 loss: [33.093976974487305, 0.16053998551797122]\n",
      "  batch 8 loss: [35.91197204589844, 0.02506293961778283]\n",
      "  batch 10 loss: [34.815486907958984, 0.01720561448018998]\n",
      "  batch 12 loss: [35.260592460632324, 0.028769019758328795]\n",
      "  batch 14 loss: [32.341407775878906, 0.09287107735872269]\n",
      "  batch 16 loss: [35.31121253967285, 1.1516577303409576]\n",
      "  batch 18 loss: [33.872039794921875, 0.825924426317215]\n",
      "  batch 20 loss: [30.90339183807373, 0.43724843859672546]\n",
      "  batch 22 loss: [29.076139450073242, 0.15335414186120033]\n",
      "  batch 24 loss: [28.083487510681152, 0.23696160316467285]\n",
      "  batch 26 loss: [29.877670288085938, 0.05214766226708889]\n",
      "  batch 28 loss: [34.2618293762207, 0.03841092437505722]\n",
      "  batch 30 loss: [33.27222442626953, 0.06842259876430035]\n",
      "  batch 32 loss: [36.029441833496094, 0.06598126515746117]\n",
      "  batch 34 loss: [35.48583221435547, 0.07123746909201145]\n",
      "  batch 36 loss: [35.2285270690918, 0.08575309067964554]\n",
      "  batch 38 loss: [32.03689384460449, 0.06039413996040821]\n",
      "  batch 40 loss: [29.99106216430664, 0.014005681034177542]\n",
      "  batch 42 loss: [33.83293628692627, 0.06272461637854576]\n",
      "  batch 44 loss: [35.96807861328125, 0.14099639095366]\n",
      "  batch 46 loss: [36.91008758544922, 0.047433216124773026]\n",
      "  batch 48 loss: [32.06756114959717, 0.026209281757473946]\n",
      "  batch 50 loss: [30.460429191589355, 0.026527994545176625]\n",
      "  batch 52 loss: [33.88961315155029, 0.016656809020787477]\n",
      "  batch 54 loss: [31.709997177124023, 0.025691729970276356]\n",
      "LOSS generator 31.709997177124023 discriminator 0.025691729970276356\n",
      "EPOCH 275:\n",
      "  batch 0 loss: [36.29480743408203, 0.01953507587313652]\n",
      "  batch 2 loss: [34.46771049499512, 0.03649899875745177]\n",
      "  batch 4 loss: [29.72836685180664, 0.014440174913033843]\n",
      "  batch 6 loss: [34.84646415710449, 0.022994539700448513]\n",
      "  batch 8 loss: [36.042367935180664, 0.011719115544110537]\n",
      "  batch 10 loss: [31.008773803710938, 0.0395441222935915]\n",
      "  batch 12 loss: [34.07311820983887, 0.023695513606071472]\n",
      "  batch 14 loss: [29.55033302307129, 0.03861946426331997]\n",
      "  batch 16 loss: [33.97178268432617, 0.01766561856493354]\n",
      "  batch 18 loss: [32.75309753417969, 0.15300855785608292]\n",
      "  batch 20 loss: [44.2064208984375, 0.05994067154824734]\n",
      "  batch 22 loss: [32.81792163848877, 0.3863319456577301]\n",
      "  batch 24 loss: [31.74888801574707, 1.1527527868747711]\n",
      "  batch 26 loss: [27.395334243774414, 0.8124611973762512]\n",
      "  batch 28 loss: [31.957935333251953, 0.4121214747428894]\n",
      "  batch 30 loss: [22.101008415222168, 0.3089662045240402]\n",
      "  batch 32 loss: [27.320005416870117, 0.31932301819324493]\n",
      "  batch 34 loss: [29.193721771240234, 0.1556524634361267]\n",
      "  batch 36 loss: [33.05156993865967, 0.20842161029577255]\n",
      "  batch 38 loss: [32.36046504974365, 0.3690105229616165]\n",
      "  batch 40 loss: [34.228774070739746, 0.3108144849538803]\n",
      "  batch 42 loss: [34.344242095947266, 0.1968688778579235]\n",
      "  batch 44 loss: [32.0078182220459, 0.15982560813426971]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
